(* quine:  -v -isafety -jobs 16 -slicing -no_carry_constraint -o small.log __asm_ntt_0_1_2_3_small_32.cl
Parsing Cryptoline file:                [OK]            0.114638 seconds
Checking well-formedness:               [OK]            0.133019 seconds
Transforming to SSA form:               [OK]            0.021695 seconds
Rewriting assignments:                  [OK]            0.021973 seconds
Verifying program safety:               [OK]            973.027172 seconds
Verifying range assertions:             [OK]            0.144750 seconds
Verifying range specification:          [OK]            497.900082 seconds
Rewriting value-preserved casting:      [OK]            0.001963 seconds
Verifying algebraic assertions:         [OK]            84.886228 seconds
Verifying algebraic specification:      [OK]            23.854631 seconds
Verification result:                    [OK]            1580.119245 seconds
                      Round 1 (5760 safety conditions, timeout = 300 seconds)
*)


proc main (
sint32 g000, sint32 g001, sint32 g002, sint32 g003, sint32 g004,
sint32 g005, sint32 g006, sint32 g007, sint32 g008, sint32 g009,
sint32 g010, sint32 g011, sint32 g012, sint32 g013, sint32 g014,
sint32 g015, sint32 g016, sint32 g017, sint32 g018, sint32 g019,
sint32 g020, sint32 g021, sint32 g022, sint32 g023, sint32 g024,
sint32 g025, sint32 g026, sint32 g027, sint32 g028, sint32 g029,
sint32 g030, sint32 g031, sint32 g032, sint32 g033, sint32 g034,
sint32 g035, sint32 g036, sint32 g037, sint32 g038, sint32 g039,
sint32 g040, sint32 g041, sint32 g042, sint32 g043, sint32 g044,
sint32 g045, sint32 g046, sint32 g047, sint32 g048, sint32 g049,
sint32 g050, sint32 g051, sint32 g052, sint32 g053, sint32 g054,
sint32 g055, sint32 g056, sint32 g057, sint32 g058, sint32 g059,
sint32 g060, sint32 g061, sint32 g062, sint32 g063, sint32 g064,
sint32 g065, sint32 g066, sint32 g067, sint32 g068, sint32 g069,
sint32 g070, sint32 g071, sint32 g072, sint32 g073, sint32 g074,
sint32 g075, sint32 g076, sint32 g077, sint32 g078, sint32 g079,
sint32 g080, sint32 g081, sint32 g082, sint32 g083, sint32 g084,
sint32 g085, sint32 g086, sint32 g087, sint32 g088, sint32 g089,
sint32 g090, sint32 g091, sint32 g092, sint32 g093, sint32 g094,
sint32 g095, sint32 g096, sint32 g097, sint32 g098, sint32 g099,
sint32 g100, sint32 g101, sint32 g102, sint32 g103, sint32 g104,
sint32 g105, sint32 g106, sint32 g107, sint32 g108, sint32 g109,
sint32 g110, sint32 g111, sint32 g112, sint32 g113, sint32 g114,
sint32 g115, sint32 g116, sint32 g117, sint32 g118, sint32 g119,
sint32 g120, sint32 g121, sint32 g122, sint32 g123, sint32 g124,
sint32 g125, sint32 g126, sint32 g127, sint32 g128, sint32 g129,
sint32 g130, sint32 g131, sint32 g132, sint32 g133, sint32 g134,
sint32 g135, sint32 g136, sint32 g137, sint32 g138, sint32 g139,
sint32 g140, sint32 g141, sint32 g142, sint32 g143, sint32 g144,
sint32 g145, sint32 g146, sint32 g147, sint32 g148, sint32 g149,
sint32 g150, sint32 g151, sint32 g152, sint32 g153, sint32 g154,
sint32 g155, sint32 g156, sint32 g157, sint32 g158, sint32 g159,
sint32 g160, sint32 g161, sint32 g162, sint32 g163, sint32 g164,
sint32 g165, sint32 g166, sint32 g167, sint32 g168, sint32 g169,
sint32 g170, sint32 g171, sint32 g172, sint32 g173, sint32 g174,
sint32 g175, sint32 g176, sint32 g177, sint32 g178, sint32 g179,
sint32 g180, sint32 g181, sint32 g182, sint32 g183, sint32 g184,
sint32 g185, sint32 g186, sint32 g187, sint32 g188, sint32 g189,
sint32 g190, sint32 g191, sint32 g192, sint32 g193, sint32 g194,
sint32 g195, sint32 g196, sint32 g197, sint32 g198, sint32 g199,
sint32 g200, sint32 g201, sint32 g202, sint32 g203, sint32 g204,
sint32 g205, sint32 g206, sint32 g207, sint32 g208, sint32 g209,
sint32 g210, sint32 g211, sint32 g212, sint32 g213, sint32 g214,
sint32 g215, sint32 g216, sint32 g217, sint32 g218, sint32 g219,
sint32 g220, sint32 g221, sint32 g222, sint32 g223, sint32 g224,
sint32 g225, sint32 g226, sint32 g227, sint32 g228, sint32 g229,
sint32 g230, sint32 g231, sint32 g232, sint32 g233, sint32 g234,
sint32 g235, sint32 g236, sint32 g237, sint32 g238, sint32 g239,
sint32 g240, sint32 g241, sint32 g242, sint32 g243, sint32 g244,
sint32 g245, sint32 g246, sint32 g247, sint32 g248, sint32 g249,
sint32 g250, sint32 g251, sint32 g252, sint32 g253, sint32 g254,
sint32 g255, sint32 g256, sint32 g257, sint32 g258, sint32 g259,
sint32 g260, sint32 g261, sint32 g262, sint32 g263, sint32 g264,
sint32 g265, sint32 g266, sint32 g267, sint32 g268, sint32 g269,
sint32 g270, sint32 g271, sint32 g272, sint32 g273, sint32 g274,
sint32 g275, sint32 g276, sint32 g277, sint32 g278, sint32 g279,
sint32 g280, sint32 g281, sint32 g282, sint32 g283, sint32 g284,
sint32 g285, sint32 g286, sint32 g287, sint32 g288, sint32 g289,
sint32 g290, sint32 g291, sint32 g292, sint32 g293, sint32 g294,
sint32 g295, sint32 g296, sint32 g297, sint32 g298, sint32 g299,
sint32 g300, sint32 g301, sint32 g302, sint32 g303, sint32 g304,
sint32 g305, sint32 g306, sint32 g307, sint32 g308, sint32 g309,
sint32 g310, sint32 g311, sint32 g312, sint32 g313, sint32 g314,
sint32 g315, sint32 g316, sint32 g317, sint32 g318, sint32 g319,
sint32 g320, sint32 g321, sint32 g322, sint32 g323, sint32 g324,
sint32 g325, sint32 g326, sint32 g327, sint32 g328, sint32 g329,
sint32 g330, sint32 g331, sint32 g332, sint32 g333, sint32 g334,
sint32 g335, sint32 g336, sint32 g337, sint32 g338, sint32 g339,
sint32 g340, sint32 g341, sint32 g342, sint32 g343, sint32 g344,
sint32 g345, sint32 g346, sint32 g347, sint32 g348, sint32 g349,
sint32 g350, sint32 g351, sint32 g352, sint32 g353, sint32 g354,
sint32 g355, sint32 g356, sint32 g357, sint32 g358, sint32 g359,
sint32 g360, sint32 g361, sint32 g362, sint32 g363, sint32 g364,
sint32 g365, sint32 g366, sint32 g367, sint32 g368, sint32 g369,
sint32 g370, sint32 g371, sint32 g372, sint32 g373, sint32 g374,
sint32 g375, sint32 g376, sint32 g377, sint32 g378, sint32 g379,
sint32 g380, sint32 g381, sint32 g382, sint32 g383, sint32 g384,
sint32 g385, sint32 g386, sint32 g387, sint32 g388, sint32 g389,
sint32 g390, sint32 g391, sint32 g392, sint32 g393, sint32 g394,
sint32 g395, sint32 g396, sint32 g397, sint32 g398, sint32 g399,
sint32 g400, sint32 g401, sint32 g402, sint32 g403, sint32 g404,
sint32 g405, sint32 g406, sint32 g407, sint32 g408, sint32 g409,
sint32 g410, sint32 g411, sint32 g412, sint32 g413, sint32 g414,
sint32 g415, sint32 g416, sint32 g417, sint32 g418, sint32 g419,
sint32 g420, sint32 g421, sint32 g422, sint32 g423, sint32 g424,
sint32 g425, sint32 g426, sint32 g427, sint32 g428, sint32 g429,
sint32 g430, sint32 g431, sint32 g432, sint32 g433, sint32 g434,
sint32 g435, sint32 g436, sint32 g437, sint32 g438, sint32 g439,
sint32 g440, sint32 g441, sint32 g442, sint32 g443, sint32 g444,
sint32 g445, sint32 g446, sint32 g447, sint32 g448, sint32 g449,
sint32 g450, sint32 g451, sint32 g452, sint32 g453, sint32 g454,
sint32 g455, sint32 g456, sint32 g457, sint32 g458, sint32 g459,
sint32 g460, sint32 g461, sint32 g462, sint32 g463, sint32 g464,
sint32 g465, sint32 g466, sint32 g467, sint32 g468, sint32 g469,
sint32 g470, sint32 g471, sint32 g472, sint32 g473, sint32 g474,
sint32 g475, sint32 g476, sint32 g477, sint32 g478, sint32 g479,
sint32 g480, sint32 g481, sint32 g482, sint32 g483, sint32 g484,
sint32 g485, sint32 g486, sint32 g487, sint32 g488, sint32 g489,
sint32 g490, sint32 g491, sint32 g492, sint32 g493, sint32 g494,
sint32 g495, sint32 g496, sint32 g497, sint32 g498, sint32 g499,
sint32 g500, sint32 g501, sint32 g502, sint32 g503, sint32 g504,
sint32 g505, sint32 g506, sint32 g507, sint32 g508
) =
{
true && and [
(-2)@32 <=s g000, g000 <s 2@32, (-2)@32 <=s g001, g001 <s 2@32,
(-2)@32 <=s g002, g002 <s 2@32, (-2)@32 <=s g003, g003 <s 2@32,
(-2)@32 <=s g004, g004 <s 2@32, (-2)@32 <=s g005, g005 <s 2@32,
(-2)@32 <=s g006, g006 <s 2@32, (-2)@32 <=s g007, g007 <s 2@32,
(-2)@32 <=s g008, g008 <s 2@32, (-2)@32 <=s g009, g009 <s 2@32,
(-2)@32 <=s g010, g010 <s 2@32, (-2)@32 <=s g011, g011 <s 2@32,
(-2)@32 <=s g012, g012 <s 2@32, (-2)@32 <=s g013, g013 <s 2@32,
(-2)@32 <=s g014, g014 <s 2@32, (-2)@32 <=s g015, g015 <s 2@32,
(-2)@32 <=s g016, g016 <s 2@32, (-2)@32 <=s g017, g017 <s 2@32,
(-2)@32 <=s g018, g018 <s 2@32, (-2)@32 <=s g019, g019 <s 2@32,
(-2)@32 <=s g020, g020 <s 2@32, (-2)@32 <=s g021, g021 <s 2@32,
(-2)@32 <=s g022, g022 <s 2@32, (-2)@32 <=s g023, g023 <s 2@32,
(-2)@32 <=s g024, g024 <s 2@32, (-2)@32 <=s g025, g025 <s 2@32,
(-2)@32 <=s g026, g026 <s 2@32, (-2)@32 <=s g027, g027 <s 2@32,
(-2)@32 <=s g028, g028 <s 2@32, (-2)@32 <=s g029, g029 <s 2@32,
(-2)@32 <=s g030, g030 <s 2@32, (-2)@32 <=s g031, g031 <s 2@32,
(-2)@32 <=s g032, g032 <s 2@32, (-2)@32 <=s g033, g033 <s 2@32,
(-2)@32 <=s g034, g034 <s 2@32, (-2)@32 <=s g035, g035 <s 2@32,
(-2)@32 <=s g036, g036 <s 2@32, (-2)@32 <=s g037, g037 <s 2@32,
(-2)@32 <=s g038, g038 <s 2@32, (-2)@32 <=s g039, g039 <s 2@32,
(-2)@32 <=s g040, g040 <s 2@32, (-2)@32 <=s g041, g041 <s 2@32,
(-2)@32 <=s g042, g042 <s 2@32, (-2)@32 <=s g043, g043 <s 2@32,
(-2)@32 <=s g044, g044 <s 2@32, (-2)@32 <=s g045, g045 <s 2@32,
(-2)@32 <=s g046, g046 <s 2@32, (-2)@32 <=s g047, g047 <s 2@32,
(-2)@32 <=s g048, g048 <s 2@32, (-2)@32 <=s g049, g049 <s 2@32,
(-2)@32 <=s g050, g050 <s 2@32, (-2)@32 <=s g051, g051 <s 2@32,
(-2)@32 <=s g052, g052 <s 2@32, (-2)@32 <=s g053, g053 <s 2@32,
(-2)@32 <=s g054, g054 <s 2@32, (-2)@32 <=s g055, g055 <s 2@32,
(-2)@32 <=s g056, g056 <s 2@32, (-2)@32 <=s g057, g057 <s 2@32,
(-2)@32 <=s g058, g058 <s 2@32, (-2)@32 <=s g059, g059 <s 2@32,
(-2)@32 <=s g060, g060 <s 2@32, (-2)@32 <=s g061, g061 <s 2@32,
(-2)@32 <=s g062, g062 <s 2@32, (-2)@32 <=s g063, g063 <s 2@32,
(-2)@32 <=s g064, g064 <s 2@32, (-2)@32 <=s g065, g065 <s 2@32,
(-2)@32 <=s g066, g066 <s 2@32, (-2)@32 <=s g067, g067 <s 2@32,
(-2)@32 <=s g068, g068 <s 2@32, (-2)@32 <=s g069, g069 <s 2@32,
(-2)@32 <=s g070, g070 <s 2@32, (-2)@32 <=s g071, g071 <s 2@32,
(-2)@32 <=s g072, g072 <s 2@32, (-2)@32 <=s g073, g073 <s 2@32,
(-2)@32 <=s g074, g074 <s 2@32, (-2)@32 <=s g075, g075 <s 2@32,
(-2)@32 <=s g076, g076 <s 2@32, (-2)@32 <=s g077, g077 <s 2@32,
(-2)@32 <=s g078, g078 <s 2@32, (-2)@32 <=s g079, g079 <s 2@32,
(-2)@32 <=s g080, g080 <s 2@32, (-2)@32 <=s g081, g081 <s 2@32,
(-2)@32 <=s g082, g082 <s 2@32, (-2)@32 <=s g083, g083 <s 2@32,
(-2)@32 <=s g084, g084 <s 2@32, (-2)@32 <=s g085, g085 <s 2@32,
(-2)@32 <=s g086, g086 <s 2@32, (-2)@32 <=s g087, g087 <s 2@32,
(-2)@32 <=s g088, g088 <s 2@32, (-2)@32 <=s g089, g089 <s 2@32,
(-2)@32 <=s g090, g090 <s 2@32, (-2)@32 <=s g091, g091 <s 2@32,
(-2)@32 <=s g092, g092 <s 2@32, (-2)@32 <=s g093, g093 <s 2@32,
(-2)@32 <=s g094, g094 <s 2@32, (-2)@32 <=s g095, g095 <s 2@32,
(-2)@32 <=s g096, g096 <s 2@32, (-2)@32 <=s g097, g097 <s 2@32,
(-2)@32 <=s g098, g098 <s 2@32, (-2)@32 <=s g099, g099 <s 2@32,
(-2)@32 <=s g100, g100 <s 2@32, (-2)@32 <=s g101, g101 <s 2@32,
(-2)@32 <=s g102, g102 <s 2@32, (-2)@32 <=s g103, g103 <s 2@32,
(-2)@32 <=s g104, g104 <s 2@32, (-2)@32 <=s g105, g105 <s 2@32,
(-2)@32 <=s g106, g106 <s 2@32, (-2)@32 <=s g107, g107 <s 2@32,
(-2)@32 <=s g108, g108 <s 2@32, (-2)@32 <=s g109, g109 <s 2@32,
(-2)@32 <=s g110, g110 <s 2@32, (-2)@32 <=s g111, g111 <s 2@32,
(-2)@32 <=s g112, g112 <s 2@32, (-2)@32 <=s g113, g113 <s 2@32,
(-2)@32 <=s g114, g114 <s 2@32, (-2)@32 <=s g115, g115 <s 2@32,
(-2)@32 <=s g116, g116 <s 2@32, (-2)@32 <=s g117, g117 <s 2@32,
(-2)@32 <=s g118, g118 <s 2@32, (-2)@32 <=s g119, g119 <s 2@32,
(-2)@32 <=s g120, g120 <s 2@32, (-2)@32 <=s g121, g121 <s 2@32,
(-2)@32 <=s g122, g122 <s 2@32, (-2)@32 <=s g123, g123 <s 2@32,
(-2)@32 <=s g124, g124 <s 2@32, (-2)@32 <=s g125, g125 <s 2@32,
(-2)@32 <=s g126, g126 <s 2@32, (-2)@32 <=s g127, g127 <s 2@32,
(-2)@32 <=s g128, g128 <s 2@32, (-2)@32 <=s g129, g129 <s 2@32,
(-2)@32 <=s g130, g130 <s 2@32, (-2)@32 <=s g131, g131 <s 2@32,
(-2)@32 <=s g132, g132 <s 2@32, (-2)@32 <=s g133, g133 <s 2@32,
(-2)@32 <=s g134, g134 <s 2@32, (-2)@32 <=s g135, g135 <s 2@32,
(-2)@32 <=s g136, g136 <s 2@32, (-2)@32 <=s g137, g137 <s 2@32,
(-2)@32 <=s g138, g138 <s 2@32, (-2)@32 <=s g139, g139 <s 2@32,
(-2)@32 <=s g140, g140 <s 2@32, (-2)@32 <=s g141, g141 <s 2@32,
(-2)@32 <=s g142, g142 <s 2@32, (-2)@32 <=s g143, g143 <s 2@32,
(-2)@32 <=s g144, g144 <s 2@32, (-2)@32 <=s g145, g145 <s 2@32,
(-2)@32 <=s g146, g146 <s 2@32, (-2)@32 <=s g147, g147 <s 2@32,
(-2)@32 <=s g148, g148 <s 2@32, (-2)@32 <=s g149, g149 <s 2@32,
(-2)@32 <=s g150, g150 <s 2@32, (-2)@32 <=s g151, g151 <s 2@32,
(-2)@32 <=s g152, g152 <s 2@32, (-2)@32 <=s g153, g153 <s 2@32,
(-2)@32 <=s g154, g154 <s 2@32, (-2)@32 <=s g155, g155 <s 2@32,
(-2)@32 <=s g156, g156 <s 2@32, (-2)@32 <=s g157, g157 <s 2@32,
(-2)@32 <=s g158, g158 <s 2@32, (-2)@32 <=s g159, g159 <s 2@32,
(-2)@32 <=s g160, g160 <s 2@32, (-2)@32 <=s g161, g161 <s 2@32,
(-2)@32 <=s g162, g162 <s 2@32, (-2)@32 <=s g163, g163 <s 2@32,
(-2)@32 <=s g164, g164 <s 2@32, (-2)@32 <=s g165, g165 <s 2@32,
(-2)@32 <=s g166, g166 <s 2@32, (-2)@32 <=s g167, g167 <s 2@32,
(-2)@32 <=s g168, g168 <s 2@32, (-2)@32 <=s g169, g169 <s 2@32,
(-2)@32 <=s g170, g170 <s 2@32, (-2)@32 <=s g171, g171 <s 2@32,
(-2)@32 <=s g172, g172 <s 2@32, (-2)@32 <=s g173, g173 <s 2@32,
(-2)@32 <=s g174, g174 <s 2@32, (-2)@32 <=s g175, g175 <s 2@32,
(-2)@32 <=s g176, g176 <s 2@32, (-2)@32 <=s g177, g177 <s 2@32,
(-2)@32 <=s g178, g178 <s 2@32, (-2)@32 <=s g179, g179 <s 2@32,
(-2)@32 <=s g180, g180 <s 2@32, (-2)@32 <=s g181, g181 <s 2@32,
(-2)@32 <=s g182, g182 <s 2@32, (-2)@32 <=s g183, g183 <s 2@32,
(-2)@32 <=s g184, g184 <s 2@32, (-2)@32 <=s g185, g185 <s 2@32,
(-2)@32 <=s g186, g186 <s 2@32, (-2)@32 <=s g187, g187 <s 2@32,
(-2)@32 <=s g188, g188 <s 2@32, (-2)@32 <=s g189, g189 <s 2@32,
(-2)@32 <=s g190, g190 <s 2@32, (-2)@32 <=s g191, g191 <s 2@32,
(-2)@32 <=s g192, g192 <s 2@32, (-2)@32 <=s g193, g193 <s 2@32,
(-2)@32 <=s g194, g194 <s 2@32, (-2)@32 <=s g195, g195 <s 2@32,
(-2)@32 <=s g196, g196 <s 2@32, (-2)@32 <=s g197, g197 <s 2@32,
(-2)@32 <=s g198, g198 <s 2@32, (-2)@32 <=s g199, g199 <s 2@32,
(-2)@32 <=s g200, g200 <s 2@32, (-2)@32 <=s g201, g201 <s 2@32,
(-2)@32 <=s g202, g202 <s 2@32, (-2)@32 <=s g203, g203 <s 2@32,
(-2)@32 <=s g204, g204 <s 2@32, (-2)@32 <=s g205, g205 <s 2@32,
(-2)@32 <=s g206, g206 <s 2@32, (-2)@32 <=s g207, g207 <s 2@32,
(-2)@32 <=s g208, g208 <s 2@32, (-2)@32 <=s g209, g209 <s 2@32,
(-2)@32 <=s g210, g210 <s 2@32, (-2)@32 <=s g211, g211 <s 2@32,
(-2)@32 <=s g212, g212 <s 2@32, (-2)@32 <=s g213, g213 <s 2@32,
(-2)@32 <=s g214, g214 <s 2@32, (-2)@32 <=s g215, g215 <s 2@32,
(-2)@32 <=s g216, g216 <s 2@32, (-2)@32 <=s g217, g217 <s 2@32,
(-2)@32 <=s g218, g218 <s 2@32, (-2)@32 <=s g219, g219 <s 2@32,
(-2)@32 <=s g220, g220 <s 2@32, (-2)@32 <=s g221, g221 <s 2@32,
(-2)@32 <=s g222, g222 <s 2@32, (-2)@32 <=s g223, g223 <s 2@32,
(-2)@32 <=s g224, g224 <s 2@32, (-2)@32 <=s g225, g225 <s 2@32,
(-2)@32 <=s g226, g226 <s 2@32, (-2)@32 <=s g227, g227 <s 2@32,
(-2)@32 <=s g228, g228 <s 2@32, (-2)@32 <=s g229, g229 <s 2@32,
(-2)@32 <=s g230, g230 <s 2@32, (-2)@32 <=s g231, g231 <s 2@32,
(-2)@32 <=s g232, g232 <s 2@32, (-2)@32 <=s g233, g233 <s 2@32,
(-2)@32 <=s g234, g234 <s 2@32, (-2)@32 <=s g235, g235 <s 2@32,
(-2)@32 <=s g236, g236 <s 2@32, (-2)@32 <=s g237, g237 <s 2@32,
(-2)@32 <=s g238, g238 <s 2@32, (-2)@32 <=s g239, g239 <s 2@32,
(-2)@32 <=s g240, g240 <s 2@32, (-2)@32 <=s g241, g241 <s 2@32,
(-2)@32 <=s g242, g242 <s 2@32, (-2)@32 <=s g243, g243 <s 2@32,
(-2)@32 <=s g244, g244 <s 2@32, (-2)@32 <=s g245, g245 <s 2@32,
(-2)@32 <=s g246, g246 <s 2@32, (-2)@32 <=s g247, g247 <s 2@32,
(-2)@32 <=s g248, g248 <s 2@32, (-2)@32 <=s g249, g249 <s 2@32,
(-2)@32 <=s g250, g250 <s 2@32, (-2)@32 <=s g251, g251 <s 2@32,
(-2)@32 <=s g252, g252 <s 2@32, (-2)@32 <=s g253, g253 <s 2@32,
(-2)@32 <=s g254, g254 <s 2@32, (-2)@32 <=s g255, g255 <s 2@32,
(-2)@32 <=s g256, g256 <s 2@32, (-2)@32 <=s g257, g257 <s 2@32,
(-2)@32 <=s g258, g258 <s 2@32, (-2)@32 <=s g259, g259 <s 2@32,
(-2)@32 <=s g260, g260 <s 2@32, (-2)@32 <=s g261, g261 <s 2@32,
(-2)@32 <=s g262, g262 <s 2@32, (-2)@32 <=s g263, g263 <s 2@32,
(-2)@32 <=s g264, g264 <s 2@32, (-2)@32 <=s g265, g265 <s 2@32,
(-2)@32 <=s g266, g266 <s 2@32, (-2)@32 <=s g267, g267 <s 2@32,
(-2)@32 <=s g268, g268 <s 2@32, (-2)@32 <=s g269, g269 <s 2@32,
(-2)@32 <=s g270, g270 <s 2@32, (-2)@32 <=s g271, g271 <s 2@32,
(-2)@32 <=s g272, g272 <s 2@32, (-2)@32 <=s g273, g273 <s 2@32,
(-2)@32 <=s g274, g274 <s 2@32, (-2)@32 <=s g275, g275 <s 2@32,
(-2)@32 <=s g276, g276 <s 2@32, (-2)@32 <=s g277, g277 <s 2@32,
(-2)@32 <=s g278, g278 <s 2@32, (-2)@32 <=s g279, g279 <s 2@32,
(-2)@32 <=s g280, g280 <s 2@32, (-2)@32 <=s g281, g281 <s 2@32,
(-2)@32 <=s g282, g282 <s 2@32, (-2)@32 <=s g283, g283 <s 2@32,
(-2)@32 <=s g284, g284 <s 2@32, (-2)@32 <=s g285, g285 <s 2@32,
(-2)@32 <=s g286, g286 <s 2@32, (-2)@32 <=s g287, g287 <s 2@32,
(-2)@32 <=s g288, g288 <s 2@32, (-2)@32 <=s g289, g289 <s 2@32,
(-2)@32 <=s g290, g290 <s 2@32, (-2)@32 <=s g291, g291 <s 2@32,
(-2)@32 <=s g292, g292 <s 2@32, (-2)@32 <=s g293, g293 <s 2@32,
(-2)@32 <=s g294, g294 <s 2@32, (-2)@32 <=s g295, g295 <s 2@32,
(-2)@32 <=s g296, g296 <s 2@32, (-2)@32 <=s g297, g297 <s 2@32,
(-2)@32 <=s g298, g298 <s 2@32, (-2)@32 <=s g299, g299 <s 2@32,
(-2)@32 <=s g300, g300 <s 2@32, (-2)@32 <=s g301, g301 <s 2@32,
(-2)@32 <=s g302, g302 <s 2@32, (-2)@32 <=s g303, g303 <s 2@32,
(-2)@32 <=s g304, g304 <s 2@32, (-2)@32 <=s g305, g305 <s 2@32,
(-2)@32 <=s g306, g306 <s 2@32, (-2)@32 <=s g307, g307 <s 2@32,
(-2)@32 <=s g308, g308 <s 2@32, (-2)@32 <=s g309, g309 <s 2@32,
(-2)@32 <=s g310, g310 <s 2@32, (-2)@32 <=s g311, g311 <s 2@32,
(-2)@32 <=s g312, g312 <s 2@32, (-2)@32 <=s g313, g313 <s 2@32,
(-2)@32 <=s g314, g314 <s 2@32, (-2)@32 <=s g315, g315 <s 2@32,
(-2)@32 <=s g316, g316 <s 2@32, (-2)@32 <=s g317, g317 <s 2@32,
(-2)@32 <=s g318, g318 <s 2@32, (-2)@32 <=s g319, g319 <s 2@32,
(-2)@32 <=s g320, g320 <s 2@32, (-2)@32 <=s g321, g321 <s 2@32,
(-2)@32 <=s g322, g322 <s 2@32, (-2)@32 <=s g323, g323 <s 2@32,
(-2)@32 <=s g324, g324 <s 2@32, (-2)@32 <=s g325, g325 <s 2@32,
(-2)@32 <=s g326, g326 <s 2@32, (-2)@32 <=s g327, g327 <s 2@32,
(-2)@32 <=s g328, g328 <s 2@32, (-2)@32 <=s g329, g329 <s 2@32,
(-2)@32 <=s g330, g330 <s 2@32, (-2)@32 <=s g331, g331 <s 2@32,
(-2)@32 <=s g332, g332 <s 2@32, (-2)@32 <=s g333, g333 <s 2@32,
(-2)@32 <=s g334, g334 <s 2@32, (-2)@32 <=s g335, g335 <s 2@32,
(-2)@32 <=s g336, g336 <s 2@32, (-2)@32 <=s g337, g337 <s 2@32,
(-2)@32 <=s g338, g338 <s 2@32, (-2)@32 <=s g339, g339 <s 2@32,
(-2)@32 <=s g340, g340 <s 2@32, (-2)@32 <=s g341, g341 <s 2@32,
(-2)@32 <=s g342, g342 <s 2@32, (-2)@32 <=s g343, g343 <s 2@32,
(-2)@32 <=s g344, g344 <s 2@32, (-2)@32 <=s g345, g345 <s 2@32,
(-2)@32 <=s g346, g346 <s 2@32, (-2)@32 <=s g347, g347 <s 2@32,
(-2)@32 <=s g348, g348 <s 2@32, (-2)@32 <=s g349, g349 <s 2@32,
(-2)@32 <=s g350, g350 <s 2@32, (-2)@32 <=s g351, g351 <s 2@32,
(-2)@32 <=s g352, g352 <s 2@32, (-2)@32 <=s g353, g353 <s 2@32,
(-2)@32 <=s g354, g354 <s 2@32, (-2)@32 <=s g355, g355 <s 2@32,
(-2)@32 <=s g356, g356 <s 2@32, (-2)@32 <=s g357, g357 <s 2@32,
(-2)@32 <=s g358, g358 <s 2@32, (-2)@32 <=s g359, g359 <s 2@32,
(-2)@32 <=s g360, g360 <s 2@32, (-2)@32 <=s g361, g361 <s 2@32,
(-2)@32 <=s g362, g362 <s 2@32, (-2)@32 <=s g363, g363 <s 2@32,
(-2)@32 <=s g364, g364 <s 2@32, (-2)@32 <=s g365, g365 <s 2@32,
(-2)@32 <=s g366, g366 <s 2@32, (-2)@32 <=s g367, g367 <s 2@32,
(-2)@32 <=s g368, g368 <s 2@32, (-2)@32 <=s g369, g369 <s 2@32,
(-2)@32 <=s g370, g370 <s 2@32, (-2)@32 <=s g371, g371 <s 2@32,
(-2)@32 <=s g372, g372 <s 2@32, (-2)@32 <=s g373, g373 <s 2@32,
(-2)@32 <=s g374, g374 <s 2@32, (-2)@32 <=s g375, g375 <s 2@32,
(-2)@32 <=s g376, g376 <s 2@32, (-2)@32 <=s g377, g377 <s 2@32,
(-2)@32 <=s g378, g378 <s 2@32, (-2)@32 <=s g379, g379 <s 2@32,
(-2)@32 <=s g380, g380 <s 2@32, (-2)@32 <=s g381, g381 <s 2@32,
(-2)@32 <=s g382, g382 <s 2@32, (-2)@32 <=s g383, g383 <s 2@32,
(-2)@32 <=s g384, g384 <s 2@32, (-2)@32 <=s g385, g385 <s 2@32,
(-2)@32 <=s g386, g386 <s 2@32, (-2)@32 <=s g387, g387 <s 2@32,
(-2)@32 <=s g388, g388 <s 2@32, (-2)@32 <=s g389, g389 <s 2@32,
(-2)@32 <=s g390, g390 <s 2@32, (-2)@32 <=s g391, g391 <s 2@32,
(-2)@32 <=s g392, g392 <s 2@32, (-2)@32 <=s g393, g393 <s 2@32,
(-2)@32 <=s g394, g394 <s 2@32, (-2)@32 <=s g395, g395 <s 2@32,
(-2)@32 <=s g396, g396 <s 2@32, (-2)@32 <=s g397, g397 <s 2@32,
(-2)@32 <=s g398, g398 <s 2@32, (-2)@32 <=s g399, g399 <s 2@32,
(-2)@32 <=s g400, g400 <s 2@32, (-2)@32 <=s g401, g401 <s 2@32,
(-2)@32 <=s g402, g402 <s 2@32, (-2)@32 <=s g403, g403 <s 2@32,
(-2)@32 <=s g404, g404 <s 2@32, (-2)@32 <=s g405, g405 <s 2@32,
(-2)@32 <=s g406, g406 <s 2@32, (-2)@32 <=s g407, g407 <s 2@32,
(-2)@32 <=s g408, g408 <s 2@32, (-2)@32 <=s g409, g409 <s 2@32,
(-2)@32 <=s g410, g410 <s 2@32, (-2)@32 <=s g411, g411 <s 2@32,
(-2)@32 <=s g412, g412 <s 2@32, (-2)@32 <=s g413, g413 <s 2@32,
(-2)@32 <=s g414, g414 <s 2@32, (-2)@32 <=s g415, g415 <s 2@32,
(-2)@32 <=s g416, g416 <s 2@32, (-2)@32 <=s g417, g417 <s 2@32,
(-2)@32 <=s g418, g418 <s 2@32, (-2)@32 <=s g419, g419 <s 2@32,
(-2)@32 <=s g420, g420 <s 2@32, (-2)@32 <=s g421, g421 <s 2@32,
(-2)@32 <=s g422, g422 <s 2@32, (-2)@32 <=s g423, g423 <s 2@32,
(-2)@32 <=s g424, g424 <s 2@32, (-2)@32 <=s g425, g425 <s 2@32,
(-2)@32 <=s g426, g426 <s 2@32, (-2)@32 <=s g427, g427 <s 2@32,
(-2)@32 <=s g428, g428 <s 2@32, (-2)@32 <=s g429, g429 <s 2@32,
(-2)@32 <=s g430, g430 <s 2@32, (-2)@32 <=s g431, g431 <s 2@32,
(-2)@32 <=s g432, g432 <s 2@32, (-2)@32 <=s g433, g433 <s 2@32,
(-2)@32 <=s g434, g434 <s 2@32, (-2)@32 <=s g435, g435 <s 2@32,
(-2)@32 <=s g436, g436 <s 2@32, (-2)@32 <=s g437, g437 <s 2@32,
(-2)@32 <=s g438, g438 <s 2@32, (-2)@32 <=s g439, g439 <s 2@32,
(-2)@32 <=s g440, g440 <s 2@32, (-2)@32 <=s g441, g441 <s 2@32,
(-2)@32 <=s g442, g442 <s 2@32, (-2)@32 <=s g443, g443 <s 2@32,
(-2)@32 <=s g444, g444 <s 2@32, (-2)@32 <=s g445, g445 <s 2@32,
(-2)@32 <=s g446, g446 <s 2@32, (-2)@32 <=s g447, g447 <s 2@32,
(-2)@32 <=s g448, g448 <s 2@32, (-2)@32 <=s g449, g449 <s 2@32,
(-2)@32 <=s g450, g450 <s 2@32, (-2)@32 <=s g451, g451 <s 2@32,
(-2)@32 <=s g452, g452 <s 2@32, (-2)@32 <=s g453, g453 <s 2@32,
(-2)@32 <=s g454, g454 <s 2@32, (-2)@32 <=s g455, g455 <s 2@32,
(-2)@32 <=s g456, g456 <s 2@32, (-2)@32 <=s g457, g457 <s 2@32,
(-2)@32 <=s g458, g458 <s 2@32, (-2)@32 <=s g459, g459 <s 2@32,
(-2)@32 <=s g460, g460 <s 2@32, (-2)@32 <=s g461, g461 <s 2@32,
(-2)@32 <=s g462, g462 <s 2@32, (-2)@32 <=s g463, g463 <s 2@32,
(-2)@32 <=s g464, g464 <s 2@32, (-2)@32 <=s g465, g465 <s 2@32,
(-2)@32 <=s g466, g466 <s 2@32, (-2)@32 <=s g467, g467 <s 2@32,
(-2)@32 <=s g468, g468 <s 2@32, (-2)@32 <=s g469, g469 <s 2@32,
(-2)@32 <=s g470, g470 <s 2@32, (-2)@32 <=s g471, g471 <s 2@32,
(-2)@32 <=s g472, g472 <s 2@32, (-2)@32 <=s g473, g473 <s 2@32,
(-2)@32 <=s g474, g474 <s 2@32, (-2)@32 <=s g475, g475 <s 2@32,
(-2)@32 <=s g476, g476 <s 2@32, (-2)@32 <=s g477, g477 <s 2@32,
(-2)@32 <=s g478, g478 <s 2@32, (-2)@32 <=s g479, g479 <s 2@32,
(-2)@32 <=s g480, g480 <s 2@32, (-2)@32 <=s g481, g481 <s 2@32,
(-2)@32 <=s g482, g482 <s 2@32, (-2)@32 <=s g483, g483 <s 2@32,
(-2)@32 <=s g484, g484 <s 2@32, (-2)@32 <=s g485, g485 <s 2@32,
(-2)@32 <=s g486, g486 <s 2@32, (-2)@32 <=s g487, g487 <s 2@32,
(-2)@32 <=s g488, g488 <s 2@32, (-2)@32 <=s g489, g489 <s 2@32,
(-2)@32 <=s g490, g490 <s 2@32, (-2)@32 <=s g491, g491 <s 2@32,
(-2)@32 <=s g492, g492 <s 2@32, (-2)@32 <=s g493, g493 <s 2@32,
(-2)@32 <=s g494, g494 <s 2@32, (-2)@32 <=s g495, g495 <s 2@32,
(-2)@32 <=s g496, g496 <s 2@32, (-2)@32 <=s g497, g497 <s 2@32,
(-2)@32 <=s g498, g498 <s 2@32, (-2)@32 <=s g499, g499 <s 2@32,
(-2)@32 <=s g500, g500 <s 2@32, (-2)@32 <=s g501, g501 <s 2@32,
(-2)@32 <=s g502, g502 <s 2@32, (-2)@32 <=s g503, g503 <s 2@32,
(-2)@32 <=s g504, g504 <s 2@32, (-2)@32 <=s g505, g505 <s 2@32,
(-2)@32 <=s g506, g506 <s 2@32, (-2)@32 <=s g507, g507 <s 2@32,
(-2)@32 <=s g508, g508 <s 2@32
]
}

(**************** initialization ****************)

mov r2 1993076223@uint32; mov r3 1043969@sint32;
mov L0x200177d0 g000; mov L0x200177d2 g001; mov L0x200177d4 g002;
mov L0x200177d6 g003; mov L0x200177d8 g004; mov L0x200177da g005;
mov L0x200177dc g006; mov L0x200177de g007; mov L0x200177e0 g008;
mov L0x200177e2 g009; mov L0x200177e4 g010; mov L0x200177e6 g011;
mov L0x200177e8 g012; mov L0x200177ea g013; mov L0x200177ec g014;
mov L0x200177ee g015; mov L0x200177f0 g016; mov L0x200177f2 g017;
mov L0x200177f4 g018; mov L0x200177f6 g019; mov L0x200177f8 g020;
mov L0x200177fa g021; mov L0x200177fc g022; mov L0x200177fe g023;
mov L0x20017800 g024; mov L0x20017802 g025; mov L0x20017804 g026;
mov L0x20017806 g027; mov L0x20017808 g028; mov L0x2001780a g029;
mov L0x2001780c g030; mov L0x2001780e g031; mov L0x20017810 g032;
mov L0x20017812 g033; mov L0x20017814 g034; mov L0x20017816 g035;
mov L0x20017818 g036; mov L0x2001781a g037; mov L0x2001781c g038;
mov L0x2001781e g039; mov L0x20017820 g040; mov L0x20017822 g041;
mov L0x20017824 g042; mov L0x20017826 g043; mov L0x20017828 g044;
mov L0x2001782a g045; mov L0x2001782c g046; mov L0x2001782e g047;
mov L0x20017830 g048; mov L0x20017832 g049; mov L0x20017834 g050;
mov L0x20017836 g051; mov L0x20017838 g052; mov L0x2001783a g053;
mov L0x2001783c g054; mov L0x2001783e g055; mov L0x20017840 g056;
mov L0x20017842 g057; mov L0x20017844 g058; mov L0x20017846 g059;
mov L0x20017848 g060; mov L0x2001784a g061; mov L0x2001784c g062;
mov L0x2001784e g063; mov L0x20017850 g064; mov L0x20017852 g065;
mov L0x20017854 g066; mov L0x20017856 g067; mov L0x20017858 g068;
mov L0x2001785a g069; mov L0x2001785c g070; mov L0x2001785e g071;
mov L0x20017860 g072; mov L0x20017862 g073; mov L0x20017864 g074;
mov L0x20017866 g075; mov L0x20017868 g076; mov L0x2001786a g077;
mov L0x2001786c g078; mov L0x2001786e g079; mov L0x20017870 g080;
mov L0x20017872 g081; mov L0x20017874 g082; mov L0x20017876 g083;
mov L0x20017878 g084; mov L0x2001787a g085; mov L0x2001787c g086;
mov L0x2001787e g087; mov L0x20017880 g088; mov L0x20017882 g089;
mov L0x20017884 g090; mov L0x20017886 g091; mov L0x20017888 g092;
mov L0x2001788a g093; mov L0x2001788c g094; mov L0x2001788e g095;
mov L0x20017890 g096; mov L0x20017892 g097; mov L0x20017894 g098;
mov L0x20017896 g099; mov L0x20017898 g100; mov L0x2001789a g101;
mov L0x2001789c g102; mov L0x2001789e g103; mov L0x200178a0 g104;
mov L0x200178a2 g105; mov L0x200178a4 g106; mov L0x200178a6 g107;
mov L0x200178a8 g108; mov L0x200178aa g109; mov L0x200178ac g110;
mov L0x200178ae g111; mov L0x200178b0 g112; mov L0x200178b2 g113;
mov L0x200178b4 g114; mov L0x200178b6 g115; mov L0x200178b8 g116;
mov L0x200178ba g117; mov L0x200178bc g118; mov L0x200178be g119;
mov L0x200178c0 g120; mov L0x200178c2 g121; mov L0x200178c4 g122;
mov L0x200178c6 g123; mov L0x200178c8 g124; mov L0x200178ca g125;
mov L0x200178cc g126; mov L0x200178ce g127; mov L0x200178d0 g128;
mov L0x200178d2 g129; mov L0x200178d4 g130; mov L0x200178d6 g131;
mov L0x200178d8 g132; mov L0x200178da g133; mov L0x200178dc g134;
mov L0x200178de g135; mov L0x200178e0 g136; mov L0x200178e2 g137;
mov L0x200178e4 g138; mov L0x200178e6 g139; mov L0x200178e8 g140;
mov L0x200178ea g141; mov L0x200178ec g142; mov L0x200178ee g143;
mov L0x200178f0 g144; mov L0x200178f2 g145; mov L0x200178f4 g146;
mov L0x200178f6 g147; mov L0x200178f8 g148; mov L0x200178fa g149;
mov L0x200178fc g150; mov L0x200178fe g151; mov L0x20017900 g152;
mov L0x20017902 g153; mov L0x20017904 g154; mov L0x20017906 g155;
mov L0x20017908 g156; mov L0x2001790a g157; mov L0x2001790c g158;
mov L0x2001790e g159; mov L0x20017910 g160; mov L0x20017912 g161;
mov L0x20017914 g162; mov L0x20017916 g163; mov L0x20017918 g164;
mov L0x2001791a g165; mov L0x2001791c g166; mov L0x2001791e g167;
mov L0x20017920 g168; mov L0x20017922 g169; mov L0x20017924 g170;
mov L0x20017926 g171; mov L0x20017928 g172; mov L0x2001792a g173;
mov L0x2001792c g174; mov L0x2001792e g175; mov L0x20017930 g176;
mov L0x20017932 g177; mov L0x20017934 g178; mov L0x20017936 g179;
mov L0x20017938 g180; mov L0x2001793a g181; mov L0x2001793c g182;
mov L0x2001793e g183; mov L0x20017940 g184; mov L0x20017942 g185;
mov L0x20017944 g186; mov L0x20017946 g187; mov L0x20017948 g188;
mov L0x2001794a g189; mov L0x2001794c g190; mov L0x2001794e g191;
mov L0x20017950 g192; mov L0x20017952 g193; mov L0x20017954 g194;
mov L0x20017956 g195; mov L0x20017958 g196; mov L0x2001795a g197;
mov L0x2001795c g198; mov L0x2001795e g199; mov L0x20017960 g200;
mov L0x20017962 g201; mov L0x20017964 g202; mov L0x20017966 g203;
mov L0x20017968 g204; mov L0x2001796a g205; mov L0x2001796c g206;
mov L0x2001796e g207; mov L0x20017970 g208; mov L0x20017972 g209;
mov L0x20017974 g210; mov L0x20017976 g211; mov L0x20017978 g212;
mov L0x2001797a g213; mov L0x2001797c g214; mov L0x2001797e g215;
mov L0x20017980 g216; mov L0x20017982 g217; mov L0x20017984 g218;
mov L0x20017986 g219; mov L0x20017988 g220; mov L0x2001798a g221;
mov L0x2001798c g222; mov L0x2001798e g223; mov L0x20017990 g224;
mov L0x20017992 g225; mov L0x20017994 g226; mov L0x20017996 g227;
mov L0x20017998 g228; mov L0x2001799a g229; mov L0x2001799c g230;
mov L0x2001799e g231; mov L0x200179a0 g232; mov L0x200179a2 g233;
mov L0x200179a4 g234; mov L0x200179a6 g235; mov L0x200179a8 g236;
mov L0x200179aa g237; mov L0x200179ac g238; mov L0x200179ae g239;
mov L0x200179b0 g240; mov L0x200179b2 g241; mov L0x200179b4 g242;
mov L0x200179b6 g243; mov L0x200179b8 g244; mov L0x200179ba g245;
mov L0x200179bc g246; mov L0x200179be g247; mov L0x200179c0 g248;
mov L0x200179c2 g249; mov L0x200179c4 g250; mov L0x200179c6 g251;
mov L0x200179c8 g252; mov L0x200179ca g253; mov L0x200179cc g254;
mov L0x200179ce g255; mov L0x200179d0 g256; mov L0x200179d2 g257;
mov L0x200179d4 g258; mov L0x200179d6 g259; mov L0x200179d8 g260;
mov L0x200179da g261; mov L0x200179dc g262; mov L0x200179de g263;
mov L0x200179e0 g264; mov L0x200179e2 g265; mov L0x200179e4 g266;
mov L0x200179e6 g267; mov L0x200179e8 g268; mov L0x200179ea g269;
mov L0x200179ec g270; mov L0x200179ee g271; mov L0x200179f0 g272;
mov L0x200179f2 g273; mov L0x200179f4 g274; mov L0x200179f6 g275;
mov L0x200179f8 g276; mov L0x200179fa g277; mov L0x200179fc g278;
mov L0x200179fe g279; mov L0x20017a00 g280; mov L0x20017a02 g281;
mov L0x20017a04 g282; mov L0x20017a06 g283; mov L0x20017a08 g284;
mov L0x20017a0a g285; mov L0x20017a0c g286; mov L0x20017a0e g287;
mov L0x20017a10 g288; mov L0x20017a12 g289; mov L0x20017a14 g290;
mov L0x20017a16 g291; mov L0x20017a18 g292; mov L0x20017a1a g293;
mov L0x20017a1c g294; mov L0x20017a1e g295; mov L0x20017a20 g296;
mov L0x20017a22 g297; mov L0x20017a24 g298; mov L0x20017a26 g299;
mov L0x20017a28 g300; mov L0x20017a2a g301; mov L0x20017a2c g302;
mov L0x20017a2e g303; mov L0x20017a30 g304; mov L0x20017a32 g305;
mov L0x20017a34 g306; mov L0x20017a36 g307; mov L0x20017a38 g308;
mov L0x20017a3a g309; mov L0x20017a3c g310; mov L0x20017a3e g311;
mov L0x20017a40 g312; mov L0x20017a42 g313; mov L0x20017a44 g314;
mov L0x20017a46 g315; mov L0x20017a48 g316; mov L0x20017a4a g317;
mov L0x20017a4c g318; mov L0x20017a4e g319; mov L0x20017a50 g320;
mov L0x20017a52 g321; mov L0x20017a54 g322; mov L0x20017a56 g323;
mov L0x20017a58 g324; mov L0x20017a5a g325; mov L0x20017a5c g326;
mov L0x20017a5e g327; mov L0x20017a60 g328; mov L0x20017a62 g329;
mov L0x20017a64 g330; mov L0x20017a66 g331; mov L0x20017a68 g332;
mov L0x20017a6a g333; mov L0x20017a6c g334; mov L0x20017a6e g335;
mov L0x20017a70 g336; mov L0x20017a72 g337; mov L0x20017a74 g338;
mov L0x20017a76 g339; mov L0x20017a78 g340; mov L0x20017a7a g341;
mov L0x20017a7c g342; mov L0x20017a7e g343; mov L0x20017a80 g344;
mov L0x20017a82 g345; mov L0x20017a84 g346; mov L0x20017a86 g347;
mov L0x20017a88 g348; mov L0x20017a8a g349; mov L0x20017a8c g350;
mov L0x20017a8e g351; mov L0x20017a90 g352; mov L0x20017a92 g353;
mov L0x20017a94 g354; mov L0x20017a96 g355; mov L0x20017a98 g356;
mov L0x20017a9a g357; mov L0x20017a9c g358; mov L0x20017a9e g359;
mov L0x20017aa0 g360; mov L0x20017aa2 g361; mov L0x20017aa4 g362;
mov L0x20017aa6 g363; mov L0x20017aa8 g364; mov L0x20017aaa g365;
mov L0x20017aac g366; mov L0x20017aae g367; mov L0x20017ab0 g368;
mov L0x20017ab2 g369; mov L0x20017ab4 g370; mov L0x20017ab6 g371;
mov L0x20017ab8 g372; mov L0x20017aba g373; mov L0x20017abc g374;
mov L0x20017abe g375; mov L0x20017ac0 g376; mov L0x20017ac2 g377;
mov L0x20017ac4 g378; mov L0x20017ac6 g379; mov L0x20017ac8 g380;
mov L0x20017aca g381; mov L0x20017acc g382; mov L0x20017ace g383;
mov L0x20017ad0 g384; mov L0x20017ad2 g385; mov L0x20017ad4 g386;
mov L0x20017ad6 g387; mov L0x20017ad8 g388; mov L0x20017ada g389;
mov L0x20017adc g390; mov L0x20017ade g391; mov L0x20017ae0 g392;
mov L0x20017ae2 g393; mov L0x20017ae4 g394; mov L0x20017ae6 g395;
mov L0x20017ae8 g396; mov L0x20017aea g397; mov L0x20017aec g398;
mov L0x20017aee g399; mov L0x20017af0 g400; mov L0x20017af2 g401;
mov L0x20017af4 g402; mov L0x20017af6 g403; mov L0x20017af8 g404;
mov L0x20017afa g405; mov L0x20017afc g406; mov L0x20017afe g407;
mov L0x20017b00 g408; mov L0x20017b02 g409; mov L0x20017b04 g410;
mov L0x20017b06 g411; mov L0x20017b08 g412; mov L0x20017b0a g413;
mov L0x20017b0c g414; mov L0x20017b0e g415; mov L0x20017b10 g416;
mov L0x20017b12 g417; mov L0x20017b14 g418; mov L0x20017b16 g419;
mov L0x20017b18 g420; mov L0x20017b1a g421; mov L0x20017b1c g422;
mov L0x20017b1e g423; mov L0x20017b20 g424; mov L0x20017b22 g425;
mov L0x20017b24 g426; mov L0x20017b26 g427; mov L0x20017b28 g428;
mov L0x20017b2a g429; mov L0x20017b2c g430; mov L0x20017b2e g431;
mov L0x20017b30 g432; mov L0x20017b32 g433; mov L0x20017b34 g434;
mov L0x20017b36 g435; mov L0x20017b38 g436; mov L0x20017b3a g437;
mov L0x20017b3c g438; mov L0x20017b3e g439; mov L0x20017b40 g440;
mov L0x20017b42 g441; mov L0x20017b44 g442; mov L0x20017b46 g443;
mov L0x20017b48 g444; mov L0x20017b4a g445; mov L0x20017b4c g446;
mov L0x20017b4e g447; mov L0x20017b50 g448; mov L0x20017b52 g449;
mov L0x20017b54 g450; mov L0x20017b56 g451; mov L0x20017b58 g452;
mov L0x20017b5a g453; mov L0x20017b5c g454; mov L0x20017b5e g455;
mov L0x20017b60 g456; mov L0x20017b62 g457; mov L0x20017b64 g458;
mov L0x20017b66 g459; mov L0x20017b68 g460; mov L0x20017b6a g461;
mov L0x20017b6c g462; mov L0x20017b6e g463; mov L0x20017b70 g464;
mov L0x20017b72 g465; mov L0x20017b74 g466; mov L0x20017b76 g467;
mov L0x20017b78 g468; mov L0x20017b7a g469; mov L0x20017b7c g470;
mov L0x20017b7e g471; mov L0x20017b80 g472; mov L0x20017b82 g473;
mov L0x20017b84 g474; mov L0x20017b86 g475; mov L0x20017b88 g476;
mov L0x20017b8a g477; mov L0x20017b8c g478; mov L0x20017b8e g479;
mov L0x20017b90 g480; mov L0x20017b92 g481; mov L0x20017b94 g482;
mov L0x20017b96 g483; mov L0x20017b98 g484; mov L0x20017b9a g485;
mov L0x20017b9c g486; mov L0x20017b9e g487; mov L0x20017ba0 g488;
mov L0x20017ba2 g489; mov L0x20017ba4 g490; mov L0x20017ba6 g491;
mov L0x20017ba8 g492; mov L0x20017baa g493; mov L0x20017bac g494;
mov L0x20017bae g495; mov L0x20017bb0 g496; mov L0x20017bb2 g497;
mov L0x20017bb4 g498; mov L0x20017bb6 g499; mov L0x20017bb8 g500;
mov L0x20017bba g501; mov L0x20017bbc g502; mov L0x20017bbe g503;
mov L0x20017bc0 g504; mov L0x20017bc2 g505; mov L0x20017bc4 g506;
mov L0x20017bc6 g507; mov L0x20017bc8 g508;



(**************** pointers ****************)

nondet lr@uint32; nondet r0@uint32;



(**************** input poly ****************)

ghost x@bit, inp_poly@bit,
inp_poly_0@bit, inp_poly_1@bit, inp_poly_2@bit, inp_poly_3@bit,
inp_poly_4@bit, inp_poly_5@bit, inp_poly_6@bit, inp_poly_7@bit :
and [
inp_poly_0**2 = 
g000*(x**0)+g001*(x**1)+g002*(x**2)+g003*(x**3)+g004*(x**4)+
g005*(x**5)+g006*(x**6)+g007*(x**7)+g008*(x**8)+g009*(x**9)+
g010*(x**10)+g011*(x**11)+g012*(x**12)+g013*(x**13)+g014*(x**14)+
g015*(x**15)+g016*(x**16)+g017*(x**17)+g018*(x**18)+g019*(x**19)+
g020*(x**20)+g021*(x**21)+g022*(x**22)+g023*(x**23)+g024*(x**24)+
g025*(x**25)+g026*(x**26)+g027*(x**27)+g028*(x**28)+g029*(x**29)+
g030*(x**30)+g031*(x**31)+g032*(x**32)+g033*(x**33)+g034*(x**34)+
g035*(x**35)+g036*(x**36)+g037*(x**37)+g038*(x**38)+g039*(x**39)+
g040*(x**40)+g041*(x**41)+g042*(x**42)+g043*(x**43)+g044*(x**44)+
g045*(x**45)+g046*(x**46)+g047*(x**47)+g048*(x**48)+g049*(x**49)+
g050*(x**50)+g051*(x**51)+g052*(x**52)+g053*(x**53)+g054*(x**54)+
g055*(x**55)+g056*(x**56)+g057*(x**57)+g058*(x**58)+g059*(x**59)+
g060*(x**60)+g061*(x**61)+g062*(x**62)+g063*(x**63),
inp_poly_1**2 = 
g064*(x**0)+g065*(x**1)+g066*(x**2)+g067*(x**3)+g068*(x**4)+
g069*(x**5)+g070*(x**6)+g071*(x**7)+g072*(x**8)+g073*(x**9)+
g074*(x**10)+g075*(x**11)+g076*(x**12)+g077*(x**13)+g078*(x**14)+
g079*(x**15)+g080*(x**16)+g081*(x**17)+g082*(x**18)+g083*(x**19)+
g084*(x**20)+g085*(x**21)+g086*(x**22)+g087*(x**23)+g088*(x**24)+
g089*(x**25)+g090*(x**26)+g091*(x**27)+g092*(x**28)+g093*(x**29)+
g094*(x**30)+g095*(x**31)+g096*(x**32)+g097*(x**33)+g098*(x**34)+
g099*(x**35)+g100*(x**36)+g101*(x**37)+g102*(x**38)+g103*(x**39)+
g104*(x**40)+g105*(x**41)+g106*(x**42)+g107*(x**43)+g108*(x**44)+
g109*(x**45)+g110*(x**46)+g111*(x**47)+g112*(x**48)+g113*(x**49)+
g114*(x**50)+g115*(x**51)+g116*(x**52)+g117*(x**53)+g118*(x**54)+
g119*(x**55)+g120*(x**56)+g121*(x**57)+g122*(x**58)+g123*(x**59)+
g124*(x**60)+g125*(x**61)+g126*(x**62)+g127*(x**63),
inp_poly_2**2 = 
g128*(x**0)+g129*(x**1)+g130*(x**2)+g131*(x**3)+g132*(x**4)+
g133*(x**5)+g134*(x**6)+g135*(x**7)+g136*(x**8)+g137*(x**9)+
g138*(x**10)+g139*(x**11)+g140*(x**12)+g141*(x**13)+g142*(x**14)+
g143*(x**15)+g144*(x**16)+g145*(x**17)+g146*(x**18)+g147*(x**19)+
g148*(x**20)+g149*(x**21)+g150*(x**22)+g151*(x**23)+g152*(x**24)+
g153*(x**25)+g154*(x**26)+g155*(x**27)+g156*(x**28)+g157*(x**29)+
g158*(x**30)+g159*(x**31)+g160*(x**32)+g161*(x**33)+g162*(x**34)+
g163*(x**35)+g164*(x**36)+g165*(x**37)+g166*(x**38)+g167*(x**39)+
g168*(x**40)+g169*(x**41)+g170*(x**42)+g171*(x**43)+g172*(x**44)+
g173*(x**45)+g174*(x**46)+g175*(x**47)+g176*(x**48)+g177*(x**49)+
g178*(x**50)+g179*(x**51)+g180*(x**52)+g181*(x**53)+g182*(x**54)+
g183*(x**55)+g184*(x**56)+g185*(x**57)+g186*(x**58)+g187*(x**59)+
g188*(x**60)+g189*(x**61)+g190*(x**62)+g191*(x**63),
inp_poly_3**2 = 
g192*(x**0)+g193*(x**1)+g194*(x**2)+g195*(x**3)+g196*(x**4)+
g197*(x**5)+g198*(x**6)+g199*(x**7)+g200*(x**8)+g201*(x**9)+
g202*(x**10)+g203*(x**11)+g204*(x**12)+g205*(x**13)+g206*(x**14)+
g207*(x**15)+g208*(x**16)+g209*(x**17)+g210*(x**18)+g211*(x**19)+
g212*(x**20)+g213*(x**21)+g214*(x**22)+g215*(x**23)+g216*(x**24)+
g217*(x**25)+g218*(x**26)+g219*(x**27)+g220*(x**28)+g221*(x**29)+
g222*(x**30)+g223*(x**31)+g224*(x**32)+g225*(x**33)+g226*(x**34)+
g227*(x**35)+g228*(x**36)+g229*(x**37)+g230*(x**38)+g231*(x**39)+
g232*(x**40)+g233*(x**41)+g234*(x**42)+g235*(x**43)+g236*(x**44)+
g237*(x**45)+g238*(x**46)+g239*(x**47)+g240*(x**48)+g241*(x**49)+
g242*(x**50)+g243*(x**51)+g244*(x**52)+g245*(x**53)+g246*(x**54)+
g247*(x**55)+g248*(x**56)+g249*(x**57)+g250*(x**58)+g251*(x**59)+
g252*(x**60)+g253*(x**61)+g254*(x**62)+g255*(x**63),
inp_poly_4**2 = 
g256*(x**0)+g257*(x**1)+g258*(x**2)+g259*(x**3)+g260*(x**4)+
g261*(x**5)+g262*(x**6)+g263*(x**7)+g264*(x**8)+g265*(x**9)+
g266*(x**10)+g267*(x**11)+g268*(x**12)+g269*(x**13)+g270*(x**14)+
g271*(x**15)+g272*(x**16)+g273*(x**17)+g274*(x**18)+g275*(x**19)+
g276*(x**20)+g277*(x**21)+g278*(x**22)+g279*(x**23)+g280*(x**24)+
g281*(x**25)+g282*(x**26)+g283*(x**27)+g284*(x**28)+g285*(x**29)+
g286*(x**30)+g287*(x**31)+g288*(x**32)+g289*(x**33)+g290*(x**34)+
g291*(x**35)+g292*(x**36)+g293*(x**37)+g294*(x**38)+g295*(x**39)+
g296*(x**40)+g297*(x**41)+g298*(x**42)+g299*(x**43)+g300*(x**44)+
g301*(x**45)+g302*(x**46)+g303*(x**47)+g304*(x**48)+g305*(x**49)+
g306*(x**50)+g307*(x**51)+g308*(x**52)+g309*(x**53)+g310*(x**54)+
g311*(x**55)+g312*(x**56)+g313*(x**57)+g314*(x**58)+g315*(x**59)+
g316*(x**60)+g317*(x**61)+g318*(x**62)+g319*(x**63),
inp_poly_5**2 = 
g320*(x**0)+g321*(x**1)+g322*(x**2)+g323*(x**3)+g324*(x**4)+
g325*(x**5)+g326*(x**6)+g327*(x**7)+g328*(x**8)+g329*(x**9)+
g330*(x**10)+g331*(x**11)+g332*(x**12)+g333*(x**13)+g334*(x**14)+
g335*(x**15)+g336*(x**16)+g337*(x**17)+g338*(x**18)+g339*(x**19)+
g340*(x**20)+g341*(x**21)+g342*(x**22)+g343*(x**23)+g344*(x**24)+
g345*(x**25)+g346*(x**26)+g347*(x**27)+g348*(x**28)+g349*(x**29)+
g350*(x**30)+g351*(x**31)+g352*(x**32)+g353*(x**33)+g354*(x**34)+
g355*(x**35)+g356*(x**36)+g357*(x**37)+g358*(x**38)+g359*(x**39)+
g360*(x**40)+g361*(x**41)+g362*(x**42)+g363*(x**43)+g364*(x**44)+
g365*(x**45)+g366*(x**46)+g367*(x**47)+g368*(x**48)+g369*(x**49)+
g370*(x**50)+g371*(x**51)+g372*(x**52)+g373*(x**53)+g374*(x**54)+
g375*(x**55)+g376*(x**56)+g377*(x**57)+g378*(x**58)+g379*(x**59)+
g380*(x**60)+g381*(x**61)+g382*(x**62)+g383*(x**63),
inp_poly_6**2 = 
g384*(x**0)+g385*(x**1)+g386*(x**2)+g387*(x**3)+g388*(x**4)+
g389*(x**5)+g390*(x**6)+g391*(x**7)+g392*(x**8)+g393*(x**9)+
g394*(x**10)+g395*(x**11)+g396*(x**12)+g397*(x**13)+g398*(x**14)+
g399*(x**15)+g400*(x**16)+g401*(x**17)+g402*(x**18)+g403*(x**19)+
g404*(x**20)+g405*(x**21)+g406*(x**22)+g407*(x**23)+g408*(x**24)+
g409*(x**25)+g410*(x**26)+g411*(x**27)+g412*(x**28)+g413*(x**29)+
g414*(x**30)+g415*(x**31)+g416*(x**32)+g417*(x**33)+g418*(x**34)+
g419*(x**35)+g420*(x**36)+g421*(x**37)+g422*(x**38)+g423*(x**39)+
g424*(x**40)+g425*(x**41)+g426*(x**42)+g427*(x**43)+g428*(x**44)+
g429*(x**45)+g430*(x**46)+g431*(x**47)+g432*(x**48)+g433*(x**49)+
g434*(x**50)+g435*(x**51)+g436*(x**52)+g437*(x**53)+g438*(x**54)+
g439*(x**55)+g440*(x**56)+g441*(x**57)+g442*(x**58)+g443*(x**59)+
g444*(x**60)+g445*(x**61)+g446*(x**62)+g447*(x**63),
inp_poly_7**2 = 
g448*(x**0)+g449*(x**1)+g450*(x**2)+g451*(x**3)+g452*(x**4)+
g453*(x**5)+g454*(x**6)+g455*(x**7)+g456*(x**8)+g457*(x**9)+
g458*(x**10)+g459*(x**11)+g460*(x**12)+g461*(x**13)+g462*(x**14)+
g463*(x**15)+g464*(x**16)+g465*(x**17)+g466*(x**18)+g467*(x**19)+
g468*(x**20)+g469*(x**21)+g470*(x**22)+g471*(x**23)+g472*(x**24)+
g473*(x**25)+g474*(x**26)+g475*(x**27)+g476*(x**28)+g477*(x**29)+
g478*(x**30)+g479*(x**31)+g480*(x**32)+g481*(x**33)+g482*(x**34)+
g483*(x**35)+g484*(x**36)+g485*(x**37)+g486*(x**38)+g487*(x**39)+
g488*(x**40)+g489*(x**41)+g490*(x**42)+g491*(x**43)+g492*(x**44)+
g493*(x**45)+g494*(x**46)+g495*(x**47)+g496*(x**48)+g497*(x**49)+
g498*(x**50)+g499*(x**51)+g500*(x**52)+g501*(x**53)+g502*(x**54)+
g503*(x**55)+g504*(x**56)+g505*(x**57)+g506*(x**58)+g507*(x**59)+
g508*(x**60),
inp_poly**2 = 
(inp_poly_0**2)*(x**0)+(inp_poly_1**2)*(x**64)+(inp_poly_2**2)*(x**128)+
(inp_poly_3**2)*(x**192)+(inp_poly_4**2)*(x**256)+(inp_poly_5**2)*(x**320)+
(inp_poly_6**2)*(x**384)+(inp_poly_7**2)*(x**448)
] && true;



(**************** constants ****************)

mov L0x80071d8 (      1)@sint32; mov L0x80071dc (      1)@sint32;
mov L0x80071e0 (-489046)@sint32; mov L0x80071e4 (      1)@sint32;
mov L0x80071e8 (-489046)@sint32; mov L0x80071ec ( 287998)@sint32;
mov L0x80071f0 (-324180)@sint32; mov L0x80071f4 (  78830)@sint32;
mov L0x80071f8 ( 191052)@sint32; mov L0x80071fc (-311503)@sint32;
mov L0x8007200 ( 207751)@sint32; mov L0x8007204 ( 468028)@sint32;
mov L0x8007208 (-149945)@sint32; mov L0x800720c ( 114478)@sint32;
mov L0x8007210 ( -82425)@sint32;

(* #! -> SP = 0x20016fb0 *)
#! 0x20016fb0 = 0x20016fb0;
(* #stmdb	sp!, {r4, r5, r6, r7, r8, r9, r10, r11, r12, lr}#! EA = L0x20016fb0; PC = 0x8001024 *)
#stmdb	sp!, {%%r4, %%r5, %%r6, %%r7, %%r8, %%r9, %%r10, %%r11, %%r12, %%lr}#! L0x20016fb0 = L0x20016fb0; 0x8001024 = 0x8001024;
(* #vpush	{s16-s31}                                 #! PC = 0x8001028 *)
#vpush	{%%s16-%%s31}                                 #! 0x8001028 = 0x8001028;
(* #ldr.w	lr, [sp, #104]	; 0x68                     #! EA = L0x20016fb0; Value = 0x200177d0; PC = 0x800102c *)
#ldr.w	%%lr, [sp, #104]	; 0x68                     #! L0x20016fb0 = L0x20016fb0; 0x200177d0 = 0x200177d0; 0x800102c = 0x800102c;
(* vldmia	r1!, {s4-s18}                             #! EA = L0x80071d8; PC = 0x8001030 *)
mov s4 L0x80071d8;
mov s5 L0x80071dc;
mov s6 L0x80071e0;
mov s7 L0x80071e4;
mov s8 L0x80071e8;
mov s9 L0x80071ec;
mov s10 L0x80071f0;
mov s11 L0x80071f4;
mov s12 L0x80071f8;
mov s13 L0x80071fc;
mov s14 L0x8007200;
mov s15 L0x8007204;
mov s16 L0x8007208;
mov s17 L0x800720c;
mov s18 L0x8007210;
(* vmov	s0, lr                                     #! PC = 0x8001034 *)
mov s0 lr;
(* add.w	r12, r0, #244	; 0xf4                      #! PC = 0x8001038 *)
adds dontcare r12 r0 244@uint32;
(* vmov	s2, r12                                    #! PC = 0x800103c *)
mov s2 r12;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017850; Value = 0x00010000; PC = 0x8001044 *)
mov r4 L0x20017850;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017950; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x20017950;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a50; Value = 0x00000001; PC = 0x800104c *)
mov r6 L0x20017a50;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b50; Value = 0x00010001; PC = 0x8001050 *)
mov r7 L0x20017b50;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178d0; Value = 0xffff0000; PC = 0x8001134 *)
mov r5 L0x200178d0;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179d0; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x200179d0;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ad0; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017ad0;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177d0; Value = 0xffffffff; PC = 0x8001140 *)
mov r4 L0x200177d0;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7d0; PC = 0x80011bc *)
mov L0x2001a7d0 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8d0; PC = 0x80011c0 *)
mov L0x2001a8d0 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9d0; PC = 0x80011c4 *)
mov L0x2001a9d0 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aad0; PC = 0x80011c8 *)
mov L0x2001aad0 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abd0; PC = 0x80011cc *)
mov L0x2001abd0 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acd0; PC = 0x80011d0 *)
mov L0x2001acd0 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001add0; PC = 0x80011d4 *)
mov L0x2001add0 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aed0; PC = 0x80011d8 *)
mov L0x2001aed0 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3d0; PC = 0x8001204 *)
mov L0x2001a3d0 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4d0; PC = 0x8001208 *)
mov L0x2001a4d0 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5d0; PC = 0x800120c *)
mov L0x2001a5d0 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6d0; PC = 0x8001210 *)
mov L0x2001a6d0 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0d0; PC = 0x8001214 *)
mov L0x2001a0d0 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1d0; PC = 0x8001218 *)
mov L0x2001a1d0 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2d0; PC = 0x800121c *)
mov L0x2001a2d0 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019fd0; PC = 0x8001220 *)
mov L0x20019fd0 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017852; Value = 0x00000001; PC = 0x8001044 *)
mov r4 L0x20017852;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017952; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x20017952;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a52; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017a52;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b52; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017b52;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178d2; Value = 0x0000ffff; PC = 0x8001134 *)
mov r5 L0x200178d2;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179d2; Value = 0x0001ffff; PC = 0x8001138 *)
mov r6 L0x200179d2;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ad2; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017ad2;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177d2; Value = 0x0001ffff; PC = 0x8001140 *)
mov r4 L0x200177d2;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7d4; PC = 0x80011bc *)
mov L0x2001a7d4 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8d4; PC = 0x80011c0 *)
mov L0x2001a8d4 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9d4; PC = 0x80011c4 *)
mov L0x2001a9d4 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aad4; PC = 0x80011c8 *)
mov L0x2001aad4 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abd4; PC = 0x80011cc *)
mov L0x2001abd4 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acd4; PC = 0x80011d0 *)
mov L0x2001acd4 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001add4; PC = 0x80011d4 *)
mov L0x2001add4 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aed4; PC = 0x80011d8 *)
mov L0x2001aed4 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3d4; PC = 0x8001204 *)
mov L0x2001a3d4 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4d4; PC = 0x8001208 *)
mov L0x2001a4d4 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5d4; PC = 0x800120c *)
mov L0x2001a5d4 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6d4; PC = 0x8001210 *)
mov L0x2001a6d4 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0d4; PC = 0x8001214 *)
mov L0x2001a0d4 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1d4; PC = 0x8001218 *)
mov L0x2001a1d4 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2d4; PC = 0x800121c *)
mov L0x2001a2d4 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019fd4; PC = 0x8001220 *)
mov L0x20019fd4 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017854; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x20017854;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017954; Value = 0x00010000; PC = 0x8001048 *)
mov r5 L0x20017954;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a54; Value = 0x0001ffff; PC = 0x800104c *)
mov r6 L0x20017a54;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b54; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017b54;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178d4; Value = 0x00010000; PC = 0x8001134 *)
mov r5 L0x200178d4;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179d4; Value = 0x00010001; PC = 0x8001138 *)
mov r6 L0x200179d4;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ad4; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017ad4;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177d4; Value = 0x00010001; PC = 0x8001140 *)
mov r4 L0x200177d4;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7d8; PC = 0x80011bc *)
mov L0x2001a7d8 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8d8; PC = 0x80011c0 *)
mov L0x2001a8d8 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9d8; PC = 0x80011c4 *)
mov L0x2001a9d8 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aad8; PC = 0x80011c8 *)
mov L0x2001aad8 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abd8; PC = 0x80011cc *)
mov L0x2001abd8 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acd8; PC = 0x80011d0 *)
mov L0x2001acd8 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001add8; PC = 0x80011d4 *)
mov L0x2001add8 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aed8; PC = 0x80011d8 *)
mov L0x2001aed8 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3d8; PC = 0x8001204 *)
mov L0x2001a3d8 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4d8; PC = 0x8001208 *)
mov L0x2001a4d8 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5d8; PC = 0x800120c *)
mov L0x2001a5d8 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6d8; PC = 0x8001210 *)
mov L0x2001a6d8 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0d8; PC = 0x8001214 *)
mov L0x2001a0d8 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1d8; PC = 0x8001218 *)
mov L0x2001a1d8 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2d8; PC = 0x800121c *)
mov L0x2001a2d8 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019fd8; PC = 0x8001220 *)
mov L0x20019fd8 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017856; Value = 0x0000ffff; PC = 0x8001044 *)
mov r4 L0x20017856;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017956; Value = 0x00010001; PC = 0x8001048 *)
mov r5 L0x20017956;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a56; Value = 0x00000001; PC = 0x800104c *)
mov r6 L0x20017a56;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b56; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017b56;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178d6; Value = 0xffff0001; PC = 0x8001134 *)
mov r5 L0x200178d6;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179d6; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x200179d6;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ad6; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017ad6;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177d6; Value = 0x00010001; PC = 0x8001140 *)
mov r4 L0x200177d6;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7dc; PC = 0x80011bc *)
mov L0x2001a7dc r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8dc; PC = 0x80011c0 *)
mov L0x2001a8dc r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9dc; PC = 0x80011c4 *)
mov L0x2001a9dc r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aadc; PC = 0x80011c8 *)
mov L0x2001aadc r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abdc; PC = 0x80011cc *)
mov L0x2001abdc r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acdc; PC = 0x80011d0 *)
mov L0x2001acdc r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001addc; PC = 0x80011d4 *)
mov L0x2001addc r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aedc; PC = 0x80011d8 *)
mov L0x2001aedc r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3dc; PC = 0x8001204 *)
mov L0x2001a3dc r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4dc; PC = 0x8001208 *)
mov L0x2001a4dc r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5dc; PC = 0x800120c *)
mov L0x2001a5dc r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6dc; PC = 0x8001210 *)
mov L0x2001a6dc r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0dc; PC = 0x8001214 *)
mov L0x2001a0dc r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1dc; PC = 0x8001218 *)
mov L0x2001a1dc r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2dc; PC = 0x800121c *)
mov L0x2001a2dc r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019fdc; PC = 0x8001220 *)
mov L0x20019fdc r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017858; Value = 0x00010000; PC = 0x8001044 *)
mov r4 L0x20017858;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017958; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x20017958;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a58; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017a58;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b58; Value = 0x0001ffff; PC = 0x8001050 *)
mov r7 L0x20017b58;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178d8; Value = 0x0001ffff; PC = 0x8001134 *)
mov r5 L0x200178d8;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179d8; Value = 0xffffffff; PC = 0x8001138 *)
mov r6 L0x200179d8;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ad8; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017ad8;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177d8; Value = 0xffff0001; PC = 0x8001140 *)
mov r4 L0x200177d8;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7e0; PC = 0x80011bc *)
mov L0x2001a7e0 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8e0; PC = 0x80011c0 *)
mov L0x2001a8e0 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9e0; PC = 0x80011c4 *)
mov L0x2001a9e0 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aae0; PC = 0x80011c8 *)
mov L0x2001aae0 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abe0; PC = 0x80011cc *)
mov L0x2001abe0 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ace0; PC = 0x80011d0 *)
mov L0x2001ace0 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ade0; PC = 0x80011d4 *)
mov L0x2001ade0 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aee0; PC = 0x80011d8 *)
mov L0x2001aee0 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3e0; PC = 0x8001204 *)
mov L0x2001a3e0 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4e0; PC = 0x8001208 *)
mov L0x2001a4e0 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5e0; PC = 0x800120c *)
mov L0x2001a5e0 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6e0; PC = 0x8001210 *)
mov L0x2001a6e0 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0e0; PC = 0x8001214 *)
mov L0x2001a0e0 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1e0; PC = 0x8001218 *)
mov L0x2001a1e0 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2e0; PC = 0x800121c *)
mov L0x2001a2e0 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019fe0; PC = 0x8001220 *)
mov L0x20019fe0 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001785a; Value = 0xffff0001; PC = 0x8001044 *)
mov r4 L0x2001785a;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001795a; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x2001795a;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a5a; Value = 0x0001ffff; PC = 0x800104c *)
mov r6 L0x20017a5a;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b5a; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017b5a;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178da; Value = 0xffff0001; PC = 0x8001134 *)
mov r5 L0x200178da;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179da; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x200179da;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ada; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017ada;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177da; Value = 0x0000ffff; PC = 0x8001140 *)
mov r4 L0x200177da;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7e4; PC = 0x80011bc *)
mov L0x2001a7e4 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8e4; PC = 0x80011c0 *)
mov L0x2001a8e4 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9e4; PC = 0x80011c4 *)
mov L0x2001a9e4 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aae4; PC = 0x80011c8 *)
mov L0x2001aae4 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abe4; PC = 0x80011cc *)
mov L0x2001abe4 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ace4; PC = 0x80011d0 *)
mov L0x2001ace4 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ade4; PC = 0x80011d4 *)
mov L0x2001ade4 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aee4; PC = 0x80011d8 *)
mov L0x2001aee4 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3e4; PC = 0x8001204 *)
mov L0x2001a3e4 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4e4; PC = 0x8001208 *)
mov L0x2001a4e4 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5e4; PC = 0x800120c *)
mov L0x2001a5e4 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6e4; PC = 0x8001210 *)
mov L0x2001a6e4 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0e4; PC = 0x8001214 *)
mov L0x2001a0e4 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1e4; PC = 0x8001218 *)
mov L0x2001a1e4 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2e4; PC = 0x800121c *)
mov L0x2001a2e4 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019fe4; PC = 0x8001220 *)
mov L0x20019fe4 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001785c; Value = 0x0001ffff; PC = 0x8001044 *)
mov r4 L0x2001785c;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001795c; Value = 0x00010000; PC = 0x8001048 *)
mov r5 L0x2001795c;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a5c; Value = 0x00010001; PC = 0x800104c *)
mov r6 L0x20017a5c;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b5c; Value = 0x0000ffff; PC = 0x8001050 *)
mov r7 L0x20017b5c;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178dc; Value = 0x0000ffff; PC = 0x8001134 *)
mov r5 L0x200178dc;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179dc; Value = 0xffff0000; PC = 0x8001138 *)
mov r6 L0x200179dc;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017adc; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017adc;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177dc; Value = 0x00010000; PC = 0x8001140 *)
mov r4 L0x200177dc;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7e8; PC = 0x80011bc *)
mov L0x2001a7e8 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8e8; PC = 0x80011c0 *)
mov L0x2001a8e8 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9e8; PC = 0x80011c4 *)
mov L0x2001a9e8 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aae8; PC = 0x80011c8 *)
mov L0x2001aae8 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abe8; PC = 0x80011cc *)
mov L0x2001abe8 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ace8; PC = 0x80011d0 *)
mov L0x2001ace8 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ade8; PC = 0x80011d4 *)
mov L0x2001ade8 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aee8; PC = 0x80011d8 *)
mov L0x2001aee8 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3e8; PC = 0x8001204 *)
mov L0x2001a3e8 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4e8; PC = 0x8001208 *)
mov L0x2001a4e8 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5e8; PC = 0x800120c *)
mov L0x2001a5e8 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6e8; PC = 0x8001210 *)
mov L0x2001a6e8 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0e8; PC = 0x8001214 *)
mov L0x2001a0e8 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1e8; PC = 0x8001218 *)
mov L0x2001a1e8 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2e8; PC = 0x800121c *)
mov L0x2001a2e8 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019fe8; PC = 0x8001220 *)
mov L0x20019fe8 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001785e; Value = 0xffff0001; PC = 0x8001044 *)
mov r4 L0x2001785e;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001795e; Value = 0x00000001; PC = 0x8001048 *)
mov r5 L0x2001795e;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a5e; Value = 0xffff0001; PC = 0x800104c *)
mov r6 L0x20017a5e;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b5e; Value = 0xffff0000; PC = 0x8001050 *)
mov r7 L0x20017b5e;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178de; Value = 0x00000000; PC = 0x8001134 *)
mov r5 L0x200178de;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179de; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x200179de;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ade; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017ade;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177de; Value = 0x00010001; PC = 0x8001140 *)
mov r4 L0x200177de;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7ec; PC = 0x80011bc *)
mov L0x2001a7ec r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8ec; PC = 0x80011c0 *)
mov L0x2001a8ec r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9ec; PC = 0x80011c4 *)
mov L0x2001a9ec r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aaec; PC = 0x80011c8 *)
mov L0x2001aaec r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abec; PC = 0x80011cc *)
mov L0x2001abec r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acec; PC = 0x80011d0 *)
mov L0x2001acec r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001adec; PC = 0x80011d4 *)
mov L0x2001adec r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aeec; PC = 0x80011d8 *)
mov L0x2001aeec r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3ec; PC = 0x8001204 *)
mov L0x2001a3ec r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4ec; PC = 0x8001208 *)
mov L0x2001a4ec r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5ec; PC = 0x800120c *)
mov L0x2001a5ec r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6ec; PC = 0x8001210 *)
mov L0x2001a6ec r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0ec; PC = 0x8001214 *)
mov L0x2001a0ec r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1ec; PC = 0x8001218 *)
mov L0x2001a1ec r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2ec; PC = 0x800121c *)
mov L0x2001a2ec r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019fec; PC = 0x8001220 *)
mov L0x20019fec r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017860; Value = 0x0001ffff; PC = 0x8001044 *)
mov r4 L0x20017860;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017960; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x20017960;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a60; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017a60;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b60; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017b60;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178e0; Value = 0x00000000; PC = 0x8001134 *)
mov r5 L0x200178e0;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179e0; Value = 0x00000000; PC = 0x8001138 *)
mov r6 L0x200179e0;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ae0; Value = 0xffff0000; PC = 0x800113c *)
mov r7 L0x20017ae0;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177e0; Value = 0xffff0001; PC = 0x8001140 *)
mov r4 L0x200177e0;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7f0; PC = 0x80011bc *)
mov L0x2001a7f0 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8f0; PC = 0x80011c0 *)
mov L0x2001a8f0 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9f0; PC = 0x80011c4 *)
mov L0x2001a9f0 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aaf0; PC = 0x80011c8 *)
mov L0x2001aaf0 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abf0; PC = 0x80011cc *)
mov L0x2001abf0 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acf0; PC = 0x80011d0 *)
mov L0x2001acf0 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001adf0; PC = 0x80011d4 *)
mov L0x2001adf0 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aef0; PC = 0x80011d8 *)
mov L0x2001aef0 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3f0; PC = 0x8001204 *)
mov L0x2001a3f0 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4f0; PC = 0x8001208 *)
mov L0x2001a4f0 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5f0; PC = 0x800120c *)
mov L0x2001a5f0 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6f0; PC = 0x8001210 *)
mov L0x2001a6f0 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0f0; PC = 0x8001214 *)
mov L0x2001a0f0 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1f0; PC = 0x8001218 *)
mov L0x2001a1f0 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2f0; PC = 0x800121c *)
mov L0x2001a2f0 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019ff0; PC = 0x8001220 *)
mov L0x20019ff0 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017862; Value = 0xffff0001; PC = 0x8001044 *)
mov r4 L0x20017862;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017962; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x20017962;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a62; Value = 0x00000000; PC = 0x800104c *)
mov r6 L0x20017a62;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b62; Value = 0x0001ffff; PC = 0x8001050 *)
mov r7 L0x20017b62;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178e2; Value = 0xffff0000; PC = 0x8001134 *)
mov r5 L0x200178e2;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179e2; Value = 0x00010000; PC = 0x8001138 *)
mov r6 L0x200179e2;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ae2; Value = 0x0000ffff; PC = 0x800113c *)
mov r7 L0x20017ae2;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177e2; Value = 0x0000ffff; PC = 0x8001140 *)
mov r4 L0x200177e2;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7f4; PC = 0x80011bc *)
mov L0x2001a7f4 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8f4; PC = 0x80011c0 *)
mov L0x2001a8f4 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9f4; PC = 0x80011c4 *)
mov L0x2001a9f4 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aaf4; PC = 0x80011c8 *)
mov L0x2001aaf4 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abf4; PC = 0x80011cc *)
mov L0x2001abf4 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acf4; PC = 0x80011d0 *)
mov L0x2001acf4 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001adf4; PC = 0x80011d4 *)
mov L0x2001adf4 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aef4; PC = 0x80011d8 *)
mov L0x2001aef4 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3f4; PC = 0x8001204 *)
mov L0x2001a3f4 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4f4; PC = 0x8001208 *)
mov L0x2001a4f4 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5f4; PC = 0x800120c *)
mov L0x2001a5f4 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6f4; PC = 0x8001210 *)
mov L0x2001a6f4 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0f4; PC = 0x8001214 *)
mov L0x2001a0f4 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1f4; PC = 0x8001218 *)
mov L0x2001a1f4 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2f4; PC = 0x800121c *)
mov L0x2001a2f4 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019ff4; PC = 0x8001220 *)
mov L0x20019ff4 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017864; Value = 0xffffffff; PC = 0x8001044 *)
mov r4 L0x20017864;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017964; Value = 0xffff0000; PC = 0x8001048 *)
mov r5 L0x20017964;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a64; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017a64;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b64; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017b64;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178e4; Value = 0x0000ffff; PC = 0x8001134 *)
mov r5 L0x200178e4;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179e4; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x200179e4;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ae4; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017ae4;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177e4; Value = 0x00010000; PC = 0x8001140 *)
mov r4 L0x200177e4;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7f8; PC = 0x80011bc *)
mov L0x2001a7f8 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8f8; PC = 0x80011c0 *)
mov L0x2001a8f8 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9f8; PC = 0x80011c4 *)
mov L0x2001a9f8 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aaf8; PC = 0x80011c8 *)
mov L0x2001aaf8 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abf8; PC = 0x80011cc *)
mov L0x2001abf8 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acf8; PC = 0x80011d0 *)
mov L0x2001acf8 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001adf8; PC = 0x80011d4 *)
mov L0x2001adf8 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aef8; PC = 0x80011d8 *)
mov L0x2001aef8 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3f8; PC = 0x8001204 *)
mov L0x2001a3f8 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4f8; PC = 0x8001208 *)
mov L0x2001a4f8 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5f8; PC = 0x800120c *)
mov L0x2001a5f8 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6f8; PC = 0x8001210 *)
mov L0x2001a6f8 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0f8; PC = 0x8001214 *)
mov L0x2001a0f8 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1f8; PC = 0x8001218 *)
mov L0x2001a1f8 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2f8; PC = 0x800121c *)
mov L0x2001a2f8 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019ff8; PC = 0x8001220 *)
mov L0x20019ff8 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017866; Value = 0x0000ffff; PC = 0x8001044 *)
mov r4 L0x20017866;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017966; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x20017966;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a66; Value = 0x0001ffff; PC = 0x800104c *)
mov r6 L0x20017a66;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b66; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017b66;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178e6; Value = 0x00010000; PC = 0x8001134 *)
mov r5 L0x200178e6;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179e6; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x200179e6;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ae6; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017ae6;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177e6; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x200177e6;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a7fc; PC = 0x80011bc *)
mov L0x2001a7fc r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a8fc; PC = 0x80011c0 *)
mov L0x2001a8fc r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001a9fc; PC = 0x80011c4 *)
mov L0x2001a9fc r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aafc; PC = 0x80011c8 *)
mov L0x2001aafc r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001abfc; PC = 0x80011cc *)
mov L0x2001abfc r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001acfc; PC = 0x80011d0 *)
mov L0x2001acfc r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001adfc; PC = 0x80011d4 *)
mov L0x2001adfc r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001aefc; PC = 0x80011d8 *)
mov L0x2001aefc r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a3fc; PC = 0x8001204 *)
mov L0x2001a3fc r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a4fc; PC = 0x8001208 *)
mov L0x2001a4fc r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a5fc; PC = 0x800120c *)
mov L0x2001a5fc r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a6fc; PC = 0x8001210 *)
mov L0x2001a6fc r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a0fc; PC = 0x8001214 *)
mov L0x2001a0fc r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a1fc; PC = 0x8001218 *)
mov L0x2001a1fc r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a2fc; PC = 0x800121c *)
mov L0x2001a2fc r5;
(* str.w	r8, [r0], #4                              #! EA = L0x20019ffc; PC = 0x8001220 *)
mov L0x20019ffc r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017868; Value = 0x00010000; PC = 0x8001044 *)
mov r4 L0x20017868;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017968; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x20017968;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a68; Value = 0xffff0001; PC = 0x800104c *)
mov r6 L0x20017a68;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b68; Value = 0x0001ffff; PC = 0x8001050 *)
mov r7 L0x20017b68;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178e8; Value = 0xffff0001; PC = 0x8001134 *)
mov r5 L0x200178e8;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179e8; Value = 0xffff0000; PC = 0x8001138 *)
mov r6 L0x200179e8;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017ae8; Value = 0x00000000; PC = 0x800113c *)
mov r7 L0x20017ae8;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177e8; Value = 0xffff0000; PC = 0x8001140 *)
mov r4 L0x200177e8;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a800; PC = 0x80011bc *)
mov L0x2001a800 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a900; PC = 0x80011c0 *)
mov L0x2001a900 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa00; PC = 0x80011c4 *)
mov L0x2001aa00 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab00; PC = 0x80011c8 *)
mov L0x2001ab00 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac00; PC = 0x80011cc *)
mov L0x2001ac00 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad00; PC = 0x80011d0 *)
mov L0x2001ad00 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae00; PC = 0x80011d4 *)
mov L0x2001ae00 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af00; PC = 0x80011d8 *)
mov L0x2001af00 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a400; PC = 0x8001204 *)
mov L0x2001a400 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a500; PC = 0x8001208 *)
mov L0x2001a500 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a600; PC = 0x800120c *)
mov L0x2001a600 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a700; PC = 0x8001210 *)
mov L0x2001a700 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a100; PC = 0x8001214 *)
mov L0x2001a100 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a200; PC = 0x8001218 *)
mov L0x2001a200 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a300; PC = 0x800121c *)
mov L0x2001a300 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a000; PC = 0x8001220 *)
mov L0x2001a000 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001786a; Value = 0x00010001; PC = 0x8001044 *)
mov r4 L0x2001786a;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001796a; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x2001796a;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a6a; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017a6a;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b6a; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017b6a;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178ea; Value = 0x0001ffff; PC = 0x8001134 *)
mov r5 L0x200178ea;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179ea; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x200179ea;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017aea; Value = 0xffff0000; PC = 0x800113c *)
mov r7 L0x20017aea;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177ea; Value = 0x0000ffff; PC = 0x8001140 *)
mov r4 L0x200177ea;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a804; PC = 0x80011bc *)
mov L0x2001a804 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a904; PC = 0x80011c0 *)
mov L0x2001a904 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa04; PC = 0x80011c4 *)
mov L0x2001aa04 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab04; PC = 0x80011c8 *)
mov L0x2001ab04 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac04; PC = 0x80011cc *)
mov L0x2001ac04 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad04; PC = 0x80011d0 *)
mov L0x2001ad04 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae04; PC = 0x80011d4 *)
mov L0x2001ae04 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af04; PC = 0x80011d8 *)
mov L0x2001af04 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a404; PC = 0x8001204 *)
mov L0x2001a404 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a504; PC = 0x8001208 *)
mov L0x2001a504 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a604; PC = 0x800120c *)
mov L0x2001a604 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a704; PC = 0x8001210 *)
mov L0x2001a704 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a104; PC = 0x8001214 *)
mov L0x2001a104 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a204; PC = 0x8001218 *)
mov L0x2001a204 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a304; PC = 0x800121c *)
mov L0x2001a304 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a004; PC = 0x8001220 *)
mov L0x2001a004 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001786c; Value = 0xffff0001; PC = 0x8001044 *)
mov r4 L0x2001786c;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001796c; Value = 0xffff0000; PC = 0x8001048 *)
mov r5 L0x2001796c;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a6c; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017a6c;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b6c; Value = 0x0001ffff; PC = 0x8001050 *)
mov r7 L0x20017b6c;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178ec; Value = 0x00010001; PC = 0x8001134 *)
mov r5 L0x200178ec;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179ec; Value = 0xffff0000; PC = 0x8001138 *)
mov r6 L0x200179ec;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017aec; Value = 0x0001ffff; PC = 0x800113c *)
mov r7 L0x20017aec;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177ec; Value = 0xffff0000; PC = 0x8001140 *)
mov r4 L0x200177ec;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a808; PC = 0x80011bc *)
mov L0x2001a808 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a908; PC = 0x80011c0 *)
mov L0x2001a908 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa08; PC = 0x80011c4 *)
mov L0x2001aa08 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab08; PC = 0x80011c8 *)
mov L0x2001ab08 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac08; PC = 0x80011cc *)
mov L0x2001ac08 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad08; PC = 0x80011d0 *)
mov L0x2001ad08 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae08; PC = 0x80011d4 *)
mov L0x2001ae08 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af08; PC = 0x80011d8 *)
mov L0x2001af08 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a408; PC = 0x8001204 *)
mov L0x2001a408 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a508; PC = 0x8001208 *)
mov L0x2001a508 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a608; PC = 0x800120c *)
mov L0x2001a608 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a708; PC = 0x8001210 *)
mov L0x2001a708 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a108; PC = 0x8001214 *)
mov L0x2001a108 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a208; PC = 0x8001218 *)
mov L0x2001a208 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a308; PC = 0x800121c *)
mov L0x2001a308 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a008; PC = 0x8001220 *)
mov L0x2001a008 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001786e; Value = 0x0001ffff; PC = 0x8001044 *)
mov r4 L0x2001786e;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001796e; Value = 0xffffffff; PC = 0x8001048 *)
mov r5 L0x2001796e;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a6e; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017a6e;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b6e; Value = 0x00000001; PC = 0x8001050 *)
mov r7 L0x20017b6e;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178ee; Value = 0x00010001; PC = 0x8001134 *)
mov r5 L0x200178ee;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179ee; Value = 0xffffffff; PC = 0x8001138 *)
mov r6 L0x200179ee;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017aee; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017aee;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177ee; Value = 0x0001ffff; PC = 0x8001140 *)
mov r4 L0x200177ee;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a80c; PC = 0x80011bc *)
mov L0x2001a80c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a90c; PC = 0x80011c0 *)
mov L0x2001a90c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa0c; PC = 0x80011c4 *)
mov L0x2001aa0c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab0c; PC = 0x80011c8 *)
mov L0x2001ab0c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac0c; PC = 0x80011cc *)
mov L0x2001ac0c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad0c; PC = 0x80011d0 *)
mov L0x2001ad0c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae0c; PC = 0x80011d4 *)
mov L0x2001ae0c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af0c; PC = 0x80011d8 *)
mov L0x2001af0c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a40c; PC = 0x8001204 *)
mov L0x2001a40c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a50c; PC = 0x8001208 *)
mov L0x2001a50c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a60c; PC = 0x800120c *)
mov L0x2001a60c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a70c; PC = 0x8001210 *)
mov L0x2001a70c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a10c; PC = 0x8001214 *)
mov L0x2001a10c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a20c; PC = 0x8001218 *)
mov L0x2001a20c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a30c; PC = 0x800121c *)
mov L0x2001a30c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a00c; PC = 0x8001220 *)
mov L0x2001a00c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017870; Value = 0x00000001; PC = 0x8001044 *)
mov r4 L0x20017870;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017970; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x20017970;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a70; Value = 0x00010000; PC = 0x800104c *)
mov r6 L0x20017a70;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b70; Value = 0x00010000; PC = 0x8001050 *)
mov r7 L0x20017b70;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178f0; Value = 0x00010001; PC = 0x8001134 *)
mov r5 L0x200178f0;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179f0; Value = 0x0001ffff; PC = 0x8001138 *)
mov r6 L0x200179f0;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017af0; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017af0;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177f0; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x200177f0;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a810; PC = 0x80011bc *)
mov L0x2001a810 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a910; PC = 0x80011c0 *)
mov L0x2001a910 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa10; PC = 0x80011c4 *)
mov L0x2001aa10 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab10; PC = 0x80011c8 *)
mov L0x2001ab10 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac10; PC = 0x80011cc *)
mov L0x2001ac10 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad10; PC = 0x80011d0 *)
mov L0x2001ad10 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae10; PC = 0x80011d4 *)
mov L0x2001ae10 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af10; PC = 0x80011d8 *)
mov L0x2001af10 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a410; PC = 0x8001204 *)
mov L0x2001a410 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a510; PC = 0x8001208 *)
mov L0x2001a510 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a610; PC = 0x800120c *)
mov L0x2001a610 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a710; PC = 0x8001210 *)
mov L0x2001a710 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a110; PC = 0x8001214 *)
mov L0x2001a110 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a210; PC = 0x8001218 *)
mov L0x2001a210 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a310; PC = 0x800121c *)
mov L0x2001a310 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a010; PC = 0x8001220 *)
mov L0x2001a010 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017872; Value = 0x00010000; PC = 0x8001044 *)
mov r4 L0x20017872;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017972; Value = 0xffff0000; PC = 0x8001048 *)
mov r5 L0x20017972;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a72; Value = 0x00010001; PC = 0x800104c *)
mov r6 L0x20017a72;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b72; Value = 0x00000001; PC = 0x8001050 *)
mov r7 L0x20017b72;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178f2; Value = 0x00000001; PC = 0x8001134 *)
mov r5 L0x200178f2;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179f2; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x200179f2;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017af2; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017af2;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177f2; Value = 0xffff0000; PC = 0x8001140 *)
mov r4 L0x200177f2;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a814; PC = 0x80011bc *)
mov L0x2001a814 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a914; PC = 0x80011c0 *)
mov L0x2001a914 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa14; PC = 0x80011c4 *)
mov L0x2001aa14 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab14; PC = 0x80011c8 *)
mov L0x2001ab14 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac14; PC = 0x80011cc *)
mov L0x2001ac14 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad14; PC = 0x80011d0 *)
mov L0x2001ad14 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae14; PC = 0x80011d4 *)
mov L0x2001ae14 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af14; PC = 0x80011d8 *)
mov L0x2001af14 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a414; PC = 0x8001204 *)
mov L0x2001a414 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a514; PC = 0x8001208 *)
mov L0x2001a514 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a614; PC = 0x800120c *)
mov L0x2001a614 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a714; PC = 0x8001210 *)
mov L0x2001a714 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a114; PC = 0x8001214 *)
mov L0x2001a114 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a214; PC = 0x8001218 *)
mov L0x2001a214 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a314; PC = 0x800121c *)
mov L0x2001a314 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a014; PC = 0x8001220 *)
mov L0x2001a014 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017874; Value = 0xffff0001; PC = 0x8001044 *)
mov r4 L0x20017874;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017974; Value = 0x0001ffff; PC = 0x8001048 *)
mov r5 L0x20017974;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a74; Value = 0xffff0001; PC = 0x800104c *)
mov r6 L0x20017a74;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b74; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017b74;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178f4; Value = 0x00010000; PC = 0x8001134 *)
mov r5 L0x200178f4;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179f4; Value = 0x0001ffff; PC = 0x8001138 *)
mov r6 L0x200179f4;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017af4; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017af4;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177f4; Value = 0x0001ffff; PC = 0x8001140 *)
mov r4 L0x200177f4;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a818; PC = 0x80011bc *)
mov L0x2001a818 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a918; PC = 0x80011c0 *)
mov L0x2001a918 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa18; PC = 0x80011c4 *)
mov L0x2001aa18 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab18; PC = 0x80011c8 *)
mov L0x2001ab18 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac18; PC = 0x80011cc *)
mov L0x2001ac18 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad18; PC = 0x80011d0 *)
mov L0x2001ad18 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae18; PC = 0x80011d4 *)
mov L0x2001ae18 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af18; PC = 0x80011d8 *)
mov L0x2001af18 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a418; PC = 0x8001204 *)
mov L0x2001a418 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a518; PC = 0x8001208 *)
mov L0x2001a518 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a618; PC = 0x800120c *)
mov L0x2001a618 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a718; PC = 0x8001210 *)
mov L0x2001a718 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a118; PC = 0x8001214 *)
mov L0x2001a118 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a218; PC = 0x8001218 *)
mov L0x2001a218 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a318; PC = 0x800121c *)
mov L0x2001a318 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a018; PC = 0x8001220 *)
mov L0x2001a018 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017876; Value = 0x0000ffff; PC = 0x8001044 *)
mov r4 L0x20017876;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017976; Value = 0x00010001; PC = 0x8001048 *)
mov r5 L0x20017976;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a76; Value = 0x0001ffff; PC = 0x800104c *)
mov r6 L0x20017a76;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b76; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017b76;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178f6; Value = 0xffff0001; PC = 0x8001134 *)
mov r5 L0x200178f6;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179f6; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x200179f6;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017af6; Value = 0xffff0000; PC = 0x800113c *)
mov r7 L0x20017af6;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177f6; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x200177f6;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a81c; PC = 0x80011bc *)
mov L0x2001a81c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a91c; PC = 0x80011c0 *)
mov L0x2001a91c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa1c; PC = 0x80011c4 *)
mov L0x2001aa1c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab1c; PC = 0x80011c8 *)
mov L0x2001ab1c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac1c; PC = 0x80011cc *)
mov L0x2001ac1c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad1c; PC = 0x80011d0 *)
mov L0x2001ad1c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae1c; PC = 0x80011d4 *)
mov L0x2001ae1c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af1c; PC = 0x80011d8 *)
mov L0x2001af1c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a41c; PC = 0x8001204 *)
mov L0x2001a41c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a51c; PC = 0x8001208 *)
mov L0x2001a51c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a61c; PC = 0x800120c *)
mov L0x2001a61c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a71c; PC = 0x8001210 *)
mov L0x2001a71c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a11c; PC = 0x8001214 *)
mov L0x2001a11c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a21c; PC = 0x8001218 *)
mov L0x2001a21c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a31c; PC = 0x800121c *)
mov L0x2001a31c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a01c; PC = 0x8001220 *)
mov L0x2001a01c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017878; Value = 0x00000000; PC = 0x8001044 *)
mov r4 L0x20017878;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017978; Value = 0x00000001; PC = 0x8001048 *)
mov r5 L0x20017978;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a78; Value = 0x00000001; PC = 0x800104c *)
mov r6 L0x20017a78;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b78; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017b78;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178f8; Value = 0x0001ffff; PC = 0x8001134 *)
mov r5 L0x200178f8;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179f8; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x200179f8;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017af8; Value = 0xffffffff; PC = 0x800113c *)
mov r7 L0x20017af8;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177f8; Value = 0x00000000; PC = 0x8001140 *)
mov r4 L0x200177f8;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a820; PC = 0x80011bc *)
mov L0x2001a820 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a920; PC = 0x80011c0 *)
mov L0x2001a920 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa20; PC = 0x80011c4 *)
mov L0x2001aa20 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab20; PC = 0x80011c8 *)
mov L0x2001ab20 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac20; PC = 0x80011cc *)
mov L0x2001ac20 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad20; PC = 0x80011d0 *)
mov L0x2001ad20 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae20; PC = 0x80011d4 *)
mov L0x2001ae20 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af20; PC = 0x80011d8 *)
mov L0x2001af20 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a420; PC = 0x8001204 *)
mov L0x2001a420 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a520; PC = 0x8001208 *)
mov L0x2001a520 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a620; PC = 0x800120c *)
mov L0x2001a620 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a720; PC = 0x8001210 *)
mov L0x2001a720 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a120; PC = 0x8001214 *)
mov L0x2001a120 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a220; PC = 0x8001218 *)
mov L0x2001a220 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a320; PC = 0x800121c *)
mov L0x2001a320 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a020; PC = 0x8001220 *)
mov L0x2001a020 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001787a; Value = 0x00000000; PC = 0x8001044 *)
mov r4 L0x2001787a;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001797a; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x2001797a;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a7a; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017a7a;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b7a; Value = 0x00010000; PC = 0x8001050 *)
mov r7 L0x20017b7a;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178fa; Value = 0x00000001; PC = 0x8001134 *)
mov r5 L0x200178fa;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179fa; Value = 0xffff0000; PC = 0x8001138 *)
mov r6 L0x200179fa;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017afa; Value = 0x0000ffff; PC = 0x800113c *)
mov r7 L0x20017afa;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177fa; Value = 0x00000000; PC = 0x8001140 *)
mov r4 L0x200177fa;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a824; PC = 0x80011bc *)
mov L0x2001a824 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a924; PC = 0x80011c0 *)
mov L0x2001a924 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa24; PC = 0x80011c4 *)
mov L0x2001aa24 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab24; PC = 0x80011c8 *)
mov L0x2001ab24 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac24; PC = 0x80011cc *)
mov L0x2001ac24 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad24; PC = 0x80011d0 *)
mov L0x2001ad24 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae24; PC = 0x80011d4 *)
mov L0x2001ae24 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af24; PC = 0x80011d8 *)
mov L0x2001af24 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a424; PC = 0x8001204 *)
mov L0x2001a424 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a524; PC = 0x8001208 *)
mov L0x2001a524 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a624; PC = 0x800120c *)
mov L0x2001a624 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a724; PC = 0x8001210 *)
mov L0x2001a724 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a124; PC = 0x8001214 *)
mov L0x2001a124 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a224; PC = 0x8001218 *)
mov L0x2001a224 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a324; PC = 0x800121c *)
mov L0x2001a324 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a024; PC = 0x8001220 *)
mov L0x2001a024 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001787c; Value = 0x00010000; PC = 0x8001044 *)
mov r4 L0x2001787c;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001797c; Value = 0x00010000; PC = 0x8001048 *)
mov r5 L0x2001797c;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a7c; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017a7c;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b7c; Value = 0x00010001; PC = 0x8001050 *)
mov r7 L0x20017b7c;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178fc; Value = 0x00010000; PC = 0x8001134 *)
mov r5 L0x200178fc;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179fc; Value = 0xffffffff; PC = 0x8001138 *)
mov r6 L0x200179fc;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017afc; Value = 0xffff0000; PC = 0x800113c *)
mov r7 L0x20017afc;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177fc; Value = 0xffff0000; PC = 0x8001140 *)
mov r4 L0x200177fc;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a828; PC = 0x80011bc *)
mov L0x2001a828 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a928; PC = 0x80011c0 *)
mov L0x2001a928 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa28; PC = 0x80011c4 *)
mov L0x2001aa28 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab28; PC = 0x80011c8 *)
mov L0x2001ab28 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac28; PC = 0x80011cc *)
mov L0x2001ac28 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad28; PC = 0x80011d0 *)
mov L0x2001ad28 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae28; PC = 0x80011d4 *)
mov L0x2001ae28 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af28; PC = 0x80011d8 *)
mov L0x2001af28 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a428; PC = 0x8001204 *)
mov L0x2001a428 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a528; PC = 0x8001208 *)
mov L0x2001a528 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a628; PC = 0x800120c *)
mov L0x2001a628 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a728; PC = 0x8001210 *)
mov L0x2001a728 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a128; PC = 0x8001214 *)
mov L0x2001a128 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a228; PC = 0x8001218 *)
mov L0x2001a228 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a328; PC = 0x800121c *)
mov L0x2001a328 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a028; PC = 0x8001220 *)
mov L0x2001a028 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001787e; Value = 0x00000001; PC = 0x8001044 *)
mov r4 L0x2001787e;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001797e; Value = 0x00000001; PC = 0x8001048 *)
mov r5 L0x2001797e;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a7e; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017a7e;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b7e; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017b7e;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x200178fe; Value = 0xffff0001; PC = 0x8001134 *)
mov r5 L0x200178fe;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x200179fe; Value = 0xffffffff; PC = 0x8001138 *)
mov r6 L0x200179fe;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017afe; Value = 0x0000ffff; PC = 0x800113c *)
mov r7 L0x20017afe;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x200177fe; Value = 0x0000ffff; PC = 0x8001140 *)
mov r4 L0x200177fe;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a82c; PC = 0x80011bc *)
mov L0x2001a82c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a92c; PC = 0x80011c0 *)
mov L0x2001a92c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa2c; PC = 0x80011c4 *)
mov L0x2001aa2c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab2c; PC = 0x80011c8 *)
mov L0x2001ab2c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac2c; PC = 0x80011cc *)
mov L0x2001ac2c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad2c; PC = 0x80011d0 *)
mov L0x2001ad2c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae2c; PC = 0x80011d4 *)
mov L0x2001ae2c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af2c; PC = 0x80011d8 *)
mov L0x2001af2c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a42c; PC = 0x8001204 *)
mov L0x2001a42c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a52c; PC = 0x8001208 *)
mov L0x2001a52c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a62c; PC = 0x800120c *)
mov L0x2001a62c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a72c; PC = 0x8001210 *)
mov L0x2001a72c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a12c; PC = 0x8001214 *)
mov L0x2001a12c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a22c; PC = 0x8001218 *)
mov L0x2001a22c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a32c; PC = 0x800121c *)
mov L0x2001a32c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a02c; PC = 0x8001220 *)
mov L0x2001a02c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017880; Value = 0x00010000; PC = 0x8001044 *)
mov r4 L0x20017880;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017980; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x20017980;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a80; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017a80;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b80; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017b80;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017900; Value = 0x0000ffff; PC = 0x8001134 *)
mov r5 L0x20017900;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a00; Value = 0x0001ffff; PC = 0x8001138 *)
mov r6 L0x20017a00;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b00; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017b00;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017800; Value = 0xffff0000; PC = 0x8001140 *)
mov r4 L0x20017800;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a830; PC = 0x80011bc *)
mov L0x2001a830 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a930; PC = 0x80011c0 *)
mov L0x2001a930 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa30; PC = 0x80011c4 *)
mov L0x2001aa30 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab30; PC = 0x80011c8 *)
mov L0x2001ab30 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac30; PC = 0x80011cc *)
mov L0x2001ac30 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad30; PC = 0x80011d0 *)
mov L0x2001ad30 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae30; PC = 0x80011d4 *)
mov L0x2001ae30 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af30; PC = 0x80011d8 *)
mov L0x2001af30 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a430; PC = 0x8001204 *)
mov L0x2001a430 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a530; PC = 0x8001208 *)
mov L0x2001a530 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a630; PC = 0x800120c *)
mov L0x2001a630 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a730; PC = 0x8001210 *)
mov L0x2001a730 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a130; PC = 0x8001214 *)
mov L0x2001a130 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a230; PC = 0x8001218 *)
mov L0x2001a230 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a330; PC = 0x800121c *)
mov L0x2001a330 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a030; PC = 0x8001220 *)
mov L0x2001a030 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017882; Value = 0x00010001; PC = 0x8001044 *)
mov r4 L0x20017882;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017982; Value = 0x00010000; PC = 0x8001048 *)
mov r5 L0x20017982;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a82; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017a82;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b82; Value = 0x0001ffff; PC = 0x8001050 *)
mov r7 L0x20017b82;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017902; Value = 0x00000000; PC = 0x8001134 *)
mov r5 L0x20017902;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a02; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x20017a02;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b02; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017b02;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017802; Value = 0xffffffff; PC = 0x8001140 *)
mov r4 L0x20017802;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a834; PC = 0x80011bc *)
mov L0x2001a834 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a934; PC = 0x80011c0 *)
mov L0x2001a934 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa34; PC = 0x80011c4 *)
mov L0x2001aa34 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab34; PC = 0x80011c8 *)
mov L0x2001ab34 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac34; PC = 0x80011cc *)
mov L0x2001ac34 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad34; PC = 0x80011d0 *)
mov L0x2001ad34 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae34; PC = 0x80011d4 *)
mov L0x2001ae34 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af34; PC = 0x80011d8 *)
mov L0x2001af34 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a434; PC = 0x8001204 *)
mov L0x2001a434 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a534; PC = 0x8001208 *)
mov L0x2001a534 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a634; PC = 0x800120c *)
mov L0x2001a634 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a734; PC = 0x8001210 *)
mov L0x2001a734 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a134; PC = 0x8001214 *)
mov L0x2001a134 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a234; PC = 0x8001218 *)
mov L0x2001a234 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a334; PC = 0x800121c *)
mov L0x2001a334 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a034; PC = 0x8001220 *)
mov L0x2001a034 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017884; Value = 0x00000001; PC = 0x8001044 *)
mov r4 L0x20017884;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017984; Value = 0x00010001; PC = 0x8001048 *)
mov r5 L0x20017984;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a84; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017a84;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b84; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017b84;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017904; Value = 0x00000000; PC = 0x8001134 *)
mov r5 L0x20017904;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a04; Value = 0x0001ffff; PC = 0x8001138 *)
mov r6 L0x20017a04;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b04; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017b04;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017804; Value = 0xffffffff; PC = 0x8001140 *)
mov r4 L0x20017804;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a838; PC = 0x80011bc *)
mov L0x2001a838 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a938; PC = 0x80011c0 *)
mov L0x2001a938 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa38; PC = 0x80011c4 *)
mov L0x2001aa38 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab38; PC = 0x80011c8 *)
mov L0x2001ab38 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac38; PC = 0x80011cc *)
mov L0x2001ac38 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad38; PC = 0x80011d0 *)
mov L0x2001ad38 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae38; PC = 0x80011d4 *)
mov L0x2001ae38 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af38; PC = 0x80011d8 *)
mov L0x2001af38 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a438; PC = 0x8001204 *)
mov L0x2001a438 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a538; PC = 0x8001208 *)
mov L0x2001a538 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a638; PC = 0x800120c *)
mov L0x2001a638 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a738; PC = 0x8001210 *)
mov L0x2001a738 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a138; PC = 0x8001214 *)
mov L0x2001a138 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a238; PC = 0x8001218 *)
mov L0x2001a238 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a338; PC = 0x800121c *)
mov L0x2001a338 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a038; PC = 0x8001220 *)
mov L0x2001a038 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017886; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x20017886;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017986; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x20017986;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a86; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017a86;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b86; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017b86;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017906; Value = 0x00010000; PC = 0x8001134 *)
mov r5 L0x20017906;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a06; Value = 0x00000001; PC = 0x8001138 *)
mov r6 L0x20017a06;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b06; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017b06;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017806; Value = 0xffffffff; PC = 0x8001140 *)
mov r4 L0x20017806;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a83c; PC = 0x80011bc *)
mov L0x2001a83c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a93c; PC = 0x80011c0 *)
mov L0x2001a93c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa3c; PC = 0x80011c4 *)
mov L0x2001aa3c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab3c; PC = 0x80011c8 *)
mov L0x2001ab3c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac3c; PC = 0x80011cc *)
mov L0x2001ac3c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad3c; PC = 0x80011d0 *)
mov L0x2001ad3c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae3c; PC = 0x80011d4 *)
mov L0x2001ae3c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af3c; PC = 0x80011d8 *)
mov L0x2001af3c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a43c; PC = 0x8001204 *)
mov L0x2001a43c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a53c; PC = 0x8001208 *)
mov L0x2001a53c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a63c; PC = 0x800120c *)
mov L0x2001a63c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a73c; PC = 0x8001210 *)
mov L0x2001a73c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a13c; PC = 0x8001214 *)
mov L0x2001a13c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a23c; PC = 0x8001218 *)
mov L0x2001a23c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a33c; PC = 0x800121c *)
mov L0x2001a33c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a03c; PC = 0x8001220 *)
mov L0x2001a03c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017888; Value = 0xffffffff; PC = 0x8001044 *)
mov r4 L0x20017888;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017988; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x20017988;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a88; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017a88;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b88; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017b88;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017908; Value = 0xffff0001; PC = 0x8001134 *)
mov r5 L0x20017908;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a08; Value = 0x00010000; PC = 0x8001138 *)
mov r6 L0x20017a08;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b08; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017b08;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017808; Value = 0x0001ffff; PC = 0x8001140 *)
mov r4 L0x20017808;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a840; PC = 0x80011bc *)
mov L0x2001a840 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a940; PC = 0x80011c0 *)
mov L0x2001a940 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa40; PC = 0x80011c4 *)
mov L0x2001aa40 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab40; PC = 0x80011c8 *)
mov L0x2001ab40 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac40; PC = 0x80011cc *)
mov L0x2001ac40 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad40; PC = 0x80011d0 *)
mov L0x2001ad40 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae40; PC = 0x80011d4 *)
mov L0x2001ae40 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af40; PC = 0x80011d8 *)
mov L0x2001af40 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a440; PC = 0x8001204 *)
mov L0x2001a440 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a540; PC = 0x8001208 *)
mov L0x2001a540 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a640; PC = 0x800120c *)
mov L0x2001a640 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a740; PC = 0x8001210 *)
mov L0x2001a740 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a140; PC = 0x8001214 *)
mov L0x2001a140 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a240; PC = 0x8001218 *)
mov L0x2001a240 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a340; PC = 0x800121c *)
mov L0x2001a340 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a040; PC = 0x8001220 *)
mov L0x2001a040 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001788a; Value = 0x0000ffff; PC = 0x8001044 *)
mov r4 L0x2001788a;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001798a; Value = 0x00010000; PC = 0x8001048 *)
mov r5 L0x2001798a;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a8a; Value = 0x0001ffff; PC = 0x800104c *)
mov r6 L0x20017a8a;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b8a; Value = 0x0001ffff; PC = 0x8001050 *)
mov r7 L0x20017b8a;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001790a; Value = 0x0000ffff; PC = 0x8001134 *)
mov r5 L0x2001790a;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a0a; Value = 0x00010001; PC = 0x8001138 *)
mov r6 L0x20017a0a;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b0a; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017b0a;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001780a; Value = 0x00010001; PC = 0x8001140 *)
mov r4 L0x2001780a;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a844; PC = 0x80011bc *)
mov L0x2001a844 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a944; PC = 0x80011c0 *)
mov L0x2001a944 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa44; PC = 0x80011c4 *)
mov L0x2001aa44 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab44; PC = 0x80011c8 *)
mov L0x2001ab44 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac44; PC = 0x80011cc *)
mov L0x2001ac44 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad44; PC = 0x80011d0 *)
mov L0x2001ad44 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae44; PC = 0x80011d4 *)
mov L0x2001ae44 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af44; PC = 0x80011d8 *)
mov L0x2001af44 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a444; PC = 0x8001204 *)
mov L0x2001a444 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a544; PC = 0x8001208 *)
mov L0x2001a544 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a644; PC = 0x800120c *)
mov L0x2001a644 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a744; PC = 0x8001210 *)
mov L0x2001a744 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a144; PC = 0x8001214 *)
mov L0x2001a144 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a244; PC = 0x8001218 *)
mov L0x2001a244 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a344; PC = 0x800121c *)
mov L0x2001a344 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a044; PC = 0x8001220 *)
mov L0x2001a044 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001788c; Value = 0x00000000; PC = 0x8001044 *)
mov r4 L0x2001788c;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001798c; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x2001798c;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a8c; Value = 0x00010001; PC = 0x800104c *)
mov r6 L0x20017a8c;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b8c; Value = 0x00010001; PC = 0x8001050 *)
mov r7 L0x20017b8c;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001790c; Value = 0x00000000; PC = 0x8001134 *)
mov r5 L0x2001790c;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a0c; Value = 0x00000001; PC = 0x8001138 *)
mov r6 L0x20017a0c;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b0c; Value = 0x00000000; PC = 0x800113c *)
mov r7 L0x20017b0c;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001780c; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x2001780c;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a848; PC = 0x80011bc *)
mov L0x2001a848 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a948; PC = 0x80011c0 *)
mov L0x2001a948 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa48; PC = 0x80011c4 *)
mov L0x2001aa48 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab48; PC = 0x80011c8 *)
mov L0x2001ab48 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac48; PC = 0x80011cc *)
mov L0x2001ac48 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad48; PC = 0x80011d0 *)
mov L0x2001ad48 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae48; PC = 0x80011d4 *)
mov L0x2001ae48 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af48; PC = 0x80011d8 *)
mov L0x2001af48 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a448; PC = 0x8001204 *)
mov L0x2001a448 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a548; PC = 0x8001208 *)
mov L0x2001a548 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a648; PC = 0x800120c *)
mov L0x2001a648 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a748; PC = 0x8001210 *)
mov L0x2001a748 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a148; PC = 0x8001214 *)
mov L0x2001a148 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a248; PC = 0x8001218 *)
mov L0x2001a248 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a348; PC = 0x800121c *)
mov L0x2001a348 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a048; PC = 0x8001220 *)
mov L0x2001a048 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001788e; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x2001788e;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001798e; Value = 0xffffffff; PC = 0x8001048 *)
mov r5 L0x2001798e;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a8e; Value = 0xffff0001; PC = 0x800104c *)
mov r6 L0x20017a8e;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b8e; Value = 0x00010001; PC = 0x8001050 *)
mov r7 L0x20017b8e;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001790e; Value = 0xffff0000; PC = 0x8001134 *)
mov r5 L0x2001790e;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a0e; Value = 0x00000000; PC = 0x8001138 *)
mov r6 L0x20017a0e;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b0e; Value = 0x00000000; PC = 0x800113c *)
mov r7 L0x20017b0e;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001780e; Value = 0xffff0000; PC = 0x8001140 *)
mov r4 L0x2001780e;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a84c; PC = 0x80011bc *)
mov L0x2001a84c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a94c; PC = 0x80011c0 *)
mov L0x2001a94c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa4c; PC = 0x80011c4 *)
mov L0x2001aa4c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab4c; PC = 0x80011c8 *)
mov L0x2001ab4c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac4c; PC = 0x80011cc *)
mov L0x2001ac4c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad4c; PC = 0x80011d0 *)
mov L0x2001ad4c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae4c; PC = 0x80011d4 *)
mov L0x2001ae4c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af4c; PC = 0x80011d8 *)
mov L0x2001af4c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a44c; PC = 0x8001204 *)
mov L0x2001a44c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a54c; PC = 0x8001208 *)
mov L0x2001a54c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a64c; PC = 0x800120c *)
mov L0x2001a64c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a74c; PC = 0x8001210 *)
mov L0x2001a74c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a14c; PC = 0x8001214 *)
mov L0x2001a14c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a24c; PC = 0x8001218 *)
mov L0x2001a24c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a34c; PC = 0x800121c *)
mov L0x2001a34c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a04c; PC = 0x8001220 *)
mov L0x2001a04c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017890; Value = 0x0000ffff; PC = 0x8001044 *)
mov r4 L0x20017890;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017990; Value = 0xffffffff; PC = 0x8001048 *)
mov r5 L0x20017990;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a90; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017a90;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b90; Value = 0x00010001; PC = 0x8001050 *)
mov r7 L0x20017b90;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017910; Value = 0xffffffff; PC = 0x8001134 *)
mov r5 L0x20017910;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a10; Value = 0x00000000; PC = 0x8001138 *)
mov r6 L0x20017a10;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b10; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017b10;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017810; Value = 0xffffffff; PC = 0x8001140 *)
mov r4 L0x20017810;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a850; PC = 0x80011bc *)
mov L0x2001a850 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a950; PC = 0x80011c0 *)
mov L0x2001a950 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa50; PC = 0x80011c4 *)
mov L0x2001aa50 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab50; PC = 0x80011c8 *)
mov L0x2001ab50 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac50; PC = 0x80011cc *)
mov L0x2001ac50 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad50; PC = 0x80011d0 *)
mov L0x2001ad50 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae50; PC = 0x80011d4 *)
mov L0x2001ae50 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af50; PC = 0x80011d8 *)
mov L0x2001af50 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a450; PC = 0x8001204 *)
mov L0x2001a450 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a550; PC = 0x8001208 *)
mov L0x2001a550 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a650; PC = 0x800120c *)
mov L0x2001a650 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a750; PC = 0x8001210 *)
mov L0x2001a750 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a150; PC = 0x8001214 *)
mov L0x2001a150 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a250; PC = 0x8001218 *)
mov L0x2001a250 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a350; PC = 0x800121c *)
mov L0x2001a350 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a050; PC = 0x8001220 *)
mov L0x2001a050 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017892; Value = 0x00000000; PC = 0x8001044 *)
mov r4 L0x20017892;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017992; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x20017992;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a92; Value = 0x00010000; PC = 0x800104c *)
mov r6 L0x20017a92;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b92; Value = 0x00010001; PC = 0x8001050 *)
mov r7 L0x20017b92;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017912; Value = 0x0001ffff; PC = 0x8001134 *)
mov r5 L0x20017912;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a12; Value = 0xffff0000; PC = 0x8001138 *)
mov r6 L0x20017a12;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b12; Value = 0xffff0001; PC = 0x800113c *)
mov r7 L0x20017b12;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017812; Value = 0x0001ffff; PC = 0x8001140 *)
mov r4 L0x20017812;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a854; PC = 0x80011bc *)
mov L0x2001a854 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a954; PC = 0x80011c0 *)
mov L0x2001a954 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa54; PC = 0x80011c4 *)
mov L0x2001aa54 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab54; PC = 0x80011c8 *)
mov L0x2001ab54 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac54; PC = 0x80011cc *)
mov L0x2001ac54 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad54; PC = 0x80011d0 *)
mov L0x2001ad54 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae54; PC = 0x80011d4 *)
mov L0x2001ae54 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af54; PC = 0x80011d8 *)
mov L0x2001af54 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a454; PC = 0x8001204 *)
mov L0x2001a454 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a554; PC = 0x8001208 *)
mov L0x2001a554 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a654; PC = 0x800120c *)
mov L0x2001a654 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a754; PC = 0x8001210 *)
mov L0x2001a754 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a154; PC = 0x8001214 *)
mov L0x2001a154 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a254; PC = 0x8001218 *)
mov L0x2001a254 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a354; PC = 0x800121c *)
mov L0x2001a354 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a054; PC = 0x8001220 *)
mov L0x2001a054 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017894; Value = 0x00000000; PC = 0x8001044 *)
mov r4 L0x20017894;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017994; Value = 0x00010000; PC = 0x8001048 *)
mov r5 L0x20017994;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a94; Value = 0xffff0001; PC = 0x800104c *)
mov r6 L0x20017a94;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b94; Value = 0x00000001; PC = 0x8001050 *)
mov r7 L0x20017b94;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017914; Value = 0x00000001; PC = 0x8001134 *)
mov r5 L0x20017914;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a14; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x20017a14;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b14; Value = 0x0001ffff; PC = 0x800113c *)
mov r7 L0x20017b14;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017814; Value = 0xffff0001; PC = 0x8001140 *)
mov r4 L0x20017814;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a858; PC = 0x80011bc *)
mov L0x2001a858 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a958; PC = 0x80011c0 *)
mov L0x2001a958 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa58; PC = 0x80011c4 *)
mov L0x2001aa58 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab58; PC = 0x80011c8 *)
mov L0x2001ab58 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac58; PC = 0x80011cc *)
mov L0x2001ac58 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad58; PC = 0x80011d0 *)
mov L0x2001ad58 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae58; PC = 0x80011d4 *)
mov L0x2001ae58 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af58; PC = 0x80011d8 *)
mov L0x2001af58 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a458; PC = 0x8001204 *)
mov L0x2001a458 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a558; PC = 0x8001208 *)
mov L0x2001a558 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a658; PC = 0x800120c *)
mov L0x2001a658 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a758; PC = 0x8001210 *)
mov L0x2001a758 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a158; PC = 0x8001214 *)
mov L0x2001a158 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a258; PC = 0x8001218 *)
mov L0x2001a258 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a358; PC = 0x800121c *)
mov L0x2001a358 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a058; PC = 0x8001220 *)
mov L0x2001a058 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017896; Value = 0x00010000; PC = 0x8001044 *)
mov r4 L0x20017896;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017996; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x20017996;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a96; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017a96;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b96; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017b96;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017916; Value = 0x00000000; PC = 0x8001134 *)
mov r5 L0x20017916;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a16; Value = 0x00000000; PC = 0x8001138 *)
mov r6 L0x20017a16;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b16; Value = 0xffff0001; PC = 0x800113c *)
mov r7 L0x20017b16;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017816; Value = 0x0001ffff; PC = 0x8001140 *)
mov r4 L0x20017816;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a85c; PC = 0x80011bc *)
mov L0x2001a85c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a95c; PC = 0x80011c0 *)
mov L0x2001a95c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa5c; PC = 0x80011c4 *)
mov L0x2001aa5c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab5c; PC = 0x80011c8 *)
mov L0x2001ab5c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac5c; PC = 0x80011cc *)
mov L0x2001ac5c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad5c; PC = 0x80011d0 *)
mov L0x2001ad5c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae5c; PC = 0x80011d4 *)
mov L0x2001ae5c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af5c; PC = 0x80011d8 *)
mov L0x2001af5c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a45c; PC = 0x8001204 *)
mov L0x2001a45c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a55c; PC = 0x8001208 *)
mov L0x2001a55c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a65c; PC = 0x800120c *)
mov L0x2001a65c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a75c; PC = 0x8001210 *)
mov L0x2001a75c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a15c; PC = 0x8001214 *)
mov L0x2001a15c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a25c; PC = 0x8001218 *)
mov L0x2001a25c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a35c; PC = 0x800121c *)
mov L0x2001a35c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a05c; PC = 0x8001220 *)
mov L0x2001a05c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x20017898; Value = 0x00000001; PC = 0x8001044 *)
mov r4 L0x20017898;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x20017998; Value = 0xffffffff; PC = 0x8001048 *)
mov r5 L0x20017998;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a98; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017a98;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b98; Value = 0x00010000; PC = 0x8001050 *)
mov r7 L0x20017b98;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017918; Value = 0xffff0000; PC = 0x8001134 *)
mov r5 L0x20017918;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a18; Value = 0x00000000; PC = 0x8001138 *)
mov r6 L0x20017a18;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b18; Value = 0xffffffff; PC = 0x800113c *)
mov r7 L0x20017b18;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017818; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x20017818;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a860; PC = 0x80011bc *)
mov L0x2001a860 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a960; PC = 0x80011c0 *)
mov L0x2001a960 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa60; PC = 0x80011c4 *)
mov L0x2001aa60 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab60; PC = 0x80011c8 *)
mov L0x2001ab60 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac60; PC = 0x80011cc *)
mov L0x2001ac60 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad60; PC = 0x80011d0 *)
mov L0x2001ad60 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae60; PC = 0x80011d4 *)
mov L0x2001ae60 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af60; PC = 0x80011d8 *)
mov L0x2001af60 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a460; PC = 0x8001204 *)
mov L0x2001a460 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a560; PC = 0x8001208 *)
mov L0x2001a560 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a660; PC = 0x800120c *)
mov L0x2001a660 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a760; PC = 0x8001210 *)
mov L0x2001a760 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a160; PC = 0x8001214 *)
mov L0x2001a160 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a260; PC = 0x8001218 *)
mov L0x2001a260 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a360; PC = 0x800121c *)
mov L0x2001a360 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a060; PC = 0x8001220 *)
mov L0x2001a060 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001789a; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x2001789a;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001799a; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x2001799a;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a9a; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017a9a;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b9a; Value = 0x00000001; PC = 0x8001050 *)
mov r7 L0x20017b9a;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001791a; Value = 0x0001ffff; PC = 0x8001134 *)
mov r5 L0x2001791a;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a1a; Value = 0x00010000; PC = 0x8001138 *)
mov r6 L0x20017a1a;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b1a; Value = 0x0001ffff; PC = 0x800113c *)
mov r7 L0x20017b1a;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001781a; Value = 0x00000000; PC = 0x8001140 *)
mov r4 L0x2001781a;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a864; PC = 0x80011bc *)
mov L0x2001a864 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a964; PC = 0x80011c0 *)
mov L0x2001a964 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa64; PC = 0x80011c4 *)
mov L0x2001aa64 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab64; PC = 0x80011c8 *)
mov L0x2001ab64 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac64; PC = 0x80011cc *)
mov L0x2001ac64 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad64; PC = 0x80011d0 *)
mov L0x2001ad64 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae64; PC = 0x80011d4 *)
mov L0x2001ae64 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af64; PC = 0x80011d8 *)
mov L0x2001af64 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a464; PC = 0x8001204 *)
mov L0x2001a464 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a564; PC = 0x8001208 *)
mov L0x2001a564 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a664; PC = 0x800120c *)
mov L0x2001a664 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a764; PC = 0x8001210 *)
mov L0x2001a764 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a164; PC = 0x8001214 *)
mov L0x2001a164 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a264; PC = 0x8001218 *)
mov L0x2001a264 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a364; PC = 0x800121c *)
mov L0x2001a364 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a064; PC = 0x8001220 *)
mov L0x2001a064 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001789c; Value = 0x0001ffff; PC = 0x8001044 *)
mov r4 L0x2001789c;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001799c; Value = 0x00010000; PC = 0x8001048 *)
mov r5 L0x2001799c;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a9c; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017a9c;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b9c; Value = 0x00010000; PC = 0x8001050 *)
mov r7 L0x20017b9c;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001791c; Value = 0x00010001; PC = 0x8001134 *)
mov r5 L0x2001791c;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a1c; Value = 0x00000001; PC = 0x8001138 *)
mov r6 L0x20017a1c;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b1c; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017b1c;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001781c; Value = 0x00000000; PC = 0x8001140 *)
mov r4 L0x2001781c;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a868; PC = 0x80011bc *)
mov L0x2001a868 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a968; PC = 0x80011c0 *)
mov L0x2001a968 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa68; PC = 0x80011c4 *)
mov L0x2001aa68 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab68; PC = 0x80011c8 *)
mov L0x2001ab68 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac68; PC = 0x80011cc *)
mov L0x2001ac68 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad68; PC = 0x80011d0 *)
mov L0x2001ad68 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae68; PC = 0x80011d4 *)
mov L0x2001ae68 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af68; PC = 0x80011d8 *)
mov L0x2001af68 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a468; PC = 0x8001204 *)
mov L0x2001a468 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a568; PC = 0x8001208 *)
mov L0x2001a568 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a668; PC = 0x800120c *)
mov L0x2001a668 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a768; PC = 0x8001210 *)
mov L0x2001a768 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a168; PC = 0x8001214 *)
mov L0x2001a168 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a268; PC = 0x8001218 *)
mov L0x2001a268 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a368; PC = 0x800121c *)
mov L0x2001a368 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a068; PC = 0x8001220 *)
mov L0x2001a068 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x2001789e; Value = 0x00000001; PC = 0x8001044 *)
mov r4 L0x2001789e;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x2001799e; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x2001799e;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017a9e; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017a9e;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017b9e; Value = 0x00010001; PC = 0x8001050 *)
mov r7 L0x20017b9e;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001791e; Value = 0xffff0001; PC = 0x8001134 *)
mov r5 L0x2001791e;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a1e; Value = 0x00010000; PC = 0x8001138 *)
mov r6 L0x20017a1e;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b1e; Value = 0x00000000; PC = 0x800113c *)
mov r7 L0x20017b1e;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001781e; Value = 0x00010000; PC = 0x8001140 *)
mov r4 L0x2001781e;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a86c; PC = 0x80011bc *)
mov L0x2001a86c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a96c; PC = 0x80011c0 *)
mov L0x2001a96c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa6c; PC = 0x80011c4 *)
mov L0x2001aa6c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab6c; PC = 0x80011c8 *)
mov L0x2001ab6c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac6c; PC = 0x80011cc *)
mov L0x2001ac6c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad6c; PC = 0x80011d0 *)
mov L0x2001ad6c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae6c; PC = 0x80011d4 *)
mov L0x2001ae6c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af6c; PC = 0x80011d8 *)
mov L0x2001af6c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a46c; PC = 0x8001204 *)
mov L0x2001a46c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a56c; PC = 0x8001208 *)
mov L0x2001a56c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a66c; PC = 0x800120c *)
mov L0x2001a66c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a76c; PC = 0x8001210 *)
mov L0x2001a76c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a16c; PC = 0x8001214 *)
mov L0x2001a16c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a26c; PC = 0x8001218 *)
mov L0x2001a26c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a36c; PC = 0x800121c *)
mov L0x2001a36c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a06c; PC = 0x8001220 *)
mov L0x2001a06c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178a0; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x200178a0;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179a0; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x200179a0;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aa0; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017aa0;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017ba0; Value = 0x00000001; PC = 0x8001050 *)
mov r7 L0x20017ba0;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017920; Value = 0xffffffff; PC = 0x8001134 *)
mov r5 L0x20017920;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a20; Value = 0x00000001; PC = 0x8001138 *)
mov r6 L0x20017a20;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b20; Value = 0x00000000; PC = 0x800113c *)
mov r7 L0x20017b20;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017820; Value = 0x00010001; PC = 0x8001140 *)
mov r4 L0x20017820;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a870; PC = 0x80011bc *)
mov L0x2001a870 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a970; PC = 0x80011c0 *)
mov L0x2001a970 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa70; PC = 0x80011c4 *)
mov L0x2001aa70 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab70; PC = 0x80011c8 *)
mov L0x2001ab70 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac70; PC = 0x80011cc *)
mov L0x2001ac70 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad70; PC = 0x80011d0 *)
mov L0x2001ad70 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae70; PC = 0x80011d4 *)
mov L0x2001ae70 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af70; PC = 0x80011d8 *)
mov L0x2001af70 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a470; PC = 0x8001204 *)
mov L0x2001a470 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a570; PC = 0x8001208 *)
mov L0x2001a570 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a670; PC = 0x800120c *)
mov L0x2001a670 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a770; PC = 0x8001210 *)
mov L0x2001a770 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a170; PC = 0x8001214 *)
mov L0x2001a170 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a270; PC = 0x8001218 *)
mov L0x2001a270 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a370; PC = 0x800121c *)
mov L0x2001a370 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a070; PC = 0x8001220 *)
mov L0x2001a070 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178a2; Value = 0x0001ffff; PC = 0x8001044 *)
mov r4 L0x200178a2;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179a2; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x200179a2;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aa2; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017aa2;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017ba2; Value = 0xffff0000; PC = 0x8001050 *)
mov r7 L0x20017ba2;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017922; Value = 0xffffffff; PC = 0x8001134 *)
mov r5 L0x20017922;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a22; Value = 0x00010000; PC = 0x8001138 *)
mov r6 L0x20017a22;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b22; Value = 0xffff0000; PC = 0x800113c *)
mov r7 L0x20017b22;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017822; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x20017822;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a874; PC = 0x80011bc *)
mov L0x2001a874 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a974; PC = 0x80011c0 *)
mov L0x2001a974 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa74; PC = 0x80011c4 *)
mov L0x2001aa74 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab74; PC = 0x80011c8 *)
mov L0x2001ab74 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac74; PC = 0x80011cc *)
mov L0x2001ac74 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad74; PC = 0x80011d0 *)
mov L0x2001ad74 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae74; PC = 0x80011d4 *)
mov L0x2001ae74 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af74; PC = 0x80011d8 *)
mov L0x2001af74 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a474; PC = 0x8001204 *)
mov L0x2001a474 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a574; PC = 0x8001208 *)
mov L0x2001a574 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a674; PC = 0x800120c *)
mov L0x2001a674 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a774; PC = 0x8001210 *)
mov L0x2001a774 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a174; PC = 0x8001214 *)
mov L0x2001a174 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a274; PC = 0x8001218 *)
mov L0x2001a274 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a374; PC = 0x800121c *)
mov L0x2001a374 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a074; PC = 0x8001220 *)
mov L0x2001a074 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178a4; Value = 0x00010001; PC = 0x8001044 *)
mov r4 L0x200178a4;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179a4; Value = 0xffff0000; PC = 0x8001048 *)
mov r5 L0x200179a4;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aa4; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017aa4;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017ba4; Value = 0x0001ffff; PC = 0x8001050 *)
mov r7 L0x20017ba4;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017924; Value = 0xffffffff; PC = 0x8001134 *)
mov r5 L0x20017924;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a24; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x20017a24;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b24; Value = 0x0000ffff; PC = 0x800113c *)
mov r7 L0x20017b24;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017824; Value = 0x00010000; PC = 0x8001140 *)
mov r4 L0x20017824;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a878; PC = 0x80011bc *)
mov L0x2001a878 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a978; PC = 0x80011c0 *)
mov L0x2001a978 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa78; PC = 0x80011c4 *)
mov L0x2001aa78 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab78; PC = 0x80011c8 *)
mov L0x2001ab78 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac78; PC = 0x80011cc *)
mov L0x2001ac78 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad78; PC = 0x80011d0 *)
mov L0x2001ad78 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae78; PC = 0x80011d4 *)
mov L0x2001ae78 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af78; PC = 0x80011d8 *)
mov L0x2001af78 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a478; PC = 0x8001204 *)
mov L0x2001a478 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a578; PC = 0x8001208 *)
mov L0x2001a578 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a678; PC = 0x800120c *)
mov L0x2001a678 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a778; PC = 0x8001210 *)
mov L0x2001a778 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a178; PC = 0x8001214 *)
mov L0x2001a178 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a278; PC = 0x8001218 *)
mov L0x2001a278 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a378; PC = 0x800121c *)
mov L0x2001a378 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a078; PC = 0x8001220 *)
mov L0x2001a078 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178a6; Value = 0x00010001; PC = 0x8001044 *)
mov r4 L0x200178a6;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179a6; Value = 0x0001ffff; PC = 0x8001048 *)
mov r5 L0x200179a6;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aa6; Value = 0x00010000; PC = 0x800104c *)
mov r6 L0x20017aa6;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017ba6; Value = 0x00000001; PC = 0x8001050 *)
mov r7 L0x20017ba6;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017926; Value = 0x0000ffff; PC = 0x8001134 *)
mov r5 L0x20017926;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a26; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x20017a26;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b26; Value = 0xffff0000; PC = 0x800113c *)
mov r7 L0x20017b26;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017826; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x20017826;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a87c; PC = 0x80011bc *)
mov L0x2001a87c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a97c; PC = 0x80011c0 *)
mov L0x2001a97c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa7c; PC = 0x80011c4 *)
mov L0x2001aa7c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab7c; PC = 0x80011c8 *)
mov L0x2001ab7c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac7c; PC = 0x80011cc *)
mov L0x2001ac7c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad7c; PC = 0x80011d0 *)
mov L0x2001ad7c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae7c; PC = 0x80011d4 *)
mov L0x2001ae7c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af7c; PC = 0x80011d8 *)
mov L0x2001af7c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a47c; PC = 0x8001204 *)
mov L0x2001a47c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a57c; PC = 0x8001208 *)
mov L0x2001a57c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a67c; PC = 0x800120c *)
mov L0x2001a67c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a77c; PC = 0x8001210 *)
mov L0x2001a77c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a17c; PC = 0x8001214 *)
mov L0x2001a17c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a27c; PC = 0x8001218 *)
mov L0x2001a27c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a37c; PC = 0x800121c *)
mov L0x2001a37c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a07c; PC = 0x8001220 *)
mov L0x2001a07c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178a8; Value = 0xffff0001; PC = 0x8001044 *)
mov r4 L0x200178a8;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179a8; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x200179a8;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aa8; Value = 0xffff0001; PC = 0x800104c *)
mov r6 L0x20017aa8;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017ba8; Value = 0x00010000; PC = 0x8001050 *)
mov r7 L0x20017ba8;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017928; Value = 0xffff0000; PC = 0x8001134 *)
mov r5 L0x20017928;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a28; Value = 0xffff0000; PC = 0x8001138 *)
mov r6 L0x20017a28;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b28; Value = 0xffffffff; PC = 0x800113c *)
mov r7 L0x20017b28;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017828; Value = 0xffff0000; PC = 0x8001140 *)
mov r4 L0x20017828;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a880; PC = 0x80011bc *)
mov L0x2001a880 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a980; PC = 0x80011c0 *)
mov L0x2001a980 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa80; PC = 0x80011c4 *)
mov L0x2001aa80 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab80; PC = 0x80011c8 *)
mov L0x2001ab80 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac80; PC = 0x80011cc *)
mov L0x2001ac80 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad80; PC = 0x80011d0 *)
mov L0x2001ad80 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae80; PC = 0x80011d4 *)
mov L0x2001ae80 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af80; PC = 0x80011d8 *)
mov L0x2001af80 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a480; PC = 0x8001204 *)
mov L0x2001a480 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a580; PC = 0x8001208 *)
mov L0x2001a580 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a680; PC = 0x800120c *)
mov L0x2001a680 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a780; PC = 0x8001210 *)
mov L0x2001a780 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a180; PC = 0x8001214 *)
mov L0x2001a180 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a280; PC = 0x8001218 *)
mov L0x2001a280 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a380; PC = 0x800121c *)
mov L0x2001a380 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a080; PC = 0x8001220 *)
mov L0x2001a080 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178aa; Value = 0x0001ffff; PC = 0x8001044 *)
mov r4 L0x200178aa;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179aa; Value = 0x0001ffff; PC = 0x8001048 *)
mov r5 L0x200179aa;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aaa; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017aaa;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017baa; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017baa;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001792a; Value = 0x0001ffff; PC = 0x8001134 *)
mov r5 L0x2001792a;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a2a; Value = 0xffffffff; PC = 0x8001138 *)
mov r6 L0x20017a2a;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b2a; Value = 0x0000ffff; PC = 0x800113c *)
mov r7 L0x20017b2a;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001782a; Value = 0x0001ffff; PC = 0x8001140 *)
mov r4 L0x2001782a;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a884; PC = 0x80011bc *)
mov L0x2001a884 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a984; PC = 0x80011c0 *)
mov L0x2001a984 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa84; PC = 0x80011c4 *)
mov L0x2001aa84 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab84; PC = 0x80011c8 *)
mov L0x2001ab84 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac84; PC = 0x80011cc *)
mov L0x2001ac84 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad84; PC = 0x80011d0 *)
mov L0x2001ad84 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae84; PC = 0x80011d4 *)
mov L0x2001ae84 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af84; PC = 0x80011d8 *)
mov L0x2001af84 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a484; PC = 0x8001204 *)
mov L0x2001a484 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a584; PC = 0x8001208 *)
mov L0x2001a584 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a684; PC = 0x800120c *)
mov L0x2001a684 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a784; PC = 0x8001210 *)
mov L0x2001a784 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a184; PC = 0x8001214 *)
mov L0x2001a184 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a284; PC = 0x8001218 *)
mov L0x2001a284 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a384; PC = 0x800121c *)
mov L0x2001a384 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a084; PC = 0x8001220 *)
mov L0x2001a084 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178ac; Value = 0x00000001; PC = 0x8001044 *)
mov r4 L0x200178ac;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179ac; Value = 0x00010001; PC = 0x8001048 *)
mov r5 L0x200179ac;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aac; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017aac;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bac; Value = 0x0000ffff; PC = 0x8001050 *)
mov r7 L0x20017bac;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001792c; Value = 0xffff0001; PC = 0x8001134 *)
mov r5 L0x2001792c;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a2c; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x20017a2c;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b2c; Value = 0xffff0000; PC = 0x800113c *)
mov r7 L0x20017b2c;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001782c; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x2001782c;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a888; PC = 0x80011bc *)
mov L0x2001a888 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a988; PC = 0x80011c0 *)
mov L0x2001a988 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa88; PC = 0x80011c4 *)
mov L0x2001aa88 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab88; PC = 0x80011c8 *)
mov L0x2001ab88 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac88; PC = 0x80011cc *)
mov L0x2001ac88 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad88; PC = 0x80011d0 *)
mov L0x2001ad88 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae88; PC = 0x80011d4 *)
mov L0x2001ae88 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af88; PC = 0x80011d8 *)
mov L0x2001af88 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a488; PC = 0x8001204 *)
mov L0x2001a488 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a588; PC = 0x8001208 *)
mov L0x2001a588 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a688; PC = 0x800120c *)
mov L0x2001a688 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a788; PC = 0x8001210 *)
mov L0x2001a788 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a188; PC = 0x8001214 *)
mov L0x2001a188 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a288; PC = 0x8001218 *)
mov L0x2001a288 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a388; PC = 0x800121c *)
mov L0x2001a388 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a088; PC = 0x8001220 *)
mov L0x2001a088 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178ae; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x200178ae;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179ae; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x200179ae;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aae; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017aae;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bae; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017bae;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001792e; Value = 0xffffffff; PC = 0x8001134 *)
mov r5 L0x2001792e;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a2e; Value = 0xffff0000; PC = 0x8001138 *)
mov r6 L0x20017a2e;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b2e; Value = 0x0000ffff; PC = 0x800113c *)
mov r7 L0x20017b2e;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001782e; Value = 0x00000000; PC = 0x8001140 *)
mov r4 L0x2001782e;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a88c; PC = 0x80011bc *)
mov L0x2001a88c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a98c; PC = 0x80011c0 *)
mov L0x2001a98c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa8c; PC = 0x80011c4 *)
mov L0x2001aa8c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab8c; PC = 0x80011c8 *)
mov L0x2001ab8c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac8c; PC = 0x80011cc *)
mov L0x2001ac8c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad8c; PC = 0x80011d0 *)
mov L0x2001ad8c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae8c; PC = 0x80011d4 *)
mov L0x2001ae8c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af8c; PC = 0x80011d8 *)
mov L0x2001af8c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a48c; PC = 0x8001204 *)
mov L0x2001a48c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a58c; PC = 0x8001208 *)
mov L0x2001a58c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a68c; PC = 0x800120c *)
mov L0x2001a68c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a78c; PC = 0x8001210 *)
mov L0x2001a78c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a18c; PC = 0x8001214 *)
mov L0x2001a18c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a28c; PC = 0x8001218 *)
mov L0x2001a28c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a38c; PC = 0x800121c *)
mov L0x2001a38c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a08c; PC = 0x8001220 *)
mov L0x2001a08c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178b0; Value = 0x0000ffff; PC = 0x8001044 *)
mov r4 L0x200178b0;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179b0; Value = 0xffffffff; PC = 0x8001048 *)
mov r5 L0x200179b0;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ab0; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017ab0;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bb0; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017bb0;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017930; Value = 0x0000ffff; PC = 0x8001134 *)
mov r5 L0x20017930;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a30; Value = 0x0001ffff; PC = 0x8001138 *)
mov r6 L0x20017a30;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b30; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017b30;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017830; Value = 0x00010000; PC = 0x8001140 *)
mov r4 L0x20017830;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a890; PC = 0x80011bc *)
mov L0x2001a890 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a990; PC = 0x80011c0 *)
mov L0x2001a990 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa90; PC = 0x80011c4 *)
mov L0x2001aa90 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab90; PC = 0x80011c8 *)
mov L0x2001ab90 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac90; PC = 0x80011cc *)
mov L0x2001ac90 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad90; PC = 0x80011d0 *)
mov L0x2001ad90 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae90; PC = 0x80011d4 *)
mov L0x2001ae90 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af90; PC = 0x80011d8 *)
mov L0x2001af90 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a490; PC = 0x8001204 *)
mov L0x2001a490 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a590; PC = 0x8001208 *)
mov L0x2001a590 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a690; PC = 0x800120c *)
mov L0x2001a690 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a790; PC = 0x8001210 *)
mov L0x2001a790 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a190; PC = 0x8001214 *)
mov L0x2001a190 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a290; PC = 0x8001218 *)
mov L0x2001a290 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a390; PC = 0x800121c *)
mov L0x2001a390 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a090; PC = 0x8001220 *)
mov L0x2001a090 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178b2; Value = 0x00010000; PC = 0x8001044 *)
mov r4 L0x200178b2;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179b2; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x200179b2;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ab2; Value = 0x00010000; PC = 0x800104c *)
mov r6 L0x20017ab2;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bb2; Value = 0x00010000; PC = 0x8001050 *)
mov r7 L0x20017bb2;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017932; Value = 0x00000000; PC = 0x8001134 *)
mov r5 L0x20017932;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a32; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x20017a32;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b32; Value = 0xffff0001; PC = 0x800113c *)
mov r7 L0x20017b32;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017832; Value = 0x00010001; PC = 0x8001140 *)
mov r4 L0x20017832;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a894; PC = 0x80011bc *)
mov L0x2001a894 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a994; PC = 0x80011c0 *)
mov L0x2001a994 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa94; PC = 0x80011c4 *)
mov L0x2001aa94 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab94; PC = 0x80011c8 *)
mov L0x2001ab94 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac94; PC = 0x80011cc *)
mov L0x2001ac94 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad94; PC = 0x80011d0 *)
mov L0x2001ad94 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae94; PC = 0x80011d4 *)
mov L0x2001ae94 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af94; PC = 0x80011d8 *)
mov L0x2001af94 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a494; PC = 0x8001204 *)
mov L0x2001a494 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a594; PC = 0x8001208 *)
mov L0x2001a594 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a694; PC = 0x800120c *)
mov L0x2001a694 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a794; PC = 0x8001210 *)
mov L0x2001a794 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a194; PC = 0x8001214 *)
mov L0x2001a194 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a294; PC = 0x8001218 *)
mov L0x2001a294 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a394; PC = 0x800121c *)
mov L0x2001a394 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a094; PC = 0x8001220 *)
mov L0x2001a094 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178b4; Value = 0xffff0001; PC = 0x8001044 *)
mov r4 L0x200178b4;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179b4; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x200179b4;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ab4; Value = 0x00010001; PC = 0x800104c *)
mov r6 L0x20017ab4;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bb4; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017bb4;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017934; Value = 0x00010000; PC = 0x8001134 *)
mov r5 L0x20017934;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a34; Value = 0x0001ffff; PC = 0x8001138 *)
mov r6 L0x20017a34;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b34; Value = 0xffffffff; PC = 0x800113c *)
mov r7 L0x20017b34;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017834; Value = 0x00010001; PC = 0x8001140 *)
mov r4 L0x20017834;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a898; PC = 0x80011bc *)
mov L0x2001a898 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a998; PC = 0x80011c0 *)
mov L0x2001a998 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa98; PC = 0x80011c4 *)
mov L0x2001aa98 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab98; PC = 0x80011c8 *)
mov L0x2001ab98 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac98; PC = 0x80011cc *)
mov L0x2001ac98 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad98; PC = 0x80011d0 *)
mov L0x2001ad98 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae98; PC = 0x80011d4 *)
mov L0x2001ae98 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af98; PC = 0x80011d8 *)
mov L0x2001af98 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a498; PC = 0x8001204 *)
mov L0x2001a498 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a598; PC = 0x8001208 *)
mov L0x2001a598 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a698; PC = 0x800120c *)
mov L0x2001a698 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a798; PC = 0x8001210 *)
mov L0x2001a798 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a198; PC = 0x8001214 *)
mov L0x2001a198 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a298; PC = 0x8001218 *)
mov L0x2001a298 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a398; PC = 0x800121c *)
mov L0x2001a398 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a098; PC = 0x8001220 *)
mov L0x2001a098 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178b6; Value = 0x0001ffff; PC = 0x8001044 *)
mov r4 L0x200178b6;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179b6; Value = 0xffff0000; PC = 0x8001048 *)
mov r5 L0x200179b6;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ab6; Value = 0xffff0001; PC = 0x800104c *)
mov r6 L0x20017ab6;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bb6; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017bb6;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017936; Value = 0x00010001; PC = 0x8001134 *)
mov r5 L0x20017936;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a36; Value = 0x00010001; PC = 0x8001138 *)
mov r6 L0x20017a36;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b36; Value = 0x0000ffff; PC = 0x800113c *)
mov r7 L0x20017b36;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017836; Value = 0xffff0001; PC = 0x8001140 *)
mov r4 L0x20017836;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a89c; PC = 0x80011bc *)
mov L0x2001a89c r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a99c; PC = 0x80011c0 *)
mov L0x2001a99c r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aa9c; PC = 0x80011c4 *)
mov L0x2001aa9c r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001ab9c; PC = 0x80011c8 *)
mov L0x2001ab9c r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001ac9c; PC = 0x80011cc *)
mov L0x2001ac9c r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ad9c; PC = 0x80011d0 *)
mov L0x2001ad9c r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001ae9c; PC = 0x80011d4 *)
mov L0x2001ae9c r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001af9c; PC = 0x80011d8 *)
mov L0x2001af9c r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a49c; PC = 0x8001204 *)
mov L0x2001a49c r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a59c; PC = 0x8001208 *)
mov L0x2001a59c r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a69c; PC = 0x800120c *)
mov L0x2001a69c r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a79c; PC = 0x8001210 *)
mov L0x2001a79c r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a19c; PC = 0x8001214 *)
mov L0x2001a19c r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a29c; PC = 0x8001218 *)
mov L0x2001a29c r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a39c; PC = 0x800121c *)
mov L0x2001a39c r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a09c; PC = 0x8001220 *)
mov L0x2001a09c r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178b8; Value = 0xffff0001; PC = 0x8001044 *)
mov r4 L0x200178b8;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179b8; Value = 0x0001ffff; PC = 0x8001048 *)
mov r5 L0x200179b8;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ab8; Value = 0x0000ffff; PC = 0x800104c *)
mov r6 L0x20017ab8;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bb8; Value = 0x0001ffff; PC = 0x8001050 *)
mov r7 L0x20017bb8;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017938; Value = 0x00010001; PC = 0x8001134 *)
mov r5 L0x20017938;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a38; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x20017a38;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b38; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017b38;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017838; Value = 0xffffffff; PC = 0x8001140 *)
mov r4 L0x20017838;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8a0; PC = 0x80011bc *)
mov L0x2001a8a0 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9a0; PC = 0x80011c0 *)
mov L0x2001a9a0 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aaa0; PC = 0x80011c4 *)
mov L0x2001aaa0 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aba0; PC = 0x80011c8 *)
mov L0x2001aba0 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001aca0; PC = 0x80011cc *)
mov L0x2001aca0 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ada0; PC = 0x80011d0 *)
mov L0x2001ada0 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aea0; PC = 0x80011d4 *)
mov L0x2001aea0 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afa0; PC = 0x80011d8 *)
mov L0x2001afa0 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4a0; PC = 0x8001204 *)
mov L0x2001a4a0 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5a0; PC = 0x8001208 *)
mov L0x2001a5a0 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6a0; PC = 0x800120c *)
mov L0x2001a6a0 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7a0; PC = 0x8001210 *)
mov L0x2001a7a0 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1a0; PC = 0x8001214 *)
mov L0x2001a1a0 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2a0; PC = 0x8001218 *)
mov L0x2001a2a0 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3a0; PC = 0x800121c *)
mov L0x2001a3a0 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0a0; PC = 0x8001220 *)
mov L0x2001a0a0 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178ba; Value = 0x0000ffff; PC = 0x8001044 *)
mov r4 L0x200178ba;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179ba; Value = 0x00010001; PC = 0x8001048 *)
mov r5 L0x200179ba;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aba; Value = 0x00010000; PC = 0x800104c *)
mov r6 L0x20017aba;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bba; Value = 0x00000001; PC = 0x8001050 *)
mov r7 L0x20017bba;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001793a; Value = 0x00000001; PC = 0x8001134 *)
mov r5 L0x2001793a;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a3a; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x20017a3a;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b3a; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017b3a;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001783a; Value = 0x0000ffff; PC = 0x8001140 *)
mov r4 L0x2001783a;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8a4; PC = 0x80011bc *)
mov L0x2001a8a4 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9a4; PC = 0x80011c0 *)
mov L0x2001a9a4 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aaa4; PC = 0x80011c4 *)
mov L0x2001aaa4 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aba4; PC = 0x80011c8 *)
mov L0x2001aba4 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001aca4; PC = 0x80011cc *)
mov L0x2001aca4 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ada4; PC = 0x80011d0 *)
mov L0x2001ada4 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aea4; PC = 0x80011d4 *)
mov L0x2001aea4 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afa4; PC = 0x80011d8 *)
mov L0x2001afa4 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4a4; PC = 0x8001204 *)
mov L0x2001a4a4 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5a4; PC = 0x8001208 *)
mov L0x2001a5a4 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6a4; PC = 0x800120c *)
mov L0x2001a6a4 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7a4; PC = 0x8001210 *)
mov L0x2001a7a4 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1a4; PC = 0x8001214 *)
mov L0x2001a1a4 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2a4; PC = 0x8001218 *)
mov L0x2001a2a4 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3a4; PC = 0x800121c *)
mov L0x2001a3a4 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0a4; PC = 0x8001220 *)
mov L0x2001a0a4 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178bc; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x200178bc;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179bc; Value = 0xffff0001; PC = 0x8001048 *)
mov r5 L0x200179bc;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017abc; Value = 0xffff0001; PC = 0x800104c *)
mov r6 L0x20017abc;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bbc; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017bbc;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001793c; Value = 0x00010000; PC = 0x8001134 *)
mov r5 L0x2001793c;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a3c; Value = 0x00010000; PC = 0x8001138 *)
mov r6 L0x20017a3c;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b3c; Value = 0xffff0001; PC = 0x800113c *)
mov r7 L0x20017b3c;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001783c; Value = 0x00010000; PC = 0x8001140 *)
mov r4 L0x2001783c;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8a8; PC = 0x80011bc *)
mov L0x2001a8a8 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9a8; PC = 0x80011c0 *)
mov L0x2001a9a8 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aaa8; PC = 0x80011c4 *)
mov L0x2001aaa8 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001aba8; PC = 0x80011c8 *)
mov L0x2001aba8 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001aca8; PC = 0x80011cc *)
mov L0x2001aca8 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001ada8; PC = 0x80011d0 *)
mov L0x2001ada8 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aea8; PC = 0x80011d4 *)
mov L0x2001aea8 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afa8; PC = 0x80011d8 *)
mov L0x2001afa8 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4a8; PC = 0x8001204 *)
mov L0x2001a4a8 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5a8; PC = 0x8001208 *)
mov L0x2001a5a8 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6a8; PC = 0x800120c *)
mov L0x2001a6a8 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7a8; PC = 0x8001210 *)
mov L0x2001a7a8 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1a8; PC = 0x8001214 *)
mov L0x2001a1a8 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2a8; PC = 0x8001218 *)
mov L0x2001a2a8 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3a8; PC = 0x800121c *)
mov L0x2001a3a8 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0a8; PC = 0x8001220 *)
mov L0x2001a0a8 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178be; Value = 0x0001ffff; PC = 0x8001044 *)
mov r4 L0x200178be;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179be; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x200179be;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017abe; Value = 0x0001ffff; PC = 0x800104c *)
mov r6 L0x20017abe;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bbe; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017bbe;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001793e; Value = 0x00000001; PC = 0x8001134 *)
mov r5 L0x2001793e;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a3e; Value = 0xffff0001; PC = 0x8001138 *)
mov r6 L0x20017a3e;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b3e; Value = 0x0001ffff; PC = 0x800113c *)
mov r7 L0x20017b3e;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001783e; Value = 0x00010001; PC = 0x8001140 *)
mov r4 L0x2001783e;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8ac; PC = 0x80011bc *)
mov L0x2001a8ac r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9ac; PC = 0x80011c0 *)
mov L0x2001a9ac r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aaac; PC = 0x80011c4 *)
mov L0x2001aaac r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abac; PC = 0x80011c8 *)
mov L0x2001abac r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001acac; PC = 0x80011cc *)
mov L0x2001acac r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adac; PC = 0x80011d0 *)
mov L0x2001adac r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aeac; PC = 0x80011d4 *)
mov L0x2001aeac r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afac; PC = 0x80011d8 *)
mov L0x2001afac r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4ac; PC = 0x8001204 *)
mov L0x2001a4ac r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5ac; PC = 0x8001208 *)
mov L0x2001a5ac r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6ac; PC = 0x800120c *)
mov L0x2001a6ac r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7ac; PC = 0x8001210 *)
mov L0x2001a7ac r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1ac; PC = 0x8001214 *)
mov L0x2001a1ac r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2ac; PC = 0x8001218 *)
mov L0x2001a2ac r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3ac; PC = 0x800121c *)
mov L0x2001a3ac r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0ac; PC = 0x8001220 *)
mov L0x2001a0ac r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178c0; Value = 0x00010001; PC = 0x8001044 *)
mov r4 L0x200178c0;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179c0; Value = 0xffff0000; PC = 0x8001048 *)
mov r5 L0x200179c0;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ac0; Value = 0x00000001; PC = 0x800104c *)
mov r6 L0x20017ac0;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bc0; Value = 0x00000000; PC = 0x8001050 *)
mov r7 L0x20017bc0;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017940; Value = 0xffff0000; PC = 0x8001134 *)
mov r5 L0x20017940;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a40; Value = 0xffffffff; PC = 0x8001138 *)
mov r6 L0x20017a40;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b40; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017b40;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017840; Value = 0xffff0001; PC = 0x8001140 *)
mov r4 L0x20017840;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8b0; PC = 0x80011bc *)
mov L0x2001a8b0 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9b0; PC = 0x80011c0 *)
mov L0x2001a9b0 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aab0; PC = 0x80011c4 *)
mov L0x2001aab0 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abb0; PC = 0x80011c8 *)
mov L0x2001abb0 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001acb0; PC = 0x80011cc *)
mov L0x2001acb0 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adb0; PC = 0x80011d0 *)
mov L0x2001adb0 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aeb0; PC = 0x80011d4 *)
mov L0x2001aeb0 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afb0; PC = 0x80011d8 *)
mov L0x2001afb0 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4b0; PC = 0x8001204 *)
mov L0x2001a4b0 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5b0; PC = 0x8001208 *)
mov L0x2001a5b0 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6b0; PC = 0x800120c *)
mov L0x2001a6b0 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7b0; PC = 0x8001210 *)
mov L0x2001a7b0 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1b0; PC = 0x8001214 *)
mov L0x2001a1b0 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2b0; PC = 0x8001218 *)
mov L0x2001a2b0 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3b0; PC = 0x800121c *)
mov L0x2001a3b0 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0b0; PC = 0x8001220 *)
mov L0x2001a0b0 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178c2; Value = 0x00000001; PC = 0x8001044 *)
mov r4 L0x200178c2;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179c2; Value = 0x0000ffff; PC = 0x8001048 *)
mov r5 L0x200179c2;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ac2; Value = 0xffff0000; PC = 0x800104c *)
mov r6 L0x20017ac2;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bc2; Value = 0x00010000; PC = 0x8001050 *)
mov r7 L0x20017bc2;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017942; Value = 0x0000ffff; PC = 0x8001134 *)
mov r5 L0x20017942;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a42; Value = 0xffffffff; PC = 0x8001138 *)
mov r6 L0x20017a42;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b42; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017b42;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017842; Value = 0x0000ffff; PC = 0x8001140 *)
mov r4 L0x20017842;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8b4; PC = 0x80011bc *)
mov L0x2001a8b4 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9b4; PC = 0x80011c0 *)
mov L0x2001a9b4 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aab4; PC = 0x80011c4 *)
mov L0x2001aab4 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abb4; PC = 0x80011c8 *)
mov L0x2001abb4 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001acb4; PC = 0x80011cc *)
mov L0x2001acb4 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adb4; PC = 0x80011d0 *)
mov L0x2001adb4 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aeb4; PC = 0x80011d4 *)
mov L0x2001aeb4 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afb4; PC = 0x80011d8 *)
mov L0x2001afb4 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4b4; PC = 0x8001204 *)
mov L0x2001a4b4 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5b4; PC = 0x8001208 *)
mov L0x2001a5b4 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6b4; PC = 0x800120c *)
mov L0x2001a6b4 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7b4; PC = 0x8001210 *)
mov L0x2001a7b4 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1b4; PC = 0x8001214 *)
mov L0x2001a1b4 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2b4; PC = 0x8001218 *)
mov L0x2001a2b4 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3b4; PC = 0x800121c *)
mov L0x2001a3b4 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0b4; PC = 0x8001220 *)
mov L0x2001a0b4 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178c4; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x200178c4;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179c4; Value = 0x00000000; PC = 0x8001048 *)
mov r5 L0x200179c4;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ac4; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017ac4;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bc4; Value = 0xffff0001; PC = 0x8001050 *)
mov r7 L0x20017bc4;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017944; Value = 0x00000000; PC = 0x8001134 *)
mov r5 L0x20017944;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a44; Value = 0x0000ffff; PC = 0x8001138 *)
mov r6 L0x20017a44;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b44; Value = 0x00010001; PC = 0x800113c *)
mov r7 L0x20017b44;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017844; Value = 0x00010000; PC = 0x8001140 *)
mov r4 L0x20017844;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8b8; PC = 0x80011bc *)
mov L0x2001a8b8 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9b8; PC = 0x80011c0 *)
mov L0x2001a9b8 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aab8; PC = 0x80011c4 *)
mov L0x2001aab8 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abb8; PC = 0x80011c8 *)
mov L0x2001abb8 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001acb8; PC = 0x80011cc *)
mov L0x2001acb8 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adb8; PC = 0x80011d0 *)
mov L0x2001adb8 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aeb8; PC = 0x80011d4 *)
mov L0x2001aeb8 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afb8; PC = 0x80011d8 *)
mov L0x2001afb8 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4b8; PC = 0x8001204 *)
mov L0x2001a4b8 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5b8; PC = 0x8001208 *)
mov L0x2001a5b8 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6b8; PC = 0x800120c *)
mov L0x2001a6b8 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7b8; PC = 0x8001210 *)
mov L0x2001a7b8 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1b8; PC = 0x8001214 *)
mov L0x2001a1b8 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2b8; PC = 0x8001218 *)
mov L0x2001a2b8 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3b8; PC = 0x800121c *)
mov L0x2001a3b8 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0b8; PC = 0x8001220 *)
mov L0x2001a0b8 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178c6; Value = 0x0000ffff; PC = 0x8001044 *)
mov r4 L0x200178c6;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179c6; Value = 0x00010000; PC = 0x8001048 *)
mov r5 L0x200179c6;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ac6; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017ac6;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bc6; Value = 0xffffffff; PC = 0x8001050 *)
mov r7 L0x20017bc6;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017946; Value = 0xffff0000; PC = 0x8001134 *)
mov r5 L0x20017946;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a46; Value = 0x00000000; PC = 0x8001138 *)
mov r6 L0x20017a46;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b46; Value = 0x00000001; PC = 0x800113c *)
mov r7 L0x20017b46;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017846; Value = 0x00000001; PC = 0x8001140 *)
mov r4 L0x20017846;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8bc; PC = 0x80011bc *)
mov L0x2001a8bc r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9bc; PC = 0x80011c0 *)
mov L0x2001a9bc r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aabc; PC = 0x80011c4 *)
mov L0x2001aabc r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abbc; PC = 0x80011c8 *)
mov L0x2001abbc r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001acbc; PC = 0x80011cc *)
mov L0x2001acbc r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adbc; PC = 0x80011d0 *)
mov L0x2001adbc r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aebc; PC = 0x80011d4 *)
mov L0x2001aebc r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afbc; PC = 0x80011d8 *)
mov L0x2001afbc r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4bc; PC = 0x8001204 *)
mov L0x2001a4bc r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5bc; PC = 0x8001208 *)
mov L0x2001a5bc r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6bc; PC = 0x800120c *)
mov L0x2001a6bc r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7bc; PC = 0x8001210 *)
mov L0x2001a7bc r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1bc; PC = 0x8001214 *)
mov L0x2001a1bc r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2bc; PC = 0x8001218 *)
mov L0x2001a2bc r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3bc; PC = 0x800121c *)
mov L0x2001a3bc r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0bc; PC = 0x8001220 *)
mov L0x2001a0bc r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* vmov	lr, s0                                     #! PC = 0x8001040 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178c8; Value = 0xffff0000; PC = 0x8001044 *)
mov r4 L0x200178c8;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179c8; Value = 0x00000001; PC = 0x8001048 *)
mov r5 L0x200179c8;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ac8; Value = 0xffffffff; PC = 0x800104c *)
mov r6 L0x20017ac8;
(* ldrsh.w	r7, [lr, #896]	; 0x380                  #! EA = L0x20017bc8; Value = 0x5ce9ffff; PC = 0x8001050 *)
mov r7 L0x20017bc8;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001054 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001058 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x800105c *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001060 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001064 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001068 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x800106c *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001070 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001074 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001078 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800107a *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x800107c *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001080 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001084 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001088 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800108a *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x800108c *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800108e *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001090 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001094 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001098 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x800109c *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x80010a0 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x80010a4 *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010a8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80010ac *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80010b0 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80010b4 *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010b8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80010bc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80010c0 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80010c4 *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010c8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80010cc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80010d0 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80010d4 *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010d8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80010dc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80010e0 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80010e4 *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010e8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80010ec *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80010f0 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80010f4 *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80010f8 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80010fc *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x8001100 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x8001104 *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001108 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x800110c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001110 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x8001114 *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001118 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x800111c *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001120 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x8001124 *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001128 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x800112c *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001130 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x20017948; Value = 0xffffffff; PC = 0x8001134 *)
mov r5 L0x20017948;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a48; Value = 0xffff0000; PC = 0x8001138 *)
mov r6 L0x20017a48;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b48; Value = 0x00010000; PC = 0x800113c *)
mov r7 L0x20017b48;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x20017848; Value = 0xffff0000; PC = 0x8001140 *)
mov r4 L0x20017848;
(* vmov	s0, lr                                     #! PC = 0x8001144 *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001148 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x800114c *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001150 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001154 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001158 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x800115c *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001160 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001164 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001168 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x800116c *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x800116e *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001170 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001174 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001178 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x800117c *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x800117e *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001180 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001182 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001184 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001188 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x800118c *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001190 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x8001194 *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001198 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x800119c *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x80011a0 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x80011a4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011a6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011a8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011aa *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011ac *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011b0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011b4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80011b8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8c0; PC = 0x80011bc *)
mov L0x2001a8c0 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9c0; PC = 0x80011c0 *)
mov L0x2001a9c0 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aac0; PC = 0x80011c4 *)
mov L0x2001aac0 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abc0; PC = 0x80011c8 *)
mov L0x2001abc0 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001acc0; PC = 0x80011cc *)
mov L0x2001acc0 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adc0; PC = 0x80011d0 *)
mov L0x2001adc0 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aec0; PC = 0x80011d4 *)
mov L0x2001aec0 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afc0; PC = 0x80011d8 *)
mov L0x2001afc0 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80011dc *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80011e0 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80011e4 *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80011e8 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80011ec *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80011ee *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80011f0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80011f2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80011f4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80011f8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80011fc *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x8001200 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4c0; PC = 0x8001204 *)
mov L0x2001a4c0 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5c0; PC = 0x8001208 *)
mov L0x2001a5c0 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6c0; PC = 0x800120c *)
mov L0x2001a6c0 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7c0; PC = 0x8001210 *)
mov L0x2001a7c0 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1c0; PC = 0x8001214 *)
mov L0x2001a1c0 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2c0; PC = 0x8001218 *)
mov L0x2001a2c0 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3c0; PC = 0x800121c *)
mov L0x2001a3c0 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0c0; PC = 0x8001220 *)
mov L0x2001a0c0 r8;
(* vmov	r12, s2                                    #! PC = 0x8001224 *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001228 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001040 <_0_1_2_3_small>               #! PC = 0x800122c *)
#bne.w	0x8001040 <_0_1_2_3_small>               #! 0x800122c = 0x800122c;
(* add.w	r12, r0, #12                              #! PC = 0x8001230 *)
adds dontcare r12 r0 12@uint32;
(* vmov	s2, r12                                    #! PC = 0x8001234 *)
mov s2 r12;
(* vmov	lr, s0                                     #! PC = 0x8001238 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178ca; Value = 0x0000ffff; PC = 0x800123c *)
mov r4 L0x200178ca;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179ca; Value = 0x00000000; PC = 0x8001240 *)
mov r5 L0x200179ca;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017aca; Value = 0x0001ffff; PC = 0x8001244 *)
mov r6 L0x20017aca;
(* movw	r7, #0                                     #! PC = 0x8001248 *)
mov r7 0@sint32;
(* vmov	r12, lr, s9, s10                           #! PC = 0x800124c *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001250 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001254 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001258 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x800125c *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001260 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001264 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001268 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x800126c *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001270 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x8001272 *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001274 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001278 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x800127c *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001280 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x8001282 *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001284 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001286 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001288 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x800128c *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001290 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001294 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x8001298 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x800129c *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012a0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80012a4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80012a8 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80012ac *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012b0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80012b4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80012b8 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80012bc *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012c0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80012c4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80012c8 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80012cc *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012d0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80012d4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80012d8 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80012dc *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012e0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80012e4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80012e8 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80012ec *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012f0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80012f4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x80012f8 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x80012fc *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001300 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x8001304 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001308 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x800130c *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001310 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x8001314 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001318 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x800131c *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001320 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x8001324 *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001328 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001794a; Value = 0x0000ffff; PC = 0x800132c *)
mov r5 L0x2001794a;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a4a; Value = 0x0001ffff; PC = 0x8001330 *)
mov r6 L0x20017a4a;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b4a; Value = 0xffff0001; PC = 0x8001334 *)
mov r7 L0x20017b4a;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001784a; Value = 0xffffffff; PC = 0x8001338 *)
mov r4 L0x2001784a;
(* vmov	s0, lr                                     #! PC = 0x800133c *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001340 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001344 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001348 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x800134c *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001350 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001354 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001358 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x800135c *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001360 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001364 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x8001366 *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001368 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x800136c *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001370 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001374 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x8001376 *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001378 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800137a *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x800137c *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001380 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001384 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001388 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x800138c *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001390 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x8001394 *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x8001398 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x800139c *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x800139e *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80013a0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80013a2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80013a4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80013a8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80013ac *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80013b0 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8c4; PC = 0x80013b4 *)
mov L0x2001a8c4 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9c4; PC = 0x80013b8 *)
mov L0x2001a9c4 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aac4; PC = 0x80013bc *)
mov L0x2001aac4 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abc4; PC = 0x80013c0 *)
mov L0x2001abc4 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001acc4; PC = 0x80013c4 *)
mov L0x2001acc4 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adc4; PC = 0x80013c8 *)
mov L0x2001adc4 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aec4; PC = 0x80013cc *)
mov L0x2001aec4 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afc4; PC = 0x80013d0 *)
mov L0x2001afc4 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80013d4 *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80013d8 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80013dc *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80013e0 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80013e4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80013e6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80013e8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80013ea *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80013ec *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80013f0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80013f4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80013f8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4c4; PC = 0x80013fc *)
mov L0x2001a4c4 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5c4; PC = 0x8001400 *)
mov L0x2001a5c4 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6c4; PC = 0x8001404 *)
mov L0x2001a6c4 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7c4; PC = 0x8001408 *)
mov L0x2001a7c4 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1c4; PC = 0x800140c *)
mov L0x2001a1c4 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2c4; PC = 0x8001410 *)
mov L0x2001a2c4 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3c4; PC = 0x8001414 *)
mov L0x2001a3c4 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0c4; PC = 0x8001418 *)
mov L0x2001a0c4 r8;
(* vmov	r12, s2                                    #! PC = 0x800141c *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001420 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001238 <_0_1_2_3_small_last>          #! PC = 0x8001424 *)
#bne.w	0x8001238 <_0_1_2_3_small_last>          #! 0x8001424 = 0x8001424;
(* vmov	lr, s0                                     #! PC = 0x8001238 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178cc; Value = 0xffff0000; PC = 0x800123c *)
mov r4 L0x200178cc;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179cc; Value = 0x00010000; PC = 0x8001240 *)
mov r5 L0x200179cc;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017acc; Value = 0xffff0001; PC = 0x8001244 *)
mov r6 L0x20017acc;
(* movw	r7, #0                                     #! PC = 0x8001248 *)
mov r7 0@sint32;
(* vmov	r12, lr, s9, s10                           #! PC = 0x800124c *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001250 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001254 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001258 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x800125c *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001260 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001264 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001268 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x800126c *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001270 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x8001272 *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001274 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001278 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x800127c *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001280 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x8001282 *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001284 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001286 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001288 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x800128c *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001290 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001294 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x8001298 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x800129c *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012a0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80012a4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80012a8 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80012ac *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012b0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80012b4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80012b8 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80012bc *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012c0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80012c4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80012c8 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80012cc *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012d0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80012d4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80012d8 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80012dc *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012e0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80012e4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80012e8 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80012ec *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012f0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80012f4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x80012f8 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x80012fc *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001300 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x8001304 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001308 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x800130c *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001310 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x8001314 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001318 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x800131c *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001320 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x8001324 *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001328 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001794c; Value = 0xffff0000; PC = 0x800132c *)
mov r5 L0x2001794c;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a4c; Value = 0xffff0001; PC = 0x8001330 *)
mov r6 L0x20017a4c;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b4c; Value = 0x0000ffff; PC = 0x8001334 *)
mov r7 L0x20017b4c;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001784c; Value = 0xffffffff; PC = 0x8001338 *)
mov r4 L0x2001784c;
(* vmov	s0, lr                                     #! PC = 0x800133c *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001340 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001344 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001348 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x800134c *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001350 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001354 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001358 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x800135c *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001360 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001364 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x8001366 *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001368 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x800136c *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001370 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001374 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x8001376 *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001378 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800137a *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x800137c *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001380 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001384 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001388 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x800138c *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001390 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x8001394 *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x8001398 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x800139c *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x800139e *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80013a0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80013a2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80013a4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80013a8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80013ac *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80013b0 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8c8; PC = 0x80013b4 *)
mov L0x2001a8c8 r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9c8; PC = 0x80013b8 *)
mov L0x2001a9c8 r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aac8; PC = 0x80013bc *)
mov L0x2001aac8 r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abc8; PC = 0x80013c0 *)
mov L0x2001abc8 r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001acc8; PC = 0x80013c4 *)
mov L0x2001acc8 r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adc8; PC = 0x80013c8 *)
mov L0x2001adc8 r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aec8; PC = 0x80013cc *)
mov L0x2001aec8 r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afc8; PC = 0x80013d0 *)
mov L0x2001afc8 r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80013d4 *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80013d8 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80013dc *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80013e0 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80013e4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80013e6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80013e8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80013ea *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80013ec *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80013f0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80013f4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80013f8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4c8; PC = 0x80013fc *)
mov L0x2001a4c8 r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5c8; PC = 0x8001400 *)
mov L0x2001a5c8 r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6c8; PC = 0x8001404 *)
mov L0x2001a6c8 r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7c8; PC = 0x8001408 *)
mov L0x2001a7c8 r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1c8; PC = 0x800140c *)
mov L0x2001a1c8 r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2c8; PC = 0x8001410 *)
mov L0x2001a2c8 r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3c8; PC = 0x8001414 *)
mov L0x2001a3c8 r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0c8; PC = 0x8001418 *)
mov L0x2001a0c8 r8;
(* vmov	r12, s2                                    #! PC = 0x800141c *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001420 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001238 <_0_1_2_3_small_last>          #! PC = 0x8001424 *)
#bne.w	0x8001238 <_0_1_2_3_small_last>          #! 0x8001424 = 0x8001424;
(* vmov	lr, s0                                     #! PC = 0x8001238 *)
mov lr s0;
(* ldrsh.w	r4, [lr, #128]	; 0x80                   #! EA = L0x200178ce; Value = 0x0000ffff; PC = 0x800123c *)
mov r4 L0x200178ce;
(* ldrsh.w	r5, [lr, #384]	; 0x180                  #! EA = L0x200179ce; Value = 0x00010001; PC = 0x8001240 *)
mov r5 L0x200179ce;
(* ldrsh.w	r6, [lr, #640]	; 0x280                  #! EA = L0x20017ace; Value = 0x0001ffff; PC = 0x8001244 *)
mov r6 L0x20017ace;
(* movw	r7, #0                                     #! PC = 0x8001248 *)
mov r7 0@sint32;
(* vmov	r12, lr, s9, s10                           #! PC = 0x800124c *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001250 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001254 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x8001258 *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x800125c *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001260 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001264 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x8001268 *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x800126c *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001270 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x8001272 *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001274 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x8001278 *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x800127c *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001280 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x8001282 *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001284 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x8001286 *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x8001288 *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x800128c *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001290 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001294 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	r1, s11                                    #! PC = 0x8001298 *)
mov r1 s11;
(* smull	r12, r4, r4, r1                           #! PC = 0x800129c *)
smull r4 r12 r4 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012a0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r4, lr, r3                           #! PC = 0x80012a4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r4 r4 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s12                                    #! PC = 0x80012a8 *)
mov r1 s12;
(* smull	r12, r5, r5, r1                           #! PC = 0x80012ac *)
smull r5 r12 r5 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012b0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r5, lr, r3                           #! PC = 0x80012b4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r5 r5 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s13                                    #! PC = 0x80012b8 *)
mov r1 s13;
(* smull	r12, r6, r6, r1                           #! PC = 0x80012bc *)
smull r6 r12 r6 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012c0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r6, lr, r3                           #! PC = 0x80012c4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r6 r6 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s14                                    #! PC = 0x80012c8 *)
mov r1 s14;
(* smull	r12, r7, r7, r1                           #! PC = 0x80012cc *)
smull r7 r12 r7 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012d0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r7, lr, r3                           #! PC = 0x80012d4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r7 r7 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s15                                    #! PC = 0x80012d8 *)
mov r1 s15;
(* smull	r12, r8, r8, r1                           #! PC = 0x80012dc *)
smull r8 r12 r8 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012e0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r8, lr, r3                           #! PC = 0x80012e4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r8 r8 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s16                                    #! PC = 0x80012e8 *)
mov r1 s16;
(* smull	r12, r9, r9, r1                           #! PC = 0x80012ec *)
smull r9 r12 r9 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x80012f0 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r9, lr, r3                           #! PC = 0x80012f4 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r9 r9 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s17                                    #! PC = 0x80012f8 *)
mov r1 s17;
(* smull	r12, r10, r10, r1                         #! PC = 0x80012fc *)
smull r10 r12 r10 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001300 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r10, lr, r3                          #! PC = 0x8001304 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r10 r10 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	r1, s18                                    #! PC = 0x8001308 *)
mov r1 s18;
(* smull	r12, r11, r11, r1                         #! PC = 0x800130c *)
smull r11 r12 r11 r1;
(* mul.w	lr, r12, r2                               #! PC = 0x8001310 *)
mull dontcare lr r12 r2;
cast lr@sint32 lr;
(* smlal	r12, r11, lr, r3                          #! PC = 0x8001314 *)
smull tmpml_h tmpml_l lr r3;
adds carry r12 r12 tmpml_l;
adc r11 r11 tmpml_h carry;
assert eqmod r12 0 (2**32) && true;
assume r12 = 0 && true;
(* vmov	s20, s21, r4, r5                           #! PC = 0x8001318 *)
mov s20 r4;
mov s21 r5;
(* vmov	s22, s23, r6, r7                           #! PC = 0x800131c *)
mov s22 r6;
mov s23 r7;
(* vmov	s24, s25, r8, r9                           #! PC = 0x8001320 *)
mov s24 r8;
mov s25 r9;
(* vmov	s26, s27, r10, r11                         #! PC = 0x8001324 *)
mov s26 r10;
mov s27 r11;
(* vmov	lr, s0                                     #! PC = 0x8001328 *)
mov lr s0;
(* ldrsh.w	r5, [lr, #256]	; 0x100                  #! EA = L0x2001794e; Value = 0x0001ffff; PC = 0x800132c *)
mov r5 L0x2001794e;
(* ldrsh.w	r6, [lr, #512]	; 0x200                  #! EA = L0x20017a4e; Value = 0x0001ffff; PC = 0x8001330 *)
mov r6 L0x20017a4e;
(* ldrsh.w	r7, [lr, #768]	; 0x300                  #! EA = L0x20017b4e; Value = 0x00010000; PC = 0x8001334 *)
mov r7 L0x20017b4e;
(* ldrsh.w	r4, [lr], #2                            #! EA = L0x2001784e; Value = 0x0000ffff; PC = 0x8001338 *)
mov r4 L0x2001784e;
(* vmov	s0, lr                                     #! PC = 0x800133c *)
mov s0 lr;
(* vmov	r12, lr, s9, s10                           #! PC = 0x8001340 *)
mov r12 s9;
mov lr s10;
(* mul.w	r9, r5, r12                               #! PC = 0x8001344 *)
mul r9 r5 r12;
(* mla	r9, r7, lr, r9                              #! PC = 0x8001348 *)
mul tmpmla r7 lr;
add r9 tmpmla r9;
(* mul.w	r11, r5, lr                               #! PC = 0x800134c *)
mul r11 r5 lr;
(* mla	r11, r7, r12, r11                           #! PC = 0x8001350 *)
mul tmpmla r7 r12;
add r11 tmpmla r11;
(* vmov	r1, s6                                     #! PC = 0x8001354 *)
mov r1 s6;
(* mul.w	r10, r6, r1                               #! PC = 0x8001358 *)
mul r10 r6 r1;
(* add.w	r8, r4, r10                               #! PC = 0x800135c *)
add r8 r4 r10;
(* sub.w	r10, r8, r10, lsl #1                      #! PC = 0x8001360 *)
shl tmpx2 r10 1;
sub r10 r8 tmpx2;
(* add	r4, r6                                      #! PC = 0x8001364 *)
add r4 r4 r6;
(* add	r5, r7                                      #! PC = 0x8001366 *)
add r5 r5 r7;
(* sub.w	r6, r4, r6, lsl #1                        #! PC = 0x8001368 *)
shl tmpx2 r6 1;
sub r6 r4 tmpx2;
(* sub.w	r7, r5, r7, lsl #1                        #! PC = 0x800136c *)
shl tmpx2 r7 1;
sub r7 r5 tmpx2;
(* mul.w	r7, r7, r1                                #! PC = 0x8001370 *)
mul r7 r7 r1;
(* add	r4, r5                                      #! PC = 0x8001374 *)
add r4 r4 r5;
(* add	r6, r7                                      #! PC = 0x8001376 *)
add r6 r6 r7;
(* add	r8, r9                                      #! PC = 0x8001378 *)
add r8 r8 r9;
(* add	r10, r11                                    #! PC = 0x800137a *)
add r10 r10 r11;
(* sub.w	r5, r4, r5, lsl #1                        #! PC = 0x800137c *)
shl tmpx2 r5 1;
sub r5 r4 tmpx2;
(* sub.w	r7, r6, r7, lsl #1                        #! PC = 0x8001380 *)
shl tmpx2 r7 1;
sub r7 r6 tmpx2;
(* sub.w	r9, r8, r9, lsl #1                        #! PC = 0x8001384 *)
shl tmpx2 r9 1;
sub r9 r8 tmpx2;
(* sub.w	r11, r10, r11, lsl #1                     #! PC = 0x8001388 *)
shl tmpx2 r11 1;
sub r11 r10 tmpx2;
(* vmov	s28, s29, r4, r5                           #! PC = 0x800138c *)
mov s28 r4;
mov s29 r5;
(* vmov	s30, s31, r6, r7                           #! PC = 0x8001390 *)
mov s30 r6;
mov s31 r7;
(* vmov	r4, r5, s24, s25                           #! PC = 0x8001394 *)
mov r4 s24;
mov r5 s25;
(* vmov	r6, r7, s26, s27                           #! PC = 0x8001398 *)
mov r6 s26;
mov r7 s27;
(* add	r8, r4                                      #! PC = 0x800139c *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x800139e *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80013a0 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80013a2 *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80013a4 *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80013a8 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80013ac *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80013b0 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r8, [r0, #2048]	; 0x800                   #! EA = L0x2001a8cc; PC = 0x80013b4 *)
mov L0x2001a8cc r8;
(* str.w	r4, [r0, #2304]	; 0x900                   #! EA = L0x2001a9cc; PC = 0x80013b8 *)
mov L0x2001a9cc r4;
(* str.w	r9, [r0, #2560]	; 0xa00                   #! EA = L0x2001aacc; PC = 0x80013bc *)
mov L0x2001aacc r9;
(* str.w	r5, [r0, #2816]	; 0xb00                   #! EA = L0x2001abcc; PC = 0x80013c0 *)
mov L0x2001abcc r5;
(* str.w	r10, [r0, #3072]	; 0xc00                  #! EA = L0x2001accc; PC = 0x80013c4 *)
mov L0x2001accc r10;
(* str.w	r6, [r0, #3328]	; 0xd00                   #! EA = L0x2001adcc; PC = 0x80013c8 *)
mov L0x2001adcc r6;
(* str.w	r11, [r0, #3584]	; 0xe00                  #! EA = L0x2001aecc; PC = 0x80013cc *)
mov L0x2001aecc r11;
(* str.w	r7, [r0, #3840]	; 0xf00                   #! EA = L0x2001afcc; PC = 0x80013d0 *)
mov L0x2001afcc r7;
(* vmov	r4, r5, s20, s21                           #! PC = 0x80013d4 *)
mov r4 s20;
mov r5 s21;
(* vmov	r6, r7, s22, s23                           #! PC = 0x80013d8 *)
mov r6 s22;
mov r7 s23;
(* vmov	r8, r9, s28, s29                           #! PC = 0x80013dc *)
mov r8 s28;
mov r9 s29;
(* vmov	r10, r11, s30, s31                         #! PC = 0x80013e0 *)
mov r10 s30;
mov r11 s31;
(* add	r8, r4                                      #! PC = 0x80013e4 *)
add r8 r8 r4;
(* add	r9, r5                                      #! PC = 0x80013e6 *)
add r9 r9 r5;
(* add	r10, r6                                     #! PC = 0x80013e8 *)
add r10 r10 r6;
(* add	r11, r7                                     #! PC = 0x80013ea *)
add r11 r11 r7;
(* sub.w	r4, r8, r4, lsl #1                        #! PC = 0x80013ec *)
shl tmpx2 r4 1;
sub r4 r8 tmpx2;
(* sub.w	r5, r9, r5, lsl #1                        #! PC = 0x80013f0 *)
shl tmpx2 r5 1;
sub r5 r9 tmpx2;
(* sub.w	r6, r10, r6, lsl #1                       #! PC = 0x80013f4 *)
shl tmpx2 r6 1;
sub r6 r10 tmpx2;
(* sub.w	r7, r11, r7, lsl #1                       #! PC = 0x80013f8 *)
shl tmpx2 r7 1;
sub r7 r11 tmpx2;
(* str.w	r10, [r0, #1024]	; 0x400                  #! EA = L0x2001a4cc; PC = 0x80013fc *)
mov L0x2001a4cc r10;
(* str.w	r6, [r0, #1280]	; 0x500                   #! EA = L0x2001a5cc; PC = 0x8001400 *)
mov L0x2001a5cc r6;
(* str.w	r11, [r0, #1536]	; 0x600                  #! EA = L0x2001a6cc; PC = 0x8001404 *)
mov L0x2001a6cc r11;
(* str.w	r7, [r0, #1792]	; 0x700                   #! EA = L0x2001a7cc; PC = 0x8001408 *)
mov L0x2001a7cc r7;
(* str.w	r4, [r0, #256]	; 0x100                    #! EA = L0x2001a1cc; PC = 0x800140c *)
mov L0x2001a1cc r4;
(* str.w	r9, [r0, #512]	; 0x200                    #! EA = L0x2001a2cc; PC = 0x8001410 *)
mov L0x2001a2cc r9;
(* str.w	r5, [r0, #768]	; 0x300                    #! EA = L0x2001a3cc; PC = 0x8001414 *)
mov L0x2001a3cc r5;
(* str.w	r8, [r0], #4                              #! EA = L0x2001a0cc; PC = 0x8001418 *)
mov L0x2001a0cc r8;
(* vmov	r12, s2                                    #! PC = 0x800141c *)
mov r12 s2;
(* cmp.w	r0, r12                                   #! PC = 0x8001420 *)
(* cmp.w r0, r12 *)
nop;
(* #bne.w	0x8001238 <_0_1_2_3_small_last>          #! PC = 0x8001424 *)
#bne.w	0x8001238 <_0_1_2_3_small_last>          #! 0x8001424 = 0x8001424;
(* #vpop	{s16-s31}                                  #! PC = 0x8001428 *)
#vpop	{%%s16-%%s31}                                  #! 0x8001428 = 0x8001428;
(* #ldmia.w	sp!, {r4, r5, r6, r7, r8, r9, r10, r11, r12, pc}#! EA = L0x20016f88; Value = 0x20016fd0; PC = 0x800142c *)
#ldmia.w	sp!, {%%r4, %%r5, %%r6, %%r7, %%r8, %%r9, %%r10, %%r11, %%r12, pc}#! L0x20016f88 = L0x20016f88; 0x20016fd0 = 0x20016fd0; 0x800142c = 0x800142c;
(* #adds	r5, #32                                    #! PC = 0x800033e *)
#adds	%%r5, #32                                    #! 0x800033e = 0x800033e;

{
and [
eqmod (inp_poly**2)
    (L0x20019fd0*(x** 0)+L0x20019fd4*(x** 1)+L0x20019fd8*(x** 2)+
     L0x20019fdc*(x** 3)+L0x20019fe0*(x** 4)+L0x20019fe4*(x** 5)+
     L0x20019fe8*(x** 6)+L0x20019fec*(x** 7)+L0x20019ff0*(x** 8)+
     L0x20019ff4*(x** 9)+L0x20019ff8*(x**10)+L0x20019ffc*(x**11)+
     L0x2001a000*(x**12)+L0x2001a004*(x**13)+L0x2001a008*(x**14)+
     L0x2001a00c*(x**15)+L0x2001a010*(x**16)+L0x2001a014*(x**17)+
     L0x2001a018*(x**18)+L0x2001a01c*(x**19)+L0x2001a020*(x**20)+
     L0x2001a024*(x**21)+L0x2001a028*(x**22)+L0x2001a02c*(x**23)+
     L0x2001a030*(x**24)+L0x2001a034*(x**25)+L0x2001a038*(x**26)+
     L0x2001a03c*(x**27)+L0x2001a040*(x**28)+L0x2001a044*(x**29)+
     L0x2001a048*(x**30)+L0x2001a04c*(x**31)+L0x2001a050*(x**32)+
     L0x2001a054*(x**33)+L0x2001a058*(x**34)+L0x2001a05c*(x**35)+
     L0x2001a060*(x**36)+L0x2001a064*(x**37)+L0x2001a068*(x**38)+
     L0x2001a06c*(x**39)+L0x2001a070*(x**40)+L0x2001a074*(x**41)+
     L0x2001a078*(x**42)+L0x2001a07c*(x**43)+L0x2001a080*(x**44)+
     L0x2001a084*(x**45)+L0x2001a088*(x**46)+L0x2001a08c*(x**47)+
     L0x2001a090*(x**48)+L0x2001a094*(x**49)+L0x2001a098*(x**50)+
     L0x2001a09c*(x**51)+L0x2001a0a0*(x**52)+L0x2001a0a4*(x**53)+
     L0x2001a0a8*(x**54)+L0x2001a0ac*(x**55)+L0x2001a0b0*(x**56)+
     L0x2001a0b4*(x**57)+L0x2001a0b8*(x**58)+L0x2001a0bc*(x**59)+
     L0x2001a0c0*(x**60)+L0x2001a0c4*(x**61)+L0x2001a0c8*(x**62)+
     L0x2001a0cc*(x**63))
    [1043969, x**64 - 1],
eqmod (inp_poly**2)
    (L0x2001a0d0*(x** 0)+L0x2001a0d4*(x** 1)+L0x2001a0d8*(x** 2)+
     L0x2001a0dc*(x** 3)+L0x2001a0e0*(x** 4)+L0x2001a0e4*(x** 5)+
     L0x2001a0e8*(x** 6)+L0x2001a0ec*(x** 7)+L0x2001a0f0*(x** 8)+
     L0x2001a0f4*(x** 9)+L0x2001a0f8*(x**10)+L0x2001a0fc*(x**11)+
     L0x2001a100*(x**12)+L0x2001a104*(x**13)+L0x2001a108*(x**14)+
     L0x2001a10c*(x**15)+L0x2001a110*(x**16)+L0x2001a114*(x**17)+
     L0x2001a118*(x**18)+L0x2001a11c*(x**19)+L0x2001a120*(x**20)+
     L0x2001a124*(x**21)+L0x2001a128*(x**22)+L0x2001a12c*(x**23)+
     L0x2001a130*(x**24)+L0x2001a134*(x**25)+L0x2001a138*(x**26)+
     L0x2001a13c*(x**27)+L0x2001a140*(x**28)+L0x2001a144*(x**29)+
     L0x2001a148*(x**30)+L0x2001a14c*(x**31)+L0x2001a150*(x**32)+
     L0x2001a154*(x**33)+L0x2001a158*(x**34)+L0x2001a15c*(x**35)+
     L0x2001a160*(x**36)+L0x2001a164*(x**37)+L0x2001a168*(x**38)+
     L0x2001a16c*(x**39)+L0x2001a170*(x**40)+L0x2001a174*(x**41)+
     L0x2001a178*(x**42)+L0x2001a17c*(x**43)+L0x2001a180*(x**44)+
     L0x2001a184*(x**45)+L0x2001a188*(x**46)+L0x2001a18c*(x**47)+
     L0x2001a190*(x**48)+L0x2001a194*(x**49)+L0x2001a198*(x**50)+
     L0x2001a19c*(x**51)+L0x2001a1a0*(x**52)+L0x2001a1a4*(x**53)+
     L0x2001a1a8*(x**54)+L0x2001a1ac*(x**55)+L0x2001a1b0*(x**56)+
     L0x2001a1b4*(x**57)+L0x2001a1b8*(x**58)+L0x2001a1bc*(x**59)+
     L0x2001a1c0*(x**60)+L0x2001a1c4*(x**61)+L0x2001a1c8*(x**62)+
     L0x2001a1cc*(x**63))
    [1043969, x**64 - 1043968],
eqmod (inp_poly**2)
    (L0x2001a1d0*(x** 0)+L0x2001a1d4*(x** 1)+L0x2001a1d8*(x** 2)+
     L0x2001a1dc*(x** 3)+L0x2001a1e0*(x** 4)+L0x2001a1e4*(x** 5)+
     L0x2001a1e8*(x** 6)+L0x2001a1ec*(x** 7)+L0x2001a1f0*(x** 8)+
     L0x2001a1f4*(x** 9)+L0x2001a1f8*(x**10)+L0x2001a1fc*(x**11)+
     L0x2001a200*(x**12)+L0x2001a204*(x**13)+L0x2001a208*(x**14)+
     L0x2001a20c*(x**15)+L0x2001a210*(x**16)+L0x2001a214*(x**17)+
     L0x2001a218*(x**18)+L0x2001a21c*(x**19)+L0x2001a220*(x**20)+
     L0x2001a224*(x**21)+L0x2001a228*(x**22)+L0x2001a22c*(x**23)+
     L0x2001a230*(x**24)+L0x2001a234*(x**25)+L0x2001a238*(x**26)+
     L0x2001a23c*(x**27)+L0x2001a240*(x**28)+L0x2001a244*(x**29)+
     L0x2001a248*(x**30)+L0x2001a24c*(x**31)+L0x2001a250*(x**32)+
     L0x2001a254*(x**33)+L0x2001a258*(x**34)+L0x2001a25c*(x**35)+
     L0x2001a260*(x**36)+L0x2001a264*(x**37)+L0x2001a268*(x**38)+
     L0x2001a26c*(x**39)+L0x2001a270*(x**40)+L0x2001a274*(x**41)+
     L0x2001a278*(x**42)+L0x2001a27c*(x**43)+L0x2001a280*(x**44)+
     L0x2001a284*(x**45)+L0x2001a288*(x**46)+L0x2001a28c*(x**47)+
     L0x2001a290*(x**48)+L0x2001a294*(x**49)+L0x2001a298*(x**50)+
     L0x2001a29c*(x**51)+L0x2001a2a0*(x**52)+L0x2001a2a4*(x**53)+
     L0x2001a2a8*(x**54)+L0x2001a2ac*(x**55)+L0x2001a2b0*(x**56)+
     L0x2001a2b4*(x**57)+L0x2001a2b8*(x**58)+L0x2001a2bc*(x**59)+
     L0x2001a2c0*(x**60)+L0x2001a2c4*(x**61)+L0x2001a2c8*(x**62)+
     L0x2001a2cc*(x**63))
    [1043969, x**64 - 554923],
eqmod (inp_poly**2)
    (L0x2001a2d0*(x** 0)+L0x2001a2d4*(x** 1)+L0x2001a2d8*(x** 2)+
     L0x2001a2dc*(x** 3)+L0x2001a2e0*(x** 4)+L0x2001a2e4*(x** 5)+
     L0x2001a2e8*(x** 6)+L0x2001a2ec*(x** 7)+L0x2001a2f0*(x** 8)+
     L0x2001a2f4*(x** 9)+L0x2001a2f8*(x**10)+L0x2001a2fc*(x**11)+
     L0x2001a300*(x**12)+L0x2001a304*(x**13)+L0x2001a308*(x**14)+
     L0x2001a30c*(x**15)+L0x2001a310*(x**16)+L0x2001a314*(x**17)+
     L0x2001a318*(x**18)+L0x2001a31c*(x**19)+L0x2001a320*(x**20)+
     L0x2001a324*(x**21)+L0x2001a328*(x**22)+L0x2001a32c*(x**23)+
     L0x2001a330*(x**24)+L0x2001a334*(x**25)+L0x2001a338*(x**26)+
     L0x2001a33c*(x**27)+L0x2001a340*(x**28)+L0x2001a344*(x**29)+
     L0x2001a348*(x**30)+L0x2001a34c*(x**31)+L0x2001a350*(x**32)+
     L0x2001a354*(x**33)+L0x2001a358*(x**34)+L0x2001a35c*(x**35)+
     L0x2001a360*(x**36)+L0x2001a364*(x**37)+L0x2001a368*(x**38)+
     L0x2001a36c*(x**39)+L0x2001a370*(x**40)+L0x2001a374*(x**41)+
     L0x2001a378*(x**42)+L0x2001a37c*(x**43)+L0x2001a380*(x**44)+
     L0x2001a384*(x**45)+L0x2001a388*(x**46)+L0x2001a38c*(x**47)+
     L0x2001a390*(x**48)+L0x2001a394*(x**49)+L0x2001a398*(x**50)+
     L0x2001a39c*(x**51)+L0x2001a3a0*(x**52)+L0x2001a3a4*(x**53)+
     L0x2001a3a8*(x**54)+L0x2001a3ac*(x**55)+L0x2001a3b0*(x**56)+
     L0x2001a3b4*(x**57)+L0x2001a3b8*(x**58)+L0x2001a3bc*(x**59)+
     L0x2001a3c0*(x**60)+L0x2001a3c4*(x**61)+L0x2001a3c8*(x**62)+
     L0x2001a3cc*(x**63))
    [1043969, x**64 - 489046],
eqmod (inp_poly**2)
    (L0x2001a3d0*(x** 0)+L0x2001a3d4*(x** 1)+L0x2001a3d8*(x** 2)+
     L0x2001a3dc*(x** 3)+L0x2001a3e0*(x** 4)+L0x2001a3e4*(x** 5)+
     L0x2001a3e8*(x** 6)+L0x2001a3ec*(x** 7)+L0x2001a3f0*(x** 8)+
     L0x2001a3f4*(x** 9)+L0x2001a3f8*(x**10)+L0x2001a3fc*(x**11)+
     L0x2001a400*(x**12)+L0x2001a404*(x**13)+L0x2001a408*(x**14)+
     L0x2001a40c*(x**15)+L0x2001a410*(x**16)+L0x2001a414*(x**17)+
     L0x2001a418*(x**18)+L0x2001a41c*(x**19)+L0x2001a420*(x**20)+
     L0x2001a424*(x**21)+L0x2001a428*(x**22)+L0x2001a42c*(x**23)+
     L0x2001a430*(x**24)+L0x2001a434*(x**25)+L0x2001a438*(x**26)+
     L0x2001a43c*(x**27)+L0x2001a440*(x**28)+L0x2001a444*(x**29)+
     L0x2001a448*(x**30)+L0x2001a44c*(x**31)+L0x2001a450*(x**32)+
     L0x2001a454*(x**33)+L0x2001a458*(x**34)+L0x2001a45c*(x**35)+
     L0x2001a460*(x**36)+L0x2001a464*(x**37)+L0x2001a468*(x**38)+
     L0x2001a46c*(x**39)+L0x2001a470*(x**40)+L0x2001a474*(x**41)+
     L0x2001a478*(x**42)+L0x2001a47c*(x**43)+L0x2001a480*(x**44)+
     L0x2001a484*(x**45)+L0x2001a488*(x**46)+L0x2001a48c*(x**47)+
     L0x2001a490*(x**48)+L0x2001a494*(x**49)+L0x2001a498*(x**50)+
     L0x2001a49c*(x**51)+L0x2001a4a0*(x**52)+L0x2001a4a4*(x**53)+
     L0x2001a4a8*(x**54)+L0x2001a4ac*(x**55)+L0x2001a4b0*(x**56)+
     L0x2001a4b4*(x**57)+L0x2001a4b8*(x**58)+L0x2001a4bc*(x**59)+
     L0x2001a4c0*(x**60)+L0x2001a4c4*(x**61)+L0x2001a4c8*(x**62)+
     L0x2001a4cc*(x**63))
    [1043969, x**64 - 287998],
eqmod (inp_poly**2)
    (L0x2001a4d0*(x** 0)+L0x2001a4d4*(x** 1)+L0x2001a4d8*(x** 2)+
     L0x2001a4dc*(x** 3)+L0x2001a4e0*(x** 4)+L0x2001a4e4*(x** 5)+
     L0x2001a4e8*(x** 6)+L0x2001a4ec*(x** 7)+L0x2001a4f0*(x** 8)+
     L0x2001a4f4*(x** 9)+L0x2001a4f8*(x**10)+L0x2001a4fc*(x**11)+
     L0x2001a500*(x**12)+L0x2001a504*(x**13)+L0x2001a508*(x**14)+
     L0x2001a50c*(x**15)+L0x2001a510*(x**16)+L0x2001a514*(x**17)+
     L0x2001a518*(x**18)+L0x2001a51c*(x**19)+L0x2001a520*(x**20)+
     L0x2001a524*(x**21)+L0x2001a528*(x**22)+L0x2001a52c*(x**23)+
     L0x2001a530*(x**24)+L0x2001a534*(x**25)+L0x2001a538*(x**26)+
     L0x2001a53c*(x**27)+L0x2001a540*(x**28)+L0x2001a544*(x**29)+
     L0x2001a548*(x**30)+L0x2001a54c*(x**31)+L0x2001a550*(x**32)+
     L0x2001a554*(x**33)+L0x2001a558*(x**34)+L0x2001a55c*(x**35)+
     L0x2001a560*(x**36)+L0x2001a564*(x**37)+L0x2001a568*(x**38)+
     L0x2001a56c*(x**39)+L0x2001a570*(x**40)+L0x2001a574*(x**41)+
     L0x2001a578*(x**42)+L0x2001a57c*(x**43)+L0x2001a580*(x**44)+
     L0x2001a584*(x**45)+L0x2001a588*(x**46)+L0x2001a58c*(x**47)+
     L0x2001a590*(x**48)+L0x2001a594*(x**49)+L0x2001a598*(x**50)+
     L0x2001a59c*(x**51)+L0x2001a5a0*(x**52)+L0x2001a5a4*(x**53)+
     L0x2001a5a8*(x**54)+L0x2001a5ac*(x**55)+L0x2001a5b0*(x**56)+
     L0x2001a5b4*(x**57)+L0x2001a5b8*(x**58)+L0x2001a5bc*(x**59)+
     L0x2001a5c0*(x**60)+L0x2001a5c4*(x**61)+L0x2001a5c8*(x**62)+
     L0x2001a5cc*(x**63))
    [1043969, x**64 - 755971],
eqmod (inp_poly**2)
    (L0x2001a5d0*(x** 0)+L0x2001a5d4*(x** 1)+L0x2001a5d8*(x** 2)+
     L0x2001a5dc*(x** 3)+L0x2001a5e0*(x** 4)+L0x2001a5e4*(x** 5)+
     L0x2001a5e8*(x** 6)+L0x2001a5ec*(x** 7)+L0x2001a5f0*(x** 8)+
     L0x2001a5f4*(x** 9)+L0x2001a5f8*(x**10)+L0x2001a5fc*(x**11)+
     L0x2001a600*(x**12)+L0x2001a604*(x**13)+L0x2001a608*(x**14)+
     L0x2001a60c*(x**15)+L0x2001a610*(x**16)+L0x2001a614*(x**17)+
     L0x2001a618*(x**18)+L0x2001a61c*(x**19)+L0x2001a620*(x**20)+
     L0x2001a624*(x**21)+L0x2001a628*(x**22)+L0x2001a62c*(x**23)+
     L0x2001a630*(x**24)+L0x2001a634*(x**25)+L0x2001a638*(x**26)+
     L0x2001a63c*(x**27)+L0x2001a640*(x**28)+L0x2001a644*(x**29)+
     L0x2001a648*(x**30)+L0x2001a64c*(x**31)+L0x2001a650*(x**32)+
     L0x2001a654*(x**33)+L0x2001a658*(x**34)+L0x2001a65c*(x**35)+
     L0x2001a660*(x**36)+L0x2001a664*(x**37)+L0x2001a668*(x**38)+
     L0x2001a66c*(x**39)+L0x2001a670*(x**40)+L0x2001a674*(x**41)+
     L0x2001a678*(x**42)+L0x2001a67c*(x**43)+L0x2001a680*(x**44)+
     L0x2001a684*(x**45)+L0x2001a688*(x**46)+L0x2001a68c*(x**47)+
     L0x2001a690*(x**48)+L0x2001a694*(x**49)+L0x2001a698*(x**50)+
     L0x2001a69c*(x**51)+L0x2001a6a0*(x**52)+L0x2001a6a4*(x**53)+
     L0x2001a6a8*(x**54)+L0x2001a6ac*(x**55)+L0x2001a6b0*(x**56)+
     L0x2001a6b4*(x**57)+L0x2001a6b8*(x**58)+L0x2001a6bc*(x**59)+
     L0x2001a6c0*(x**60)+L0x2001a6c4*(x**61)+L0x2001a6c8*(x**62)+
     L0x2001a6cc*(x**63))
    [1043969, x**64 - 719789],
eqmod (inp_poly**2)
    (L0x2001a6d0*(x** 0)+L0x2001a6d4*(x** 1)+L0x2001a6d8*(x** 2)+
     L0x2001a6dc*(x** 3)+L0x2001a6e0*(x** 4)+L0x2001a6e4*(x** 5)+
     L0x2001a6e8*(x** 6)+L0x2001a6ec*(x** 7)+L0x2001a6f0*(x** 8)+
     L0x2001a6f4*(x** 9)+L0x2001a6f8*(x**10)+L0x2001a6fc*(x**11)+
     L0x2001a700*(x**12)+L0x2001a704*(x**13)+L0x2001a708*(x**14)+
     L0x2001a70c*(x**15)+L0x2001a710*(x**16)+L0x2001a714*(x**17)+
     L0x2001a718*(x**18)+L0x2001a71c*(x**19)+L0x2001a720*(x**20)+
     L0x2001a724*(x**21)+L0x2001a728*(x**22)+L0x2001a72c*(x**23)+
     L0x2001a730*(x**24)+L0x2001a734*(x**25)+L0x2001a738*(x**26)+
     L0x2001a73c*(x**27)+L0x2001a740*(x**28)+L0x2001a744*(x**29)+
     L0x2001a748*(x**30)+L0x2001a74c*(x**31)+L0x2001a750*(x**32)+
     L0x2001a754*(x**33)+L0x2001a758*(x**34)+L0x2001a75c*(x**35)+
     L0x2001a760*(x**36)+L0x2001a764*(x**37)+L0x2001a768*(x**38)+
     L0x2001a76c*(x**39)+L0x2001a770*(x**40)+L0x2001a774*(x**41)+
     L0x2001a778*(x**42)+L0x2001a77c*(x**43)+L0x2001a780*(x**44)+
     L0x2001a784*(x**45)+L0x2001a788*(x**46)+L0x2001a78c*(x**47)+
     L0x2001a790*(x**48)+L0x2001a794*(x**49)+L0x2001a798*(x**50)+
     L0x2001a79c*(x**51)+L0x2001a7a0*(x**52)+L0x2001a7a4*(x**53)+
     L0x2001a7a8*(x**54)+L0x2001a7ac*(x**55)+L0x2001a7b0*(x**56)+
     L0x2001a7b4*(x**57)+L0x2001a7b8*(x**58)+L0x2001a7bc*(x**59)+
     L0x2001a7c0*(x**60)+L0x2001a7c4*(x**61)+L0x2001a7c8*(x**62)+
     L0x2001a7cc*(x**63))
    [1043969, x**64 - 324180],
eqmod (inp_poly**2)
    (L0x2001a7d0*(x** 0)+L0x2001a7d4*(x** 1)+L0x2001a7d8*(x** 2)+
     L0x2001a7dc*(x** 3)+L0x2001a7e0*(x** 4)+L0x2001a7e4*(x** 5)+
     L0x2001a7e8*(x** 6)+L0x2001a7ec*(x** 7)+L0x2001a7f0*(x** 8)+
     L0x2001a7f4*(x** 9)+L0x2001a7f8*(x**10)+L0x2001a7fc*(x**11)+
     L0x2001a800*(x**12)+L0x2001a804*(x**13)+L0x2001a808*(x**14)+
     L0x2001a80c*(x**15)+L0x2001a810*(x**16)+L0x2001a814*(x**17)+
     L0x2001a818*(x**18)+L0x2001a81c*(x**19)+L0x2001a820*(x**20)+
     L0x2001a824*(x**21)+L0x2001a828*(x**22)+L0x2001a82c*(x**23)+
     L0x2001a830*(x**24)+L0x2001a834*(x**25)+L0x2001a838*(x**26)+
     L0x2001a83c*(x**27)+L0x2001a840*(x**28)+L0x2001a844*(x**29)+
     L0x2001a848*(x**30)+L0x2001a84c*(x**31)+L0x2001a850*(x**32)+
     L0x2001a854*(x**33)+L0x2001a858*(x**34)+L0x2001a85c*(x**35)+
     L0x2001a860*(x**36)+L0x2001a864*(x**37)+L0x2001a868*(x**38)+
     L0x2001a86c*(x**39)+L0x2001a870*(x**40)+L0x2001a874*(x**41)+
     L0x2001a878*(x**42)+L0x2001a87c*(x**43)+L0x2001a880*(x**44)+
     L0x2001a884*(x**45)+L0x2001a888*(x**46)+L0x2001a88c*(x**47)+
     L0x2001a890*(x**48)+L0x2001a894*(x**49)+L0x2001a898*(x**50)+
     L0x2001a89c*(x**51)+L0x2001a8a0*(x**52)+L0x2001a8a4*(x**53)+
     L0x2001a8a8*(x**54)+L0x2001a8ac*(x**55)+L0x2001a8b0*(x**56)+
     L0x2001a8b4*(x**57)+L0x2001a8b8*(x**58)+L0x2001a8bc*(x**59)+
     L0x2001a8c0*(x**60)+L0x2001a8c4*(x**61)+L0x2001a8c8*(x**62)+
     L0x2001a8cc*(x**63))
    [1043969, x**64 - 29512],
eqmod (inp_poly**2)
    (L0x2001a8d0*(x** 0)+L0x2001a8d4*(x** 1)+L0x2001a8d8*(x** 2)+
     L0x2001a8dc*(x** 3)+L0x2001a8e0*(x** 4)+L0x2001a8e4*(x** 5)+
     L0x2001a8e8*(x** 6)+L0x2001a8ec*(x** 7)+L0x2001a8f0*(x** 8)+
     L0x2001a8f4*(x** 9)+L0x2001a8f8*(x**10)+L0x2001a8fc*(x**11)+
     L0x2001a900*(x**12)+L0x2001a904*(x**13)+L0x2001a908*(x**14)+
     L0x2001a90c*(x**15)+L0x2001a910*(x**16)+L0x2001a914*(x**17)+
     L0x2001a918*(x**18)+L0x2001a91c*(x**19)+L0x2001a920*(x**20)+
     L0x2001a924*(x**21)+L0x2001a928*(x**22)+L0x2001a92c*(x**23)+
     L0x2001a930*(x**24)+L0x2001a934*(x**25)+L0x2001a938*(x**26)+
     L0x2001a93c*(x**27)+L0x2001a940*(x**28)+L0x2001a944*(x**29)+
     L0x2001a948*(x**30)+L0x2001a94c*(x**31)+L0x2001a950*(x**32)+
     L0x2001a954*(x**33)+L0x2001a958*(x**34)+L0x2001a95c*(x**35)+
     L0x2001a960*(x**36)+L0x2001a964*(x**37)+L0x2001a968*(x**38)+
     L0x2001a96c*(x**39)+L0x2001a970*(x**40)+L0x2001a974*(x**41)+
     L0x2001a978*(x**42)+L0x2001a97c*(x**43)+L0x2001a980*(x**44)+
     L0x2001a984*(x**45)+L0x2001a988*(x**46)+L0x2001a98c*(x**47)+
     L0x2001a990*(x**48)+L0x2001a994*(x**49)+L0x2001a998*(x**50)+
     L0x2001a99c*(x**51)+L0x2001a9a0*(x**52)+L0x2001a9a4*(x**53)+
     L0x2001a9a8*(x**54)+L0x2001a9ac*(x**55)+L0x2001a9b0*(x**56)+
     L0x2001a9b4*(x**57)+L0x2001a9b8*(x**58)+L0x2001a9bc*(x**59)+
     L0x2001a9c0*(x**60)+L0x2001a9c4*(x**61)+L0x2001a9c8*(x**62)+
     L0x2001a9cc*(x**63))
    [1043969, x**64 - 1014457],
eqmod (inp_poly**2)
    (L0x2001a9d0*(x** 0)+L0x2001a9d4*(x** 1)+L0x2001a9d8*(x** 2)+
     L0x2001a9dc*(x** 3)+L0x2001a9e0*(x** 4)+L0x2001a9e4*(x** 5)+
     L0x2001a9e8*(x** 6)+L0x2001a9ec*(x** 7)+L0x2001a9f0*(x** 8)+
     L0x2001a9f4*(x** 9)+L0x2001a9f8*(x**10)+L0x2001a9fc*(x**11)+
     L0x2001aa00*(x**12)+L0x2001aa04*(x**13)+L0x2001aa08*(x**14)+
     L0x2001aa0c*(x**15)+L0x2001aa10*(x**16)+L0x2001aa14*(x**17)+
     L0x2001aa18*(x**18)+L0x2001aa1c*(x**19)+L0x2001aa20*(x**20)+
     L0x2001aa24*(x**21)+L0x2001aa28*(x**22)+L0x2001aa2c*(x**23)+
     L0x2001aa30*(x**24)+L0x2001aa34*(x**25)+L0x2001aa38*(x**26)+
     L0x2001aa3c*(x**27)+L0x2001aa40*(x**28)+L0x2001aa44*(x**29)+
     L0x2001aa48*(x**30)+L0x2001aa4c*(x**31)+L0x2001aa50*(x**32)+
     L0x2001aa54*(x**33)+L0x2001aa58*(x**34)+L0x2001aa5c*(x**35)+
     L0x2001aa60*(x**36)+L0x2001aa64*(x**37)+L0x2001aa68*(x**38)+
     L0x2001aa6c*(x**39)+L0x2001aa70*(x**40)+L0x2001aa74*(x**41)+
     L0x2001aa78*(x**42)+L0x2001aa7c*(x**43)+L0x2001aa80*(x**44)+
     L0x2001aa84*(x**45)+L0x2001aa88*(x**46)+L0x2001aa8c*(x**47)+
     L0x2001aa90*(x**48)+L0x2001aa94*(x**49)+L0x2001aa98*(x**50)+
     L0x2001aa9c*(x**51)+L0x2001aaa0*(x**52)+L0x2001aaa4*(x**53)+
     L0x2001aaa8*(x**54)+L0x2001aaac*(x**55)+L0x2001aab0*(x**56)+
     L0x2001aab4*(x**57)+L0x2001aab8*(x**58)+L0x2001aabc*(x**59)+
     L0x2001aac0*(x**60)+L0x2001aac4*(x**61)+L0x2001aac8*(x**62)+
     L0x2001aacc*(x**63))
    [1043969, x**64 - 145873],
eqmod (inp_poly**2)
    (L0x2001aad0*(x** 0)+L0x2001aad4*(x** 1)+L0x2001aad8*(x** 2)+
     L0x2001aadc*(x** 3)+L0x2001aae0*(x** 4)+L0x2001aae4*(x** 5)+
     L0x2001aae8*(x** 6)+L0x2001aaec*(x** 7)+L0x2001aaf0*(x** 8)+
     L0x2001aaf4*(x** 9)+L0x2001aaf8*(x**10)+L0x2001aafc*(x**11)+
     L0x2001ab00*(x**12)+L0x2001ab04*(x**13)+L0x2001ab08*(x**14)+
     L0x2001ab0c*(x**15)+L0x2001ab10*(x**16)+L0x2001ab14*(x**17)+
     L0x2001ab18*(x**18)+L0x2001ab1c*(x**19)+L0x2001ab20*(x**20)+
     L0x2001ab24*(x**21)+L0x2001ab28*(x**22)+L0x2001ab2c*(x**23)+
     L0x2001ab30*(x**24)+L0x2001ab34*(x**25)+L0x2001ab38*(x**26)+
     L0x2001ab3c*(x**27)+L0x2001ab40*(x**28)+L0x2001ab44*(x**29)+
     L0x2001ab48*(x**30)+L0x2001ab4c*(x**31)+L0x2001ab50*(x**32)+
     L0x2001ab54*(x**33)+L0x2001ab58*(x**34)+L0x2001ab5c*(x**35)+
     L0x2001ab60*(x**36)+L0x2001ab64*(x**37)+L0x2001ab68*(x**38)+
     L0x2001ab6c*(x**39)+L0x2001ab70*(x**40)+L0x2001ab74*(x**41)+
     L0x2001ab78*(x**42)+L0x2001ab7c*(x**43)+L0x2001ab80*(x**44)+
     L0x2001ab84*(x**45)+L0x2001ab88*(x**46)+L0x2001ab8c*(x**47)+
     L0x2001ab90*(x**48)+L0x2001ab94*(x**49)+L0x2001ab98*(x**50)+
     L0x2001ab9c*(x**51)+L0x2001aba0*(x**52)+L0x2001aba4*(x**53)+
     L0x2001aba8*(x**54)+L0x2001abac*(x**55)+L0x2001abb0*(x**56)+
     L0x2001abb4*(x**57)+L0x2001abb8*(x**58)+L0x2001abbc*(x**59)+
     L0x2001abc0*(x**60)+L0x2001abc4*(x**61)+L0x2001abc8*(x**62)+
     L0x2001abcc*(x**63))
    [1043969, x**64 - 898096],
eqmod (inp_poly**2)
    (L0x2001abd0*(x** 0)+L0x2001abd4*(x** 1)+L0x2001abd8*(x** 2)+
     L0x2001abdc*(x** 3)+L0x2001abe0*(x** 4)+L0x2001abe4*(x** 5)+
     L0x2001abe8*(x** 6)+L0x2001abec*(x** 7)+L0x2001abf0*(x** 8)+
     L0x2001abf4*(x** 9)+L0x2001abf8*(x**10)+L0x2001abfc*(x**11)+
     L0x2001ac00*(x**12)+L0x2001ac04*(x**13)+L0x2001ac08*(x**14)+
     L0x2001ac0c*(x**15)+L0x2001ac10*(x**16)+L0x2001ac14*(x**17)+
     L0x2001ac18*(x**18)+L0x2001ac1c*(x**19)+L0x2001ac20*(x**20)+
     L0x2001ac24*(x**21)+L0x2001ac28*(x**22)+L0x2001ac2c*(x**23)+
     L0x2001ac30*(x**24)+L0x2001ac34*(x**25)+L0x2001ac38*(x**26)+
     L0x2001ac3c*(x**27)+L0x2001ac40*(x**28)+L0x2001ac44*(x**29)+
     L0x2001ac48*(x**30)+L0x2001ac4c*(x**31)+L0x2001ac50*(x**32)+
     L0x2001ac54*(x**33)+L0x2001ac58*(x**34)+L0x2001ac5c*(x**35)+
     L0x2001ac60*(x**36)+L0x2001ac64*(x**37)+L0x2001ac68*(x**38)+
     L0x2001ac6c*(x**39)+L0x2001ac70*(x**40)+L0x2001ac74*(x**41)+
     L0x2001ac78*(x**42)+L0x2001ac7c*(x**43)+L0x2001ac80*(x**44)+
     L0x2001ac84*(x**45)+L0x2001ac88*(x**46)+L0x2001ac8c*(x**47)+
     L0x2001ac90*(x**48)+L0x2001ac94*(x**49)+L0x2001ac98*(x**50)+
     L0x2001ac9c*(x**51)+L0x2001aca0*(x**52)+L0x2001aca4*(x**53)+
     L0x2001aca8*(x**54)+L0x2001acac*(x**55)+L0x2001acb0*(x**56)+
     L0x2001acb4*(x**57)+L0x2001acb8*(x**58)+L0x2001acbc*(x**59)+
     L0x2001acc0*(x**60)+L0x2001acc4*(x**61)+L0x2001acc8*(x**62)+
     L0x2001accc*(x**63))
    [1043969, x**64 - 445347],
eqmod (inp_poly**2)
    (L0x2001acd0*(x** 0)+L0x2001acd4*(x** 1)+L0x2001acd8*(x** 2)+
     L0x2001acdc*(x** 3)+L0x2001ace0*(x** 4)+L0x2001ace4*(x** 5)+
     L0x2001ace8*(x** 6)+L0x2001acec*(x** 7)+L0x2001acf0*(x** 8)+
     L0x2001acf4*(x** 9)+L0x2001acf8*(x**10)+L0x2001acfc*(x**11)+
     L0x2001ad00*(x**12)+L0x2001ad04*(x**13)+L0x2001ad08*(x**14)+
     L0x2001ad0c*(x**15)+L0x2001ad10*(x**16)+L0x2001ad14*(x**17)+
     L0x2001ad18*(x**18)+L0x2001ad1c*(x**19)+L0x2001ad20*(x**20)+
     L0x2001ad24*(x**21)+L0x2001ad28*(x**22)+L0x2001ad2c*(x**23)+
     L0x2001ad30*(x**24)+L0x2001ad34*(x**25)+L0x2001ad38*(x**26)+
     L0x2001ad3c*(x**27)+L0x2001ad40*(x**28)+L0x2001ad44*(x**29)+
     L0x2001ad48*(x**30)+L0x2001ad4c*(x**31)+L0x2001ad50*(x**32)+
     L0x2001ad54*(x**33)+L0x2001ad58*(x**34)+L0x2001ad5c*(x**35)+
     L0x2001ad60*(x**36)+L0x2001ad64*(x**37)+L0x2001ad68*(x**38)+
     L0x2001ad6c*(x**39)+L0x2001ad70*(x**40)+L0x2001ad74*(x**41)+
     L0x2001ad78*(x**42)+L0x2001ad7c*(x**43)+L0x2001ad80*(x**44)+
     L0x2001ad84*(x**45)+L0x2001ad88*(x**46)+L0x2001ad8c*(x**47)+
     L0x2001ad90*(x**48)+L0x2001ad94*(x**49)+L0x2001ad98*(x**50)+
     L0x2001ad9c*(x**51)+L0x2001ada0*(x**52)+L0x2001ada4*(x**53)+
     L0x2001ada8*(x**54)+L0x2001adac*(x**55)+L0x2001adb0*(x**56)+
     L0x2001adb4*(x**57)+L0x2001adb8*(x**58)+L0x2001adbc*(x**59)+
     L0x2001adc0*(x**60)+L0x2001adc4*(x**61)+L0x2001adc8*(x**62)+
     L0x2001adcc*(x**63))
    [1043969, x**64 - 598622],
eqmod (inp_poly**2)
    (L0x2001add0*(x** 0)+L0x2001add4*(x** 1)+L0x2001add8*(x** 2)+
     L0x2001addc*(x** 3)+L0x2001ade0*(x** 4)+L0x2001ade4*(x** 5)+
     L0x2001ade8*(x** 6)+L0x2001adec*(x** 7)+L0x2001adf0*(x** 8)+
     L0x2001adf4*(x** 9)+L0x2001adf8*(x**10)+L0x2001adfc*(x**11)+
     L0x2001ae00*(x**12)+L0x2001ae04*(x**13)+L0x2001ae08*(x**14)+
     L0x2001ae0c*(x**15)+L0x2001ae10*(x**16)+L0x2001ae14*(x**17)+
     L0x2001ae18*(x**18)+L0x2001ae1c*(x**19)+L0x2001ae20*(x**20)+
     L0x2001ae24*(x**21)+L0x2001ae28*(x**22)+L0x2001ae2c*(x**23)+
     L0x2001ae30*(x**24)+L0x2001ae34*(x**25)+L0x2001ae38*(x**26)+
     L0x2001ae3c*(x**27)+L0x2001ae40*(x**28)+L0x2001ae44*(x**29)+
     L0x2001ae48*(x**30)+L0x2001ae4c*(x**31)+L0x2001ae50*(x**32)+
     L0x2001ae54*(x**33)+L0x2001ae58*(x**34)+L0x2001ae5c*(x**35)+
     L0x2001ae60*(x**36)+L0x2001ae64*(x**37)+L0x2001ae68*(x**38)+
     L0x2001ae6c*(x**39)+L0x2001ae70*(x**40)+L0x2001ae74*(x**41)+
     L0x2001ae78*(x**42)+L0x2001ae7c*(x**43)+L0x2001ae80*(x**44)+
     L0x2001ae84*(x**45)+L0x2001ae88*(x**46)+L0x2001ae8c*(x**47)+
     L0x2001ae90*(x**48)+L0x2001ae94*(x**49)+L0x2001ae98*(x**50)+
     L0x2001ae9c*(x**51)+L0x2001aea0*(x**52)+L0x2001aea4*(x**53)+
     L0x2001aea8*(x**54)+L0x2001aeac*(x**55)+L0x2001aeb0*(x**56)+
     L0x2001aeb4*(x**57)+L0x2001aeb8*(x**58)+L0x2001aebc*(x**59)+
     L0x2001aec0*(x**60)+L0x2001aec4*(x**61)+L0x2001aec8*(x**62)+
     L0x2001aecc*(x**63))
    [1043969, x**64 - 775725],
eqmod (inp_poly**2)
    (L0x2001aed0*(x** 0)+L0x2001aed4*(x** 1)+L0x2001aed8*(x** 2)+
     L0x2001aedc*(x** 3)+L0x2001aee0*(x** 4)+L0x2001aee4*(x** 5)+
     L0x2001aee8*(x** 6)+L0x2001aeec*(x** 7)+L0x2001aef0*(x** 8)+
     L0x2001aef4*(x** 9)+L0x2001aef8*(x**10)+L0x2001aefc*(x**11)+
     L0x2001af00*(x**12)+L0x2001af04*(x**13)+L0x2001af08*(x**14)+
     L0x2001af0c*(x**15)+L0x2001af10*(x**16)+L0x2001af14*(x**17)+
     L0x2001af18*(x**18)+L0x2001af1c*(x**19)+L0x2001af20*(x**20)+
     L0x2001af24*(x**21)+L0x2001af28*(x**22)+L0x2001af2c*(x**23)+
     L0x2001af30*(x**24)+L0x2001af34*(x**25)+L0x2001af38*(x**26)+
     L0x2001af3c*(x**27)+L0x2001af40*(x**28)+L0x2001af44*(x**29)+
     L0x2001af48*(x**30)+L0x2001af4c*(x**31)+L0x2001af50*(x**32)+
     L0x2001af54*(x**33)+L0x2001af58*(x**34)+L0x2001af5c*(x**35)+
     L0x2001af60*(x**36)+L0x2001af64*(x**37)+L0x2001af68*(x**38)+
     L0x2001af6c*(x**39)+L0x2001af70*(x**40)+L0x2001af74*(x**41)+
     L0x2001af78*(x**42)+L0x2001af7c*(x**43)+L0x2001af80*(x**44)+
     L0x2001af84*(x**45)+L0x2001af88*(x**46)+L0x2001af8c*(x**47)+
     L0x2001af90*(x**48)+L0x2001af94*(x**49)+L0x2001af98*(x**50)+
     L0x2001af9c*(x**51)+L0x2001afa0*(x**52)+L0x2001afa4*(x**53)+
     L0x2001afa8*(x**54)+L0x2001afac*(x**55)+L0x2001afb0*(x**56)+
     L0x2001afb4*(x**57)+L0x2001afb8*(x**58)+L0x2001afbc*(x**59)+
     L0x2001afc0*(x**60)+L0x2001afc4*(x**61)+L0x2001afc8*(x**62)+
     L0x2001afcc*(x**63))
    [1043969, x**64 - 268244]
] && and [
(-5)@32*1043969@32 <s L0x20019fd0, L0x20019fd0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019fd4, L0x20019fd4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019fd8, L0x20019fd8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019fdc, L0x20019fdc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019fe0, L0x20019fe0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019fe4, L0x20019fe4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019fe8, L0x20019fe8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019fec, L0x20019fec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019ff0, L0x20019ff0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019ff4, L0x20019ff4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019ff8, L0x20019ff8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x20019ffc, L0x20019ffc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a000, L0x2001a000 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a004, L0x2001a004 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a008, L0x2001a008 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a00c, L0x2001a00c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a010, L0x2001a010 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a014, L0x2001a014 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a018, L0x2001a018 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a01c, L0x2001a01c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a020, L0x2001a020 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a024, L0x2001a024 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a028, L0x2001a028 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a02c, L0x2001a02c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a030, L0x2001a030 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a034, L0x2001a034 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a038, L0x2001a038 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a03c, L0x2001a03c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a040, L0x2001a040 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a044, L0x2001a044 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a048, L0x2001a048 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a04c, L0x2001a04c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a050, L0x2001a050 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a054, L0x2001a054 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a058, L0x2001a058 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a05c, L0x2001a05c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a060, L0x2001a060 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a064, L0x2001a064 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a068, L0x2001a068 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a06c, L0x2001a06c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a070, L0x2001a070 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a074, L0x2001a074 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a078, L0x2001a078 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a07c, L0x2001a07c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a080, L0x2001a080 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a084, L0x2001a084 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a088, L0x2001a088 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a08c, L0x2001a08c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a090, L0x2001a090 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a094, L0x2001a094 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a098, L0x2001a098 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a09c, L0x2001a09c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0a0, L0x2001a0a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0a4, L0x2001a0a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0a8, L0x2001a0a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0ac, L0x2001a0ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0b0, L0x2001a0b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0b4, L0x2001a0b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0b8, L0x2001a0b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0bc, L0x2001a0bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0c0, L0x2001a0c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0c4, L0x2001a0c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0c8, L0x2001a0c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0cc, L0x2001a0cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0d0, L0x2001a0d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0d4, L0x2001a0d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0d8, L0x2001a0d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0dc, L0x2001a0dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0e0, L0x2001a0e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0e4, L0x2001a0e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0e8, L0x2001a0e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0ec, L0x2001a0ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0f0, L0x2001a0f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0f4, L0x2001a0f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0f8, L0x2001a0f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a0fc, L0x2001a0fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a100, L0x2001a100 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a104, L0x2001a104 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a108, L0x2001a108 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a10c, L0x2001a10c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a110, L0x2001a110 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a114, L0x2001a114 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a118, L0x2001a118 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a11c, L0x2001a11c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a120, L0x2001a120 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a124, L0x2001a124 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a128, L0x2001a128 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a12c, L0x2001a12c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a130, L0x2001a130 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a134, L0x2001a134 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a138, L0x2001a138 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a13c, L0x2001a13c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a140, L0x2001a140 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a144, L0x2001a144 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a148, L0x2001a148 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a14c, L0x2001a14c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a150, L0x2001a150 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a154, L0x2001a154 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a158, L0x2001a158 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a15c, L0x2001a15c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a160, L0x2001a160 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a164, L0x2001a164 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a168, L0x2001a168 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a16c, L0x2001a16c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a170, L0x2001a170 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a174, L0x2001a174 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a178, L0x2001a178 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a17c, L0x2001a17c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a180, L0x2001a180 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a184, L0x2001a184 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a188, L0x2001a188 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a18c, L0x2001a18c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a190, L0x2001a190 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a194, L0x2001a194 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a198, L0x2001a198 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a19c, L0x2001a19c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1a0, L0x2001a1a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1a4, L0x2001a1a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1a8, L0x2001a1a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1ac, L0x2001a1ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1b0, L0x2001a1b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1b4, L0x2001a1b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1b8, L0x2001a1b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1bc, L0x2001a1bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1c0, L0x2001a1c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1c4, L0x2001a1c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1c8, L0x2001a1c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1cc, L0x2001a1cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1d0, L0x2001a1d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1d4, L0x2001a1d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1d8, L0x2001a1d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1dc, L0x2001a1dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1e0, L0x2001a1e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1e4, L0x2001a1e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1e8, L0x2001a1e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1ec, L0x2001a1ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1f0, L0x2001a1f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1f4, L0x2001a1f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1f8, L0x2001a1f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a1fc, L0x2001a1fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a200, L0x2001a200 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a204, L0x2001a204 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a208, L0x2001a208 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a20c, L0x2001a20c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a210, L0x2001a210 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a214, L0x2001a214 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a218, L0x2001a218 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a21c, L0x2001a21c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a220, L0x2001a220 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a224, L0x2001a224 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a228, L0x2001a228 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a22c, L0x2001a22c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a230, L0x2001a230 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a234, L0x2001a234 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a238, L0x2001a238 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a23c, L0x2001a23c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a240, L0x2001a240 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a244, L0x2001a244 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a248, L0x2001a248 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a24c, L0x2001a24c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a250, L0x2001a250 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a254, L0x2001a254 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a258, L0x2001a258 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a25c, L0x2001a25c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a260, L0x2001a260 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a264, L0x2001a264 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a268, L0x2001a268 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a26c, L0x2001a26c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a270, L0x2001a270 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a274, L0x2001a274 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a278, L0x2001a278 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a27c, L0x2001a27c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a280, L0x2001a280 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a284, L0x2001a284 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a288, L0x2001a288 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a28c, L0x2001a28c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a290, L0x2001a290 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a294, L0x2001a294 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a298, L0x2001a298 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a29c, L0x2001a29c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2a0, L0x2001a2a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2a4, L0x2001a2a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2a8, L0x2001a2a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2ac, L0x2001a2ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2b0, L0x2001a2b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2b4, L0x2001a2b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2b8, L0x2001a2b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2bc, L0x2001a2bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2c0, L0x2001a2c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2c4, L0x2001a2c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2c8, L0x2001a2c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2cc, L0x2001a2cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2d0, L0x2001a2d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2d4, L0x2001a2d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2d8, L0x2001a2d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2dc, L0x2001a2dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2e0, L0x2001a2e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2e4, L0x2001a2e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2e8, L0x2001a2e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2ec, L0x2001a2ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2f0, L0x2001a2f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2f4, L0x2001a2f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2f8, L0x2001a2f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a2fc, L0x2001a2fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a300, L0x2001a300 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a304, L0x2001a304 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a308, L0x2001a308 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a30c, L0x2001a30c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a310, L0x2001a310 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a314, L0x2001a314 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a318, L0x2001a318 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a31c, L0x2001a31c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a320, L0x2001a320 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a324, L0x2001a324 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a328, L0x2001a328 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a32c, L0x2001a32c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a330, L0x2001a330 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a334, L0x2001a334 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a338, L0x2001a338 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a33c, L0x2001a33c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a340, L0x2001a340 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a344, L0x2001a344 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a348, L0x2001a348 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a34c, L0x2001a34c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a350, L0x2001a350 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a354, L0x2001a354 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a358, L0x2001a358 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a35c, L0x2001a35c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a360, L0x2001a360 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a364, L0x2001a364 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a368, L0x2001a368 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a36c, L0x2001a36c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a370, L0x2001a370 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a374, L0x2001a374 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a378, L0x2001a378 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a37c, L0x2001a37c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a380, L0x2001a380 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a384, L0x2001a384 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a388, L0x2001a388 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a38c, L0x2001a38c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a390, L0x2001a390 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a394, L0x2001a394 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a398, L0x2001a398 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a39c, L0x2001a39c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3a0, L0x2001a3a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3a4, L0x2001a3a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3a8, L0x2001a3a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3ac, L0x2001a3ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3b0, L0x2001a3b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3b4, L0x2001a3b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3b8, L0x2001a3b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3bc, L0x2001a3bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3c0, L0x2001a3c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3c4, L0x2001a3c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3c8, L0x2001a3c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3cc, L0x2001a3cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3d0, L0x2001a3d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3d4, L0x2001a3d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3d8, L0x2001a3d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3dc, L0x2001a3dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3e0, L0x2001a3e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3e4, L0x2001a3e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3e8, L0x2001a3e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3ec, L0x2001a3ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3f0, L0x2001a3f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3f4, L0x2001a3f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3f8, L0x2001a3f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a3fc, L0x2001a3fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a400, L0x2001a400 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a404, L0x2001a404 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a408, L0x2001a408 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a40c, L0x2001a40c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a410, L0x2001a410 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a414, L0x2001a414 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a418, L0x2001a418 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a41c, L0x2001a41c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a420, L0x2001a420 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a424, L0x2001a424 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a428, L0x2001a428 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a42c, L0x2001a42c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a430, L0x2001a430 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a434, L0x2001a434 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a438, L0x2001a438 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a43c, L0x2001a43c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a440, L0x2001a440 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a444, L0x2001a444 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a448, L0x2001a448 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a44c, L0x2001a44c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a450, L0x2001a450 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a454, L0x2001a454 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a458, L0x2001a458 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a45c, L0x2001a45c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a460, L0x2001a460 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a464, L0x2001a464 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a468, L0x2001a468 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a46c, L0x2001a46c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a470, L0x2001a470 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a474, L0x2001a474 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a478, L0x2001a478 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a47c, L0x2001a47c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a480, L0x2001a480 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a484, L0x2001a484 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a488, L0x2001a488 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a48c, L0x2001a48c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a490, L0x2001a490 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a494, L0x2001a494 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a498, L0x2001a498 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a49c, L0x2001a49c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4a0, L0x2001a4a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4a4, L0x2001a4a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4a8, L0x2001a4a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4ac, L0x2001a4ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4b0, L0x2001a4b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4b4, L0x2001a4b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4b8, L0x2001a4b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4bc, L0x2001a4bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4c0, L0x2001a4c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4c4, L0x2001a4c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4c8, L0x2001a4c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4cc, L0x2001a4cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4d0, L0x2001a4d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4d4, L0x2001a4d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4d8, L0x2001a4d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4dc, L0x2001a4dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4e0, L0x2001a4e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4e4, L0x2001a4e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4e8, L0x2001a4e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4ec, L0x2001a4ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4f0, L0x2001a4f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4f4, L0x2001a4f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4f8, L0x2001a4f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a4fc, L0x2001a4fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a500, L0x2001a500 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a504, L0x2001a504 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a508, L0x2001a508 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a50c, L0x2001a50c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a510, L0x2001a510 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a514, L0x2001a514 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a518, L0x2001a518 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a51c, L0x2001a51c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a520, L0x2001a520 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a524, L0x2001a524 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a528, L0x2001a528 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a52c, L0x2001a52c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a530, L0x2001a530 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a534, L0x2001a534 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a538, L0x2001a538 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a53c, L0x2001a53c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a540, L0x2001a540 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a544, L0x2001a544 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a548, L0x2001a548 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a54c, L0x2001a54c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a550, L0x2001a550 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a554, L0x2001a554 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a558, L0x2001a558 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a55c, L0x2001a55c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a560, L0x2001a560 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a564, L0x2001a564 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a568, L0x2001a568 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a56c, L0x2001a56c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a570, L0x2001a570 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a574, L0x2001a574 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a578, L0x2001a578 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a57c, L0x2001a57c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a580, L0x2001a580 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a584, L0x2001a584 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a588, L0x2001a588 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a58c, L0x2001a58c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a590, L0x2001a590 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a594, L0x2001a594 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a598, L0x2001a598 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a59c, L0x2001a59c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5a0, L0x2001a5a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5a4, L0x2001a5a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5a8, L0x2001a5a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5ac, L0x2001a5ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5b0, L0x2001a5b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5b4, L0x2001a5b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5b8, L0x2001a5b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5bc, L0x2001a5bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5c0, L0x2001a5c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5c4, L0x2001a5c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5c8, L0x2001a5c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5cc, L0x2001a5cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5d0, L0x2001a5d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5d4, L0x2001a5d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5d8, L0x2001a5d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5dc, L0x2001a5dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5e0, L0x2001a5e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5e4, L0x2001a5e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5e8, L0x2001a5e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5ec, L0x2001a5ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5f0, L0x2001a5f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5f4, L0x2001a5f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5f8, L0x2001a5f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a5fc, L0x2001a5fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a600, L0x2001a600 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a604, L0x2001a604 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a608, L0x2001a608 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a60c, L0x2001a60c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a610, L0x2001a610 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a614, L0x2001a614 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a618, L0x2001a618 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a61c, L0x2001a61c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a620, L0x2001a620 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a624, L0x2001a624 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a628, L0x2001a628 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a62c, L0x2001a62c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a630, L0x2001a630 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a634, L0x2001a634 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a638, L0x2001a638 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a63c, L0x2001a63c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a640, L0x2001a640 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a644, L0x2001a644 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a648, L0x2001a648 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a64c, L0x2001a64c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a650, L0x2001a650 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a654, L0x2001a654 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a658, L0x2001a658 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a65c, L0x2001a65c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a660, L0x2001a660 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a664, L0x2001a664 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a668, L0x2001a668 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a66c, L0x2001a66c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a670, L0x2001a670 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a674, L0x2001a674 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a678, L0x2001a678 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a67c, L0x2001a67c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a680, L0x2001a680 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a684, L0x2001a684 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a688, L0x2001a688 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a68c, L0x2001a68c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a690, L0x2001a690 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a694, L0x2001a694 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a698, L0x2001a698 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a69c, L0x2001a69c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6a0, L0x2001a6a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6a4, L0x2001a6a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6a8, L0x2001a6a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6ac, L0x2001a6ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6b0, L0x2001a6b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6b4, L0x2001a6b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6b8, L0x2001a6b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6bc, L0x2001a6bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6c0, L0x2001a6c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6c4, L0x2001a6c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6c8, L0x2001a6c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6cc, L0x2001a6cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6d0, L0x2001a6d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6d4, L0x2001a6d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6d8, L0x2001a6d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6dc, L0x2001a6dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6e0, L0x2001a6e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6e4, L0x2001a6e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6e8, L0x2001a6e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6ec, L0x2001a6ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6f0, L0x2001a6f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6f4, L0x2001a6f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6f8, L0x2001a6f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a6fc, L0x2001a6fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a700, L0x2001a700 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a704, L0x2001a704 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a708, L0x2001a708 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a70c, L0x2001a70c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a710, L0x2001a710 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a714, L0x2001a714 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a718, L0x2001a718 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a71c, L0x2001a71c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a720, L0x2001a720 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a724, L0x2001a724 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a728, L0x2001a728 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a72c, L0x2001a72c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a730, L0x2001a730 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a734, L0x2001a734 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a738, L0x2001a738 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a73c, L0x2001a73c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a740, L0x2001a740 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a744, L0x2001a744 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a748, L0x2001a748 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a74c, L0x2001a74c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a750, L0x2001a750 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a754, L0x2001a754 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a758, L0x2001a758 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a75c, L0x2001a75c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a760, L0x2001a760 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a764, L0x2001a764 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a768, L0x2001a768 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a76c, L0x2001a76c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a770, L0x2001a770 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a774, L0x2001a774 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a778, L0x2001a778 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a77c, L0x2001a77c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a780, L0x2001a780 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a784, L0x2001a784 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a788, L0x2001a788 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a78c, L0x2001a78c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a790, L0x2001a790 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a794, L0x2001a794 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a798, L0x2001a798 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a79c, L0x2001a79c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7a0, L0x2001a7a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7a4, L0x2001a7a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7a8, L0x2001a7a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7ac, L0x2001a7ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7b0, L0x2001a7b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7b4, L0x2001a7b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7b8, L0x2001a7b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7bc, L0x2001a7bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7c0, L0x2001a7c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7c4, L0x2001a7c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7c8, L0x2001a7c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7cc, L0x2001a7cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7d0, L0x2001a7d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7d4, L0x2001a7d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7d8, L0x2001a7d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7dc, L0x2001a7dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7e0, L0x2001a7e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7e4, L0x2001a7e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7e8, L0x2001a7e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7ec, L0x2001a7ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7f0, L0x2001a7f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7f4, L0x2001a7f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7f8, L0x2001a7f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a7fc, L0x2001a7fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a800, L0x2001a800 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a804, L0x2001a804 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a808, L0x2001a808 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a80c, L0x2001a80c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a810, L0x2001a810 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a814, L0x2001a814 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a818, L0x2001a818 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a81c, L0x2001a81c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a820, L0x2001a820 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a824, L0x2001a824 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a828, L0x2001a828 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a82c, L0x2001a82c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a830, L0x2001a830 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a834, L0x2001a834 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a838, L0x2001a838 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a83c, L0x2001a83c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a840, L0x2001a840 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a844, L0x2001a844 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a848, L0x2001a848 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a84c, L0x2001a84c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a850, L0x2001a850 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a854, L0x2001a854 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a858, L0x2001a858 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a85c, L0x2001a85c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a860, L0x2001a860 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a864, L0x2001a864 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a868, L0x2001a868 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a86c, L0x2001a86c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a870, L0x2001a870 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a874, L0x2001a874 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a878, L0x2001a878 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a87c, L0x2001a87c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a880, L0x2001a880 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a884, L0x2001a884 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a888, L0x2001a888 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a88c, L0x2001a88c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a890, L0x2001a890 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a894, L0x2001a894 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a898, L0x2001a898 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a89c, L0x2001a89c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8a0, L0x2001a8a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8a4, L0x2001a8a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8a8, L0x2001a8a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8ac, L0x2001a8ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8b0, L0x2001a8b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8b4, L0x2001a8b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8b8, L0x2001a8b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8bc, L0x2001a8bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8c0, L0x2001a8c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8c4, L0x2001a8c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8c8, L0x2001a8c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8cc, L0x2001a8cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8d0, L0x2001a8d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8d4, L0x2001a8d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8d8, L0x2001a8d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8dc, L0x2001a8dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8e0, L0x2001a8e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8e4, L0x2001a8e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8e8, L0x2001a8e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8ec, L0x2001a8ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8f0, L0x2001a8f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8f4, L0x2001a8f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8f8, L0x2001a8f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a8fc, L0x2001a8fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a900, L0x2001a900 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a904, L0x2001a904 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a908, L0x2001a908 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a90c, L0x2001a90c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a910, L0x2001a910 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a914, L0x2001a914 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a918, L0x2001a918 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a91c, L0x2001a91c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a920, L0x2001a920 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a924, L0x2001a924 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a928, L0x2001a928 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a92c, L0x2001a92c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a930, L0x2001a930 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a934, L0x2001a934 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a938, L0x2001a938 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a93c, L0x2001a93c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a940, L0x2001a940 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a944, L0x2001a944 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a948, L0x2001a948 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a94c, L0x2001a94c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a950, L0x2001a950 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a954, L0x2001a954 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a958, L0x2001a958 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a95c, L0x2001a95c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a960, L0x2001a960 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a964, L0x2001a964 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a968, L0x2001a968 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a96c, L0x2001a96c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a970, L0x2001a970 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a974, L0x2001a974 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a978, L0x2001a978 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a97c, L0x2001a97c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a980, L0x2001a980 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a984, L0x2001a984 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a988, L0x2001a988 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a98c, L0x2001a98c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a990, L0x2001a990 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a994, L0x2001a994 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a998, L0x2001a998 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a99c, L0x2001a99c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9a0, L0x2001a9a0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9a4, L0x2001a9a4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9a8, L0x2001a9a8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9ac, L0x2001a9ac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9b0, L0x2001a9b0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9b4, L0x2001a9b4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9b8, L0x2001a9b8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9bc, L0x2001a9bc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9c0, L0x2001a9c0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9c4, L0x2001a9c4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9c8, L0x2001a9c8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9cc, L0x2001a9cc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9d0, L0x2001a9d0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9d4, L0x2001a9d4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9d8, L0x2001a9d8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9dc, L0x2001a9dc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9e0, L0x2001a9e0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9e4, L0x2001a9e4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9e8, L0x2001a9e8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9ec, L0x2001a9ec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9f0, L0x2001a9f0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9f4, L0x2001a9f4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9f8, L0x2001a9f8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001a9fc, L0x2001a9fc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa00, L0x2001aa00 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa04, L0x2001aa04 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa08, L0x2001aa08 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa0c, L0x2001aa0c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa10, L0x2001aa10 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa14, L0x2001aa14 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa18, L0x2001aa18 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa1c, L0x2001aa1c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa20, L0x2001aa20 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa24, L0x2001aa24 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa28, L0x2001aa28 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa2c, L0x2001aa2c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa30, L0x2001aa30 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa34, L0x2001aa34 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa38, L0x2001aa38 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa3c, L0x2001aa3c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa40, L0x2001aa40 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa44, L0x2001aa44 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa48, L0x2001aa48 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa4c, L0x2001aa4c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa50, L0x2001aa50 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa54, L0x2001aa54 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa58, L0x2001aa58 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa5c, L0x2001aa5c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa60, L0x2001aa60 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa64, L0x2001aa64 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa68, L0x2001aa68 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa6c, L0x2001aa6c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa70, L0x2001aa70 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa74, L0x2001aa74 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa78, L0x2001aa78 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa7c, L0x2001aa7c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa80, L0x2001aa80 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa84, L0x2001aa84 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa88, L0x2001aa88 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa8c, L0x2001aa8c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa90, L0x2001aa90 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa94, L0x2001aa94 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa98, L0x2001aa98 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aa9c, L0x2001aa9c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aaa0, L0x2001aaa0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aaa4, L0x2001aaa4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aaa8, L0x2001aaa8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aaac, L0x2001aaac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aab0, L0x2001aab0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aab4, L0x2001aab4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aab8, L0x2001aab8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aabc, L0x2001aabc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aac0, L0x2001aac0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aac4, L0x2001aac4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aac8, L0x2001aac8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aacc, L0x2001aacc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aad0, L0x2001aad0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aad4, L0x2001aad4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aad8, L0x2001aad8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aadc, L0x2001aadc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aae0, L0x2001aae0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aae4, L0x2001aae4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aae8, L0x2001aae8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aaec, L0x2001aaec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aaf0, L0x2001aaf0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aaf4, L0x2001aaf4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aaf8, L0x2001aaf8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aafc, L0x2001aafc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab00, L0x2001ab00 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab04, L0x2001ab04 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab08, L0x2001ab08 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab0c, L0x2001ab0c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab10, L0x2001ab10 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab14, L0x2001ab14 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab18, L0x2001ab18 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab1c, L0x2001ab1c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab20, L0x2001ab20 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab24, L0x2001ab24 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab28, L0x2001ab28 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab2c, L0x2001ab2c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab30, L0x2001ab30 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab34, L0x2001ab34 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab38, L0x2001ab38 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab3c, L0x2001ab3c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab40, L0x2001ab40 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab44, L0x2001ab44 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab48, L0x2001ab48 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab4c, L0x2001ab4c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab50, L0x2001ab50 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab54, L0x2001ab54 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab58, L0x2001ab58 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab5c, L0x2001ab5c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab60, L0x2001ab60 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab64, L0x2001ab64 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab68, L0x2001ab68 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab6c, L0x2001ab6c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab70, L0x2001ab70 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab74, L0x2001ab74 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab78, L0x2001ab78 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab7c, L0x2001ab7c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab80, L0x2001ab80 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab84, L0x2001ab84 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab88, L0x2001ab88 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab8c, L0x2001ab8c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab90, L0x2001ab90 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab94, L0x2001ab94 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab98, L0x2001ab98 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ab9c, L0x2001ab9c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aba0, L0x2001aba0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aba4, L0x2001aba4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aba8, L0x2001aba8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abac, L0x2001abac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abb0, L0x2001abb0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abb4, L0x2001abb4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abb8, L0x2001abb8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abbc, L0x2001abbc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abc0, L0x2001abc0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abc4, L0x2001abc4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abc8, L0x2001abc8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abcc, L0x2001abcc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abd0, L0x2001abd0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abd4, L0x2001abd4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abd8, L0x2001abd8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abdc, L0x2001abdc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abe0, L0x2001abe0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abe4, L0x2001abe4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abe8, L0x2001abe8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abec, L0x2001abec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abf0, L0x2001abf0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abf4, L0x2001abf4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abf8, L0x2001abf8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001abfc, L0x2001abfc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac00, L0x2001ac00 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac04, L0x2001ac04 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac08, L0x2001ac08 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac0c, L0x2001ac0c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac10, L0x2001ac10 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac14, L0x2001ac14 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac18, L0x2001ac18 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac1c, L0x2001ac1c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac20, L0x2001ac20 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac24, L0x2001ac24 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac28, L0x2001ac28 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac2c, L0x2001ac2c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac30, L0x2001ac30 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac34, L0x2001ac34 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac38, L0x2001ac38 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac3c, L0x2001ac3c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac40, L0x2001ac40 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac44, L0x2001ac44 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac48, L0x2001ac48 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac4c, L0x2001ac4c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac50, L0x2001ac50 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac54, L0x2001ac54 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac58, L0x2001ac58 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac5c, L0x2001ac5c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac60, L0x2001ac60 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac64, L0x2001ac64 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac68, L0x2001ac68 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac6c, L0x2001ac6c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac70, L0x2001ac70 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac74, L0x2001ac74 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac78, L0x2001ac78 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac7c, L0x2001ac7c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac80, L0x2001ac80 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac84, L0x2001ac84 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac88, L0x2001ac88 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac8c, L0x2001ac8c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac90, L0x2001ac90 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac94, L0x2001ac94 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac98, L0x2001ac98 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ac9c, L0x2001ac9c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aca0, L0x2001aca0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aca4, L0x2001aca4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aca8, L0x2001aca8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acac, L0x2001acac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acb0, L0x2001acb0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acb4, L0x2001acb4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acb8, L0x2001acb8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acbc, L0x2001acbc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acc0, L0x2001acc0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acc4, L0x2001acc4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acc8, L0x2001acc8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001accc, L0x2001accc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acd0, L0x2001acd0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acd4, L0x2001acd4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acd8, L0x2001acd8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acdc, L0x2001acdc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ace0, L0x2001ace0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ace4, L0x2001ace4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ace8, L0x2001ace8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acec, L0x2001acec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acf0, L0x2001acf0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acf4, L0x2001acf4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acf8, L0x2001acf8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001acfc, L0x2001acfc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad00, L0x2001ad00 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad04, L0x2001ad04 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad08, L0x2001ad08 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad0c, L0x2001ad0c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad10, L0x2001ad10 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad14, L0x2001ad14 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad18, L0x2001ad18 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad1c, L0x2001ad1c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad20, L0x2001ad20 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad24, L0x2001ad24 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad28, L0x2001ad28 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad2c, L0x2001ad2c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad30, L0x2001ad30 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad34, L0x2001ad34 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad38, L0x2001ad38 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad3c, L0x2001ad3c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad40, L0x2001ad40 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad44, L0x2001ad44 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad48, L0x2001ad48 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad4c, L0x2001ad4c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad50, L0x2001ad50 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad54, L0x2001ad54 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad58, L0x2001ad58 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad5c, L0x2001ad5c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad60, L0x2001ad60 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad64, L0x2001ad64 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad68, L0x2001ad68 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad6c, L0x2001ad6c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad70, L0x2001ad70 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad74, L0x2001ad74 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad78, L0x2001ad78 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad7c, L0x2001ad7c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad80, L0x2001ad80 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad84, L0x2001ad84 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad88, L0x2001ad88 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad8c, L0x2001ad8c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad90, L0x2001ad90 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad94, L0x2001ad94 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad98, L0x2001ad98 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ad9c, L0x2001ad9c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ada0, L0x2001ada0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ada4, L0x2001ada4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ada8, L0x2001ada8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adac, L0x2001adac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adb0, L0x2001adb0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adb4, L0x2001adb4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adb8, L0x2001adb8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adbc, L0x2001adbc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adc0, L0x2001adc0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adc4, L0x2001adc4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adc8, L0x2001adc8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adcc, L0x2001adcc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001add0, L0x2001add0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001add4, L0x2001add4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001add8, L0x2001add8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001addc, L0x2001addc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ade0, L0x2001ade0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ade4, L0x2001ade4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ade8, L0x2001ade8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adec, L0x2001adec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adf0, L0x2001adf0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adf4, L0x2001adf4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adf8, L0x2001adf8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001adfc, L0x2001adfc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae00, L0x2001ae00 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae04, L0x2001ae04 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae08, L0x2001ae08 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae0c, L0x2001ae0c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae10, L0x2001ae10 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae14, L0x2001ae14 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae18, L0x2001ae18 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae1c, L0x2001ae1c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae20, L0x2001ae20 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae24, L0x2001ae24 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae28, L0x2001ae28 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae2c, L0x2001ae2c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae30, L0x2001ae30 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae34, L0x2001ae34 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae38, L0x2001ae38 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae3c, L0x2001ae3c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae40, L0x2001ae40 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae44, L0x2001ae44 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae48, L0x2001ae48 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae4c, L0x2001ae4c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae50, L0x2001ae50 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae54, L0x2001ae54 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae58, L0x2001ae58 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae5c, L0x2001ae5c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae60, L0x2001ae60 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae64, L0x2001ae64 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae68, L0x2001ae68 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae6c, L0x2001ae6c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae70, L0x2001ae70 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae74, L0x2001ae74 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae78, L0x2001ae78 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae7c, L0x2001ae7c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae80, L0x2001ae80 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae84, L0x2001ae84 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae88, L0x2001ae88 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae8c, L0x2001ae8c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae90, L0x2001ae90 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae94, L0x2001ae94 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae98, L0x2001ae98 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001ae9c, L0x2001ae9c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aea0, L0x2001aea0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aea4, L0x2001aea4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aea8, L0x2001aea8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aeac, L0x2001aeac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aeb0, L0x2001aeb0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aeb4, L0x2001aeb4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aeb8, L0x2001aeb8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aebc, L0x2001aebc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aec0, L0x2001aec0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aec4, L0x2001aec4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aec8, L0x2001aec8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aecc, L0x2001aecc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aed0, L0x2001aed0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aed4, L0x2001aed4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aed8, L0x2001aed8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aedc, L0x2001aedc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aee0, L0x2001aee0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aee4, L0x2001aee4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aee8, L0x2001aee8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aeec, L0x2001aeec <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aef0, L0x2001aef0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aef4, L0x2001aef4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aef8, L0x2001aef8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001aefc, L0x2001aefc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af00, L0x2001af00 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af04, L0x2001af04 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af08, L0x2001af08 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af0c, L0x2001af0c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af10, L0x2001af10 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af14, L0x2001af14 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af18, L0x2001af18 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af1c, L0x2001af1c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af20, L0x2001af20 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af24, L0x2001af24 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af28, L0x2001af28 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af2c, L0x2001af2c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af30, L0x2001af30 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af34, L0x2001af34 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af38, L0x2001af38 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af3c, L0x2001af3c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af40, L0x2001af40 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af44, L0x2001af44 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af48, L0x2001af48 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af4c, L0x2001af4c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af50, L0x2001af50 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af54, L0x2001af54 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af58, L0x2001af58 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af5c, L0x2001af5c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af60, L0x2001af60 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af64, L0x2001af64 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af68, L0x2001af68 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af6c, L0x2001af6c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af70, L0x2001af70 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af74, L0x2001af74 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af78, L0x2001af78 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af7c, L0x2001af7c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af80, L0x2001af80 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af84, L0x2001af84 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af88, L0x2001af88 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af8c, L0x2001af8c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af90, L0x2001af90 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af94, L0x2001af94 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af98, L0x2001af98 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001af9c, L0x2001af9c <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afa0, L0x2001afa0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afa4, L0x2001afa4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afa8, L0x2001afa8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afac, L0x2001afac <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afb0, L0x2001afb0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afb4, L0x2001afb4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afb8, L0x2001afb8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afbc, L0x2001afbc <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afc0, L0x2001afc0 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afc4, L0x2001afc4 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afc8, L0x2001afc8 <s 5@32*1043969@32,
(-5)@32*1043969@32 <s L0x2001afcc, L0x2001afcc <s 5@32*1043969@32
]
}

